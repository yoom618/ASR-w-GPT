{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39678a37",
   "metadata": {},
   "source": [
    "### 0. Initial Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf0bf6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture\n",
    "# !pip install datasets==1.0.2\n",
    "# !pip install transformers==4.2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d44238cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33myoom618\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/yoomin/wandb/run-20220401_000929-2j7svr3k</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/yoom618/testing-roberta2gpt/runs/2j7svr3k\" target=\"_blank\">atomic-tree-31</a></strong> to <a href=\"https://wandb.ai/yoom618/testing-roberta2gpt\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/yoom618/testing-roberta2gpt/runs/2j7svr3k?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7feb05c84eb0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "cache_dir = \"/data4/yoomcache\"\n",
    "model_cache_dir = os.path.join(cache_dir, 'huggingface')\n",
    "data_cache_dir = os.path.join(cache_dir, 'datasets')\n",
    "checkpoint_dir = os.path.join(cache_dir, 'checkpoint')\n",
    "\n",
    "import logging\n",
    "logging.getLogger().setLevel(logging.CRITICAL)\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "\n",
    "import torch\n",
    "from datasets import load_dataset, load_metric, load_from_disk\n",
    "from transformers import BertTokenizer, RobertaTokenizer, GPT2Tokenizer\n",
    "from transformers import AutoConfig, EncoderDecoderConfig, EncoderDecoderModel\n",
    "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
    "\n",
    "import wandb\n",
    "wandb.init(project=\"testing-roberta2gpt\", entity=\"yoom618\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc6e87b",
   "metadata": {},
   "source": [
    "### 1. Initialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "435b40c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "config_encoder = AutoConfig.from_pretrained(\"roberta-base\", cache_dir=model_cache_dir)\n",
    "config_decoder = AutoConfig.from_pretrained(\"gpt2\", cache_dir=model_cache_dir)\n",
    "config = EncoderDecoderConfig.from_encoder_decoder_configs(config_encoder, config_decoder, cache_dir=model_cache_dir)\n",
    "model = EncoderDecoderModel(config=config)\n",
    "# model.save_pretrained(\"roberta2gpt\", cache_dir=model_cache_dir)\n",
    "# model = EncoderDecoderModel.from_pretrained(\"roberta2gpt\", cache_dir=model_cache_dir)\n",
    "\n",
    "model.encoder.encoder.layer = model.encoder.encoder.layer[:6]\n",
    "model.decoder.transformer.h = model.decoder.transformer.h[-6:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6fe24aec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "encoder_tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\", cache_dir=model_cache_dir)\n",
    "encoder_tokenizer.bos_token = encoder_tokenizer.cls_token  # CLS token will work as BOS token\n",
    "encoder_tokenizer.eos_token = encoder_tokenizer.sep_token  # SEP token will work as EOS token\n",
    "\n",
    "# make sure GPT2 appends EOS in begin and end\n",
    "def build_inputs_with_special_tokens(self, token_ids_0, token_ids_1=None):\n",
    "    outputs = [self.bos_token_id] + token_ids_0 + [self.eos_token_id]\n",
    "    return outputs\n",
    "\n",
    "GPT2Tokenizer.build_inputs_with_special_tokens = build_inputs_with_special_tokens\n",
    "decoder_tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\", cache_dir=model_cache_dir)\n",
    "# set pad_token_id to unk_token_id -> be careful here as unk_token_id == eos_token_id == bos_token_id\n",
    "decoder_tokenizer.pad_token = decoder_tokenizer.unk_token\n",
    "\n",
    "\n",
    "model.config.decoder_start_token_id = encoder_tokenizer.cls_token_id\n",
    "model.config.eos_token_id = encoder_tokenizer.sep_token_id\n",
    "model.config.pad_token_id = encoder_tokenizer.pad_token_id\n",
    "model.config.vocab_size = model.config.encoder.vocab_size\n",
    "\n",
    "\n",
    "# set decoding params\n",
    "model.config.decoder_start_token_id = decoder_tokenizer.bos_token_id\n",
    "model.config.eos_token_id = decoder_tokenizer.eos_token_id\n",
    "model.config.max_length = 142\n",
    "model.config.min_length = 56\n",
    "model.config.no_repeat_ngram_size = 3\n",
    "model.early_stopping = True\n",
    "model.length_penalty = 2.0\n",
    "model.num_beams = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "466b4194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze decoder parameters\n",
    "for param in model.decoder.parameters():\n",
    "    param.requires_grad = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bce84c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "467b21e7",
   "metadata": {},
   "source": [
    "### 2. Preparing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "feaded22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# map data correctly\n",
    "def map_to_encoder_decoder_inputs(batch):    # Tokenizer will automatically set [BOS] <text> [EOS] \n",
    "    encoder_length, decoder_length = 512, 128\n",
    "    inputs = encoder_tokenizer(batch[\"article\"], \n",
    "                               padding=\"max_length\", \n",
    "                               truncation=True, \n",
    "                               max_length=encoder_length)\n",
    "    outputs = decoder_tokenizer(batch[\"highlights\"], \n",
    "                                padding=\"max_length\", \n",
    "                                truncation=True, \n",
    "                                max_length=decoder_length)\n",
    "    \n",
    "    batch[\"input_ids\"] = inputs.input_ids\n",
    "    batch[\"attention_mask\"] = inputs.attention_mask\n",
    "    batch[\"decoder_input_ids\"] = outputs.input_ids\n",
    "    batch[\"labels\"] = outputs.input_ids.copy()\n",
    "    batch[\"decoder_attention_mask\"] = outputs.attention_mask\n",
    "\n",
    "    # complicated list comprehension here because pad_token_id alone is not good enough to know whether label should be excluded or not\n",
    "    batch[\"labels\"] = -100 if batch[\"decoder_attention_mask\"] == 0 else batch[\"labels\"]\n",
    "\n",
    "    assert len(inputs.input_ids) == encoder_length\n",
    "    assert len(outputs.input_ids) == decoder_length\n",
    "\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d77189b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(cache_dir, 'preprocessed/train')):\n",
    "    train_dataset = load_from_disk(os.path.join(cache_dir, 'preprocessed/train'))\n",
    "else:\n",
    "    train_dataset = load_dataset(\"ccdv/cnn_dailymail\", \"3.0.0\", split=\"train\", cache_dir=data_cache_dir)\n",
    "    train_dataset = train_dataset.map(\n",
    "        map_to_encoder_decoder_inputs, \n",
    "        # batched=True, \n",
    "        # batch_size=batch_size, \n",
    "        remove_columns=['id', 'article', 'highlights'],\n",
    "    )\n",
    "    train_dataset.set_format(\n",
    "        type=\"torch\", \n",
    "        columns=[\"input_ids\", \"attention_mask\", \"decoder_input_ids\", \"decoder_attention_mask\", \"labels\"],\n",
    "    )\n",
    "    \n",
    "    train_dataset.save_to_disk(os.path.join(cache_dir, 'preprocessed/train'))\n",
    "\n",
    "\n",
    "if os.path.exists(os.path.join(cache_dir, 'preprocessed/val')):\n",
    "    val_dataset = load_from_disk(os.path.join(cache_dir, 'preprocessed/val'))\n",
    "else:\n",
    "    val_dataset = load_dataset(\"ccdv/cnn_dailymail\", \"3.0.0\", split=\"validation\", cache_dir=data_cache_dir)\n",
    "    val_dataset = val_dataset.map(\n",
    "        map_to_encoder_decoder_inputs, \n",
    "        # batched=True, \n",
    "        # batch_size=batch_size, \n",
    "        remove_columns=['id', 'article', 'highlights'],\n",
    "    )\n",
    "    val_dataset.set_format(\n",
    "        type=\"torch\", \n",
    "        columns=[\"input_ids\", \"attention_mask\", \"decoder_input_ids\", \"decoder_attention_mask\", \"labels\"],\n",
    "    )\n",
    "    val_dataset.save_to_disk(os.path.join(cache_dir, 'preprocessed/val'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80414621",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "63779bf8",
   "metadata": {},
   "source": [
    "### Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9cde9706",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load rouge for validation\n",
    "rouge = load_metric(\"rouge\")\n",
    "# rouge = load_metric(\"rouge\", experiment_id=1)\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels_ids = pred.label_ids\n",
    "    pred_ids = pred.predictions\n",
    "\n",
    "    # all unnecessary tokens are removed\n",
    "    pred_str = decoder_tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "    labels_ids[labels_ids == -100] = decoder_tokenizer.eos_token_id\n",
    "    label_str = decoder_tokenizer.batch_decode(labels_ids, skip_special_tokens=True)\n",
    "\n",
    "    rouge_output = rouge.compute(predictions=pred_str, references=label_str, rouge_types=[\"rouge2\"])[\"rouge2\"].mid\n",
    "\n",
    "    return {\n",
    "        \"rouge2_precision\": round(rouge_output.precision, 4),\n",
    "        \"rouge2_recall\": round(rouge_output.recall, 4),\n",
    "        \"rouge2_fmeasure\": round(rouge_output.fmeasure, 4),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1453320d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 28711\n",
      "  Num Epochs = 100\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 358900\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='25023' max='358900' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 25023/358900 14:02:51 < 187:27:01, 0.49 it/s, Epoch 6.97/100]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge2 Precision</th>\n",
       "      <th>Rouge2 Recall</th>\n",
       "      <th>Rouge2 Fmeasure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>5.456600</td>\n",
       "      <td>3.917020</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>5.010600</td>\n",
       "      <td>3.927585</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>4.995400</td>\n",
       "      <td>3.937867</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>4.996600</td>\n",
       "      <td>3.937300</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>4.981500</td>\n",
       "      <td>3.948406</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>4.972800</td>\n",
       "      <td>3.936208</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>4.966400</td>\n",
       "      <td>3.953957</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>4.957800</td>\n",
       "      <td>3.950956</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>4.946300</td>\n",
       "      <td>3.942316</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>4.951200</td>\n",
       "      <td>3.949973</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>4.758900</td>\n",
       "      <td>4.165597</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>4.655000</td>\n",
       "      <td>4.511131</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>4.623100</td>\n",
       "      <td>4.778203</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>4.569400</td>\n",
       "      <td>5.021382</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>4.566200</td>\n",
       "      <td>5.205748</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>4.521600</td>\n",
       "      <td>5.473104</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>4.498700</td>\n",
       "      <td>5.589217</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>4.470900</td>\n",
       "      <td>5.655803</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>4.446600</td>\n",
       "      <td>5.803108</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>4.442800</td>\n",
       "      <td>5.874566</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21000</td>\n",
       "      <td>4.431400</td>\n",
       "      <td>5.930039</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>4.417600</td>\n",
       "      <td>6.015490</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23000</td>\n",
       "      <td>4.398200</td>\n",
       "      <td>6.044671</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24000</td>\n",
       "      <td>4.352900</td>\n",
       "      <td>6.177953</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25000</td>\n",
       "      <td>4.364000</td>\n",
       "      <td>6.252666</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/roberta2gpt/checkpoint-2000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/roberta2gpt/checkpoint-2000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/roberta2gpt/checkpoint-2000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/roberta2gpt/checkpoint-33] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/roberta2gpt/checkpoint-4000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/roberta2gpt/checkpoint-4000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/roberta2gpt/checkpoint-4000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/roberta2gpt/checkpoint-1795] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/roberta2gpt/checkpoint-6000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/roberta2gpt/checkpoint-6000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/roberta2gpt/checkpoint-6000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/roberta2gpt/checkpoint-3590] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/roberta2gpt/checkpoint-8000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/roberta2gpt/checkpoint-8000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/roberta2gpt/checkpoint-8000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/roberta2gpt/checkpoint-2000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/roberta2gpt/checkpoint-10000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/roberta2gpt/checkpoint-10000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/roberta2gpt/checkpoint-10000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/roberta2gpt/checkpoint-4000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/roberta2gpt/checkpoint-12000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/roberta2gpt/checkpoint-12000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/roberta2gpt/checkpoint-12000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/roberta2gpt/checkpoint-6000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/roberta2gpt/checkpoint-14000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/roberta2gpt/checkpoint-14000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/roberta2gpt/checkpoint-14000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/roberta2gpt/checkpoint-8000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/roberta2gpt/checkpoint-16000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/roberta2gpt/checkpoint-16000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/roberta2gpt/checkpoint-16000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/roberta2gpt/checkpoint-10000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/roberta2gpt/checkpoint-18000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/roberta2gpt/checkpoint-18000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/roberta2gpt/checkpoint-18000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/roberta2gpt/checkpoint-12000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/roberta2gpt/checkpoint-20000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/roberta2gpt/checkpoint-20000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/roberta2gpt/checkpoint-20000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/roberta2gpt/checkpoint-14000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/roberta2gpt/checkpoint-22000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/roberta2gpt/checkpoint-22000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/roberta2gpt/checkpoint-22000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/roberta2gpt/checkpoint-16000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/roberta2gpt/checkpoint-24000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/roberta2gpt/checkpoint-24000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/roberta2gpt/checkpoint-24000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/roberta2gpt/checkpoint-18000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 1\n"
     ]
    }
   ],
   "source": [
    "batch_size = 8\n",
    "\n",
    "# set training arguments - these params are not really tuned, feel free to change\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    predict_with_generate=True,\n",
    "    output_dir=os.path.join(checkpoint_dir, \"roberta2gpt\"),\n",
    "    # do_train=True,\n",
    "    # do_eval=True,\n",
    "    # do_predict=True,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=1,\n",
    "#     learning_rate=1e-4, weight_decay=0.0, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0,\n",
    "    num_train_epochs=100,\n",
    "    max_steps=-1,\n",
    "    # lr_scheduler_type='linear', warmup_ratio=0.0, \n",
    "    \n",
    "    logging_strategy='steps',\n",
    "    save_strategy='steps',\n",
    "    evaluation_strategy='steps',\n",
    "    logging_steps=1000,\n",
    "    save_steps=2000,\n",
    "    eval_steps=1000,\n",
    "    warmup_steps=10000,\n",
    "    save_total_limit=3,\n",
    "    overwrite_output_dir=True,\n",
    ")\n",
    "\n",
    "# instantiate trainer\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    ")\n",
    "\n",
    "# start training\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2be7e0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6b0595",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd93c69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401ac735",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fff11ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7245a07f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c0da071a",
   "metadata": {},
   "source": [
    "https://huggingface.co/patrickvonplaten/bert2gpt2-cnn_dailymail-fp16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1cd79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EncoderDecoderModel.from_pretrained(\"patrickvonplaten/bert2gpt2-cnn_dailymail-fp16\")\n",
    "model.to(device)\n",
    "\n",
    "bert_tokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "# CLS token will work as BOS token\n",
    "bert_tokenizer.bos_token = bert_tokenizer.cls_token\n",
    "\n",
    "# SEP token will work as EOS token\n",
    "bert_tokenizer.eos_token = bert_tokenizer.sep_token\n",
    "\n",
    "\n",
    "# make sure GPT2 appends EOS in begin and end\n",
    "def build_inputs_with_special_tokens(self, token_ids_0, token_ids_1=None):\n",
    "    outputs = [self.bos_token_id] + token_ids_0 + [self.eos_token_id]\n",
    "    return outputs\n",
    "\n",
    "\n",
    "GPT2Tokenizer.build_inputs_with_special_tokens = build_inputs_with_special_tokens\n",
    "gpt2_tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "# set pad_token_id to unk_token_id -> be careful here as unk_token_id == eos_token_id == bos_token_id\n",
    "gpt2_tokenizer.pad_token = gpt2_tokenizer.unk_token\n",
    "\n",
    "\n",
    "# set decoding params\n",
    "model.config.decoder_start_token_id = gpt2_tokenizer.bos_token_id\n",
    "model.config.eos_token_id = gpt2_tokenizer.eos_token_id\n",
    "model.config.max_length = 142\n",
    "model.config.min_length = 56\n",
    "model.config.no_repeat_ngram_size = 3\n",
    "model.early_stopping = True\n",
    "model.length_penalty = 2.0\n",
    "model.num_beams = 4\n",
    "\n",
    "test_dataset = load_dataset(\"cnn_dailymail\", \"3.0.0\", split=\"test\")\n",
    "batch_size = 4\n",
    "\n",
    "\n",
    "# map data correctly\n",
    "def generate_summary(batch):\n",
    "    # Tokenizer will automatically set [BOS] <text> [EOS]\n",
    "    # cut off at BERT max length 512\n",
    "    inputs = bert_tokenizer(batch[\"article\"], padding=\"max_length\", truncation=True, max_length=512, return_tensors=\"pt\")\n",
    "    input_ids = inputs.input_ids.to(\"cuda\")\n",
    "    attention_mask = inputs.attention_mask.to(\"cuda\")\n",
    "\n",
    "    outputs = model.generate(input_ids, attention_mask=attention_mask)\n",
    "\n",
    "    # all special tokens including will be removed\n",
    "    output_str = gpt2_tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "\n",
    "    batch[\"pred\"] = output_str\n",
    "\n",
    "    return batch\n",
    "\n",
    "\n",
    "results = test_dataset.map(generate_summary, batched=True, batch_size=batch_size, remove_columns=[\"article\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2bac2c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load rouge for validation\n",
    "rouge = load_metric(\"rouge\")\n",
    "\n",
    "pred_str = results[\"pred\"]\n",
    "label_str = results[\"highlights\"]\n",
    "\n",
    "rouge_output = rouge.compute(predictions=pred_str, references=label_str, rouge_types=[\"rouge2\"])[\"rouge2\"].mid\n",
    "\n",
    "print(rouge_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a488e8b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad86b46e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
