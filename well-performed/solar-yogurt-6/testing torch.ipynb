{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "aceb3a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3fb9209a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = nn.LSTM(10, 20, bidirectional=True)\n",
    "input_ = torch.randn(6, 3, 10) # (seq_len, batch, input_state)\n",
    "output, (hn, cn) = rnn(input_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b32abd7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 3, 40])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "dc9ee3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = nn.AdaptiveMaxPool1d(8, return_indices=True)\n",
    "input_ = torch.randn(10, 64, 5)\n",
    "hidden_states, peak = input_[:,:,:-1], input_[:,:,-1]\n",
    "peak_values, peak_indices = m(peak)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "962671e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.2000, -0.2965, -0.2208, -1.5311],\n",
       "         [ 0.0141, -2.5344, -1.1507, -0.0047],\n",
       "         [-0.2588, -0.2056, -1.9372, -1.1506],\n",
       "         ...,\n",
       "         [ 1.5177, -0.6383, -0.5786, -0.5134],\n",
       "         [-1.3475,  0.3094,  0.7638, -0.5641],\n",
       "         [ 0.9799,  1.2143,  1.4283, -0.4043]],\n",
       "\n",
       "        [[ 0.0764,  1.0214,  0.0113,  0.3919],\n",
       "         [ 0.2163, -0.3800, -0.4736, -2.7479],\n",
       "         [ 0.4992,  0.4733,  1.7211,  0.3596],\n",
       "         ...,\n",
       "         [-1.7523, -0.9162,  1.5520,  0.6578],\n",
       "         [ 0.0899,  0.8529, -0.6514,  2.0086],\n",
       "         [-0.4912,  0.5996, -1.1437,  1.2587]],\n",
       "\n",
       "        [[ 0.4594,  0.7425, -0.7260,  0.4576],\n",
       "         [ 0.0401,  1.1417, -0.3344, -0.8563],\n",
       "         [-0.6201,  0.6714, -1.4530, -1.8778],\n",
       "         ...,\n",
       "         [ 0.0984, -0.2239,  1.4361,  0.1292],\n",
       "         [-0.2430,  1.5821, -0.2780,  1.2236],\n",
       "         [-0.6219, -0.5811, -1.5943,  0.6945]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-1.2568, -0.3326,  0.0289, -1.5400],\n",
       "         [-0.0519,  0.6400,  1.8838, -0.8912],\n",
       "         [ 1.4776,  0.9827,  1.4182,  0.9352],\n",
       "         ...,\n",
       "         [-0.1310,  1.1038, -0.5891,  1.1923],\n",
       "         [ 0.3250, -0.2619, -0.0315,  0.4367],\n",
       "         [-0.1060, -0.6169, -1.2166,  0.4688]],\n",
       "\n",
       "        [[ 0.4584,  0.6098, -0.5645, -0.6307],\n",
       "         [ 1.5726,  0.4183,  0.1856,  1.4119],\n",
       "         [-0.6463, -1.9571, -0.9616,  0.2217],\n",
       "         ...,\n",
       "         [ 1.7935, -0.0047,  0.1510, -0.8567],\n",
       "         [ 0.6372, -0.9115, -0.6402, -0.4083],\n",
       "         [-0.4021,  0.3315, -1.1390, -0.3659]],\n",
       "\n",
       "        [[-0.2189,  0.4561,  0.5324, -1.6557],\n",
       "         [ 1.1596,  0.7051, -0.5446,  0.8883],\n",
       "         [-1.4337, -1.7085,  0.6778,  1.5168],\n",
       "         ...,\n",
       "         [-0.7730,  0.1303, -0.1093, -1.3943],\n",
       "         [-1.2795,  2.2243,  0.6854,  1.3100],\n",
       "         [ 0.6398, -0.4858,  0.3969, -0.2863]]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3f794b05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 64])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peak.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "32fb9d1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6, 13, 18, 24, 34, 43, 55, 63],\n",
       "        [ 2,  9, 17, 31, 37, 45, 48, 56],\n",
       "        [ 2, 15, 22, 27, 33, 46, 52, 62],\n",
       "        [ 0,  9, 21, 31, 37, 42, 55, 59],\n",
       "        [ 5, 15, 17, 31, 34, 43, 55, 58],\n",
       "        [ 1, 10, 16, 29, 39, 45, 51, 59],\n",
       "        [ 5, 11, 19, 25, 36, 43, 54, 63],\n",
       "        [ 7, 12, 23, 25, 38, 40, 48, 61],\n",
       "        [ 2, 14, 17, 27, 34, 42, 51, 56],\n",
       "        [ 6, 12, 19, 30, 37, 42, 54, 61]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peak_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b96d2176",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 6,  6,  6,  6],\n",
       "         [13, 13, 13, 13],\n",
       "         [18, 18, 18, 18],\n",
       "         [24, 24, 24, 24],\n",
       "         [34, 34, 34, 34],\n",
       "         [43, 43, 43, 43],\n",
       "         [55, 55, 55, 55],\n",
       "         [63, 63, 63, 63]],\n",
       "\n",
       "        [[ 2,  2,  2,  2],\n",
       "         [ 9,  9,  9,  9],\n",
       "         [17, 17, 17, 17],\n",
       "         [31, 31, 31, 31],\n",
       "         [37, 37, 37, 37],\n",
       "         [45, 45, 45, 45],\n",
       "         [48, 48, 48, 48],\n",
       "         [56, 56, 56, 56]],\n",
       "\n",
       "        [[ 2,  2,  2,  2],\n",
       "         [15, 15, 15, 15],\n",
       "         [22, 22, 22, 22],\n",
       "         [27, 27, 27, 27],\n",
       "         [33, 33, 33, 33],\n",
       "         [46, 46, 46, 46],\n",
       "         [52, 52, 52, 52],\n",
       "         [62, 62, 62, 62]],\n",
       "\n",
       "        [[ 0,  0,  0,  0],\n",
       "         [ 9,  9,  9,  9],\n",
       "         [21, 21, 21, 21],\n",
       "         [31, 31, 31, 31],\n",
       "         [37, 37, 37, 37],\n",
       "         [42, 42, 42, 42],\n",
       "         [55, 55, 55, 55],\n",
       "         [59, 59, 59, 59]],\n",
       "\n",
       "        [[ 5,  5,  5,  5],\n",
       "         [15, 15, 15, 15],\n",
       "         [17, 17, 17, 17],\n",
       "         [31, 31, 31, 31],\n",
       "         [34, 34, 34, 34],\n",
       "         [43, 43, 43, 43],\n",
       "         [55, 55, 55, 55],\n",
       "         [58, 58, 58, 58]],\n",
       "\n",
       "        [[ 1,  1,  1,  1],\n",
       "         [10, 10, 10, 10],\n",
       "         [16, 16, 16, 16],\n",
       "         [29, 29, 29, 29],\n",
       "         [39, 39, 39, 39],\n",
       "         [45, 45, 45, 45],\n",
       "         [51, 51, 51, 51],\n",
       "         [59, 59, 59, 59]],\n",
       "\n",
       "        [[ 5,  5,  5,  5],\n",
       "         [11, 11, 11, 11],\n",
       "         [19, 19, 19, 19],\n",
       "         [25, 25, 25, 25],\n",
       "         [36, 36, 36, 36],\n",
       "         [43, 43, 43, 43],\n",
       "         [54, 54, 54, 54],\n",
       "         [63, 63, 63, 63]],\n",
       "\n",
       "        [[ 7,  7,  7,  7],\n",
       "         [12, 12, 12, 12],\n",
       "         [23, 23, 23, 23],\n",
       "         [25, 25, 25, 25],\n",
       "         [38, 38, 38, 38],\n",
       "         [40, 40, 40, 40],\n",
       "         [48, 48, 48, 48],\n",
       "         [61, 61, 61, 61]],\n",
       "\n",
       "        [[ 2,  2,  2,  2],\n",
       "         [14, 14, 14, 14],\n",
       "         [17, 17, 17, 17],\n",
       "         [27, 27, 27, 27],\n",
       "         [34, 34, 34, 34],\n",
       "         [42, 42, 42, 42],\n",
       "         [51, 51, 51, 51],\n",
       "         [56, 56, 56, 56]],\n",
       "\n",
       "        [[ 6,  6,  6,  6],\n",
       "         [12, 12, 12, 12],\n",
       "         [19, 19, 19, 19],\n",
       "         [30, 30, 30, 30],\n",
       "         [37, 37, 37, 37],\n",
       "         [42, 42, 42, 42],\n",
       "         [54, 54, 54, 54],\n",
       "         [61, 61, 61, 61]]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peak_indices.unsqueeze(-1).expand(-1,-1,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a72d23e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0,\n",
       "         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "         0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1],\n",
       "        [0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "         1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0,\n",
       "         1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0],\n",
       "        [0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "         0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "         0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0,\n",
       "         0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0,\n",
       "         1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1],\n",
       "        [0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1,\n",
       "         1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
       "         0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "         0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0],\n",
       "        [1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0,\n",
       "         0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1],\n",
       "        [0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1,\n",
       "         0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "         1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0],\n",
       "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1],\n",
       "        [0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0,\n",
       "         0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n",
       "         1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.where(peak >= peak_values.min(dim=1)[0].unsqueeze(-1).expand(-1,peak.size(1)), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "414c8474",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0,\n",
       "         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "         0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0],\n",
       "        [0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "         1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0,\n",
       "         1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0],\n",
       "        [0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "         0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "         0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0,\n",
       "         0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0,\n",
       "         1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0],\n",
       "        [0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1,\n",
       "         1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
       "         0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "         0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0],\n",
       "        [1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0,\n",
       "         0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0],\n",
       "        [0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1,\n",
       "         0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "         1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0],\n",
       "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "        [0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0,\n",
       "         0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n",
       "         1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_mask = torch.where(peak >= peak_values.min(dim=1)[0].unsqueeze(-1).expand(-1,peak.size(1)), 1, 0)\n",
    "nn.functional.pad(attention_mask, (0,1,0,0), mode='constant', value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "28765682",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6, 13, 22, 24, 32, 43, 49, 59],\n",
       "        [ 2, 12, 18, 31, 31, 45, 48, 56],\n",
       "        [ 7,  7, 15, 27, 33, 44, 52, 59],\n",
       "        [ 0, 11, 21, 31, 32, 42, 50, 61],\n",
       "        [ 6, 12, 15, 25, 36, 43, 53, 58],\n",
       "        [ 6, 12, 16, 26, 37, 45, 54, 56],\n",
       "        [ 0, 11, 20, 25, 36, 43, 49, 58],\n",
       "        [ 0, 12, 23, 23, 33, 42, 49, 61],\n",
       "        [ 2, 14, 17, 27, 34, 40, 51, 56],\n",
       "        [ 6, 12, 19, 30, 39, 42, 54, 61]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m(input_[:,:-1,-1] - input_[:,1:,-1])[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cf96d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ee55eda1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3,  8, 20, 24, 33, 42, 50, 58],\n",
       "        [ 3, 14, 19, 28, 37, 45, 55, 62],\n",
       "        [ 1, 11, 23, 31, 32, 47, 51, 59],\n",
       "        [ 6, 11, 23, 28, 35, 46, 49, 56],\n",
       "        [ 5, 11, 22, 31, 36, 42, 55, 61],\n",
       "        [ 0,  9, 20, 26, 36, 41, 50, 59],\n",
       "        [ 3, 14, 23, 24, 35, 44, 54, 56],\n",
       "        [ 7, 12, 22, 30, 38, 41, 55, 61],\n",
       "        [ 2, 12, 16, 28, 35, 47, 50, 60],\n",
       "        [ 1, 12, 23, 31, 32, 42, 53, 59]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = nn.AdaptiveMaxPool1d(8, return_indices=True)\n",
    "input_ = torch.randn(10, 64, 5)\n",
    "output = m(input_[:,:,-1])\n",
    "peak_values, peak_indices = output\n",
    "peak_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2049abe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  8,  5,  1, 13,  2,  3,  5],\n",
       "        [ 4,  4,  3, 14,  4,  3,  9, 11],\n",
       "        [ 4,  9,  3,  2,  1,  2, 12,  8],\n",
       "        [12, 16, 14,  5, 15,  6, 13, 16],\n",
       "        [10, 16,  1, 12,  1,  9,  9,  3],\n",
       "        [14,  3,  4,  3,  3,  7,  4, 11],\n",
       "        [14, 12,  3, 13, 14, 15, 10,  1],\n",
       "        [ 9,  1,  3, 16,  0, 10,  4,  7],\n",
       "        [ 3, 16,  7, 15, 11, 11,  1,  1],\n",
       "        [11,  5,  6, 12, 12, 15, 10, 13]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = torch.LongTensor([[ 8,  2,  5,  9,  2,  0,  9, 10],\n",
    "                            [ 5,  6,  3, 12,  7, 15, 12, 11],\n",
    "                            [ 0,  2,  1,  2,  8, 14, 10, 13],\n",
    "                            [ 9,  1, 15, 10,  7, 13,  4,  1],\n",
    "                            [10,  2, 10,  1, 10,  1,  5,  5],\n",
    "                            [11, 16,  6, 15,  5, 15,  5, 12],\n",
    "                            [10, 11,  8,  7,  7,  9, 13,  8],\n",
    "                            [14,  4, 12, 11,  5, 10,  6,  2],\n",
    "                            [15, 14,  2,  3, 15,  2, 10, 16],\n",
    "                            [ 4, 15, 15, 15, 11, 16,  7,  3]])\n",
    "\n",
    "\n",
    "lm_logits = torch.randn(10, 8, 17) # batch: 3, seq: 6, vocab_size:17\n",
    "pred_label = torch.argmax(lm_logits[..., :, :], dim=2, keepdim=False)\n",
    "pred_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "652b62e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_label = torch.argmax(lm_logits[..., :, :], dim=2, keepdim=False)\n",
    "loss_peak = torch.binary_cross_entropy_with_logits(peak_values, (pred_label == labels).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a306dd24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.5564, 1.0822, 0.4509, 1.5788, 1.2846, 2.0580, 1.9542, 0.8372],\n",
       "        [1.5642, 1.9789, 0.2242, 1.8752, 1.5667, 1.0829, 1.8913, 0.2867],\n",
       "        [0.9234, 2.1745, 1.8493, 0.4190, 1.0391, 1.9315, 1.5220, 0.9571],\n",
       "        [1.8056, 2.6107, 1.9748, 1.8438, 2.0410, 1.5962, 2.3993, 2.3716],\n",
       "        [0.1479, 1.7636, 1.4761, 2.6316, 1.4447, 1.2865, 1.8241, 1.7405],\n",
       "        [1.3389, 2.1617, 2.5268, 1.3026, 1.3961, 0.9127, 1.3415, 1.1022],\n",
       "        [1.1832, 1.2295, 1.3042, 2.6070, 1.1620, 1.6475, 2.5005, 2.3029],\n",
       "        [2.2742, 1.3788, 1.9834, 1.3300, 1.7606, 0.1179, 1.7884, 0.9628],\n",
       "        [1.0106, 2.2729, 1.1003, 2.0958, 1.9864, 1.8831, 2.6114, 2.8641],\n",
       "        [1.3624, 1.9362, 0.7995, 1.0764, 1.7285, 1.7351, 1.7551, 1.0702]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_peak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f38b115c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.3195, 0.6684, 0.5625, 1.3478, 0.9606, 1.9214, 1.8014, 0.2700],\n",
       "        [1.3294, 1.8301, 1.3810, 1.7087, 1.3325, 0.6695, 1.7278, 1.1024],\n",
       "        [0.4172, 2.0538, 1.6781, 0.6531, 0.6025, 1.7749, 1.2758, 0.4726],\n",
       "        [1.6260, 2.5344, 1.8254, 1.6715, 1.9019, 1.3698, 2.3042, 2.2736],\n",
       "        [1.8360, 1.5756, 1.2166, 2.5569, 1.1758, 0.9633, 1.6481, 1.5476],\n",
       "        [1.0349, 2.0394, 2.4435, 0.9855, 1.1117, 0.3995, 1.0384, 0.6985],\n",
       "        [0.8175, 0.8836, 0.9875, 2.5304, 0.7867, 1.4337, 2.4149, 2.1976],\n",
       "        [2.1656, 1.0887, 1.8354, 1.0228, 1.5720, 2.0787, 1.6054, 0.4818],\n",
       "        [0.5580, 2.1642, 0.6957, 1.9646, 1.8388, 1.7181, 2.5351, 2.8054],\n",
       "        [1.0666, 1.7804, 0.2025, 0.6596, 1.5330, 1.5411, 1.5652, 0.6502]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peak_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "52ea35df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(pred_label == labels).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7baab439",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([[-0.3084,  1.6866,  1.6117,  0.9698,  2.0495,  1.3440,  0.9888,  1.4596,\n",
       "          1.4429,  0.8147,  0.0976,  2.0972,  1.5441,  1.0902,  1.5217,  1.2635,\n",
       "         -0.1483,  1.7322,  1.7627,  1.8031,  0.7477,  1.0680,  1.1418,  0.8647,\n",
       "          0.6536,  1.4081,  0.8071,  1.0107,  1.9388,  1.9420,  1.0947,  0.1482,\n",
       "          0.6699,  0.9300,  1.7979,  1.6813,  0.6532,  1.6796,  1.7580,  1.1983,\n",
       "          0.9506,  2.0081,  0.7722, -0.1044,  1.0084,  1.2638,  2.3838,  1.7721,\n",
       "          2.1871,  1.0712,  0.7853,  0.7914,  1.8280,  1.2325,  0.7129,  0.7750,\n",
       "          1.7624,  0.3088,  1.0490,  0.4446,  0.6047,  0.2575,  0.4435,  1.2036],\n",
       "        [ 1.0393,  1.0769,  0.5378,  2.7197,  0.5459,  0.4998,  0.2838,  0.7519,\n",
       "          0.2911,  0.9053,  1.5468,  0.5858,  1.0000,  1.0970,  1.0580,  0.9960,\n",
       "          0.8111,  0.6581,  0.5260,  0.7965, -0.1437,  2.2750,  1.7818,  1.0233,\n",
       "          1.1709,  1.0988,  0.1643,  0.7146, -0.6394,  1.7253,  1.9522,  0.3826,\n",
       "          0.4413,  1.2093,  1.3740,  1.1771,  1.0766,  1.3752,  1.3852,  1.1746,\n",
       "          1.4897,  0.8475,  2.0972,  1.0558,  0.3143,  2.3169,  0.6835,  0.5692,\n",
       "          0.9251,  1.6807,  1.2930,  2.4373,  1.1114,  0.6370,  1.1093,  0.8379,\n",
       "          1.5569,  2.1844, -0.1156,  1.9077,  0.3575,  1.2176,  0.7586,  0.7055],\n",
       "        [ 1.9861,  1.3416,  1.2395,  0.8268, -0.4805,  1.0011,  0.9076,  0.7820,\n",
       "          2.0478,  1.9179,  0.5706,  0.8699,  0.8644,  1.6271,  0.7395,  1.2514,\n",
       "          0.4871,  1.9884,  0.9520,  2.0947,  1.7152,  1.6835,  1.3302,  1.2699,\n",
       "          0.4575,  0.8940,  1.9361,  0.1176,  2.4919,  1.5195,  1.7051,  0.7202,\n",
       "          0.4555,  1.4547,  0.0543,  0.3815,  1.1826,  0.9739,  1.8462,  0.5207,\n",
       "          0.7692,  0.9993,  0.0557,  0.4151,  1.7892,  0.5201,  0.2719,  2.0297,\n",
       "          1.5029,  0.3953,  1.8304,  1.4318,  1.1250,  1.0195,  1.6193,  0.3668,\n",
       "          2.1285,  0.2974,  1.0887,  0.9613,  1.0311,  1.3790,  1.3817,  1.6515],\n",
       "        [ 1.0945,  1.0062,  2.3922,  2.1901,  1.6273,  1.1519,  2.8024,  1.3312,\n",
       "          0.6634,  1.0324,  1.0233,  0.1079,  1.7187,  0.6426,  0.7630,  1.6486,\n",
       "          0.7409, -0.0506,  0.2659,  0.4306,  0.7722,  1.1680,  2.3247,  0.4503,\n",
       "          2.3246,  2.2396,  1.4815,  0.1744,  0.8029,  1.0668,  1.6030,  1.5642,\n",
       "          0.8034,  1.6121,  2.2798,  1.9342,  0.8040,  0.3270,  1.4123,  1.3224,\n",
       "          0.7775,  1.1376,  1.5587,  1.9008,  0.9835,  1.2407,  1.2007,  1.3531,\n",
       "          1.6247,  0.9265,  1.8034,  0.6925,  1.5048,  0.6989,  1.0761,  0.3936,\n",
       "          2.3598,  1.0789,  0.9702,  2.0008,  1.3892,  1.2915,  1.8092,  0.0919],\n",
       "        [ 1.5471,  1.4647,  1.0829,  1.5649,  1.7330,  0.4989,  0.5597,  1.1362,\n",
       "          1.0595,  1.5144,  1.1518,  0.2941,  0.7827,  0.3327,  1.0247,  0.5870,\n",
       "          1.2531,  1.4383,  1.0338,  0.7405,  0.7616,  0.6269,  1.9981,  1.3901,\n",
       "          3.0233,  1.0855,  1.2041,  0.9366,  1.1239,  1.5335,  0.7067,  2.8176,\n",
       "          2.3162,  0.4388,  1.1234,  1.1569,  0.7131,  1.5055,  1.0422,  1.3628,\n",
       "          1.0483,  1.2457, -0.3161,  0.3949,  2.0446,  2.0300,  0.2943,  0.5726,\n",
       "          1.1746,  0.1247,  1.1271,  3.1578,  0.7082,  0.1621,  1.2764,  1.0510,\n",
       "          1.0129,  1.3644,  0.2950,  1.7571,  1.6216,  1.2184,  2.2744,  0.8339],\n",
       "        [ 1.2653,  2.4368,  1.0170,  1.5466,  1.5899, -0.1043,  1.9764,  1.6342,\n",
       "          1.8529,  1.1317, -0.0953,  1.1623,  1.2317,  1.7953,  1.3021,  1.9349,\n",
       "          1.8240,  1.9447,  0.3331,  0.6325,  1.5386,  0.9998,  1.0179,  1.1860,\n",
       "          1.1192,  0.7048,  1.9873,  0.5614,  0.3847,  1.3025,  0.9415,  1.0108,\n",
       "          1.3044,  1.7255,  1.2083,  1.9521,  1.0221,  0.7122,  1.4780,  0.5846,\n",
       "          1.2526,  1.5005,  0.6442,  1.9018,  1.6009,  0.7526,  1.0694,  1.0553,\n",
       "          0.9881,  1.3968,  1.7511,  1.9424, -0.6322,  0.5438,  0.8069,  1.9343,\n",
       "          0.2358,  1.0369,  1.7842,  0.6005,  1.2305,  0.5928,  0.9879,  1.2512],\n",
       "        [ 0.8890,  1.2843,  1.1969,  1.1654,  1.0826,  1.1027,  2.4936,  1.1413,\n",
       "          0.6835,  1.2313,  1.0784,  1.4433,  1.1426,  1.5855,  1.6572,  1.2595,\n",
       "          1.8166,  1.6045,  0.8040,  2.0966,  0.8996,  0.9670,  0.5184,  0.4522,\n",
       "          0.6633,  2.0671,  0.5627,  1.0789,  0.1886,  0.7456,  2.0315,  1.8980,\n",
       "          1.0864,  0.1670,  1.1933,  1.5948,  0.4373,  1.4477,  1.4902,  1.0087,\n",
       "          1.5570,  0.5552,  0.3128,  2.0482,  2.0603,  1.3412,  0.6072,  1.2490,\n",
       "          1.2997,  0.3951,  0.7603,  0.4949,  1.1920,  1.5288,  0.5502,  1.9260,\n",
       "          1.0354,  1.5374,  1.6575,  2.1099,  2.6098,  1.9699,  1.1271,  1.1745],\n",
       "        [ 0.1999,  0.4485,  1.6889,  0.2660,  1.2901,  1.5362, -0.5306,  2.6084,\n",
       "          1.4594,  0.8609,  1.0782,  1.0494,  1.0043,  0.7249,  0.9263,  1.7941,\n",
       "          0.9738,  0.6395,  1.2736,  1.9527,  0.9044,  0.7887,  1.3529,  1.2471,\n",
       "          1.6700,  2.0392,  1.2068,  1.3423,  0.6717,  0.5980,  1.2720,  0.4039,\n",
       "          0.9442,  1.2193,  0.9572,  2.1129,  0.9353,  0.8443,  0.7645,  1.1239,\n",
       "          1.4119,  1.1072,  2.8822,  1.0024,  0.8535,  1.8017,  1.3307,  0.4507,\n",
       "          0.3912,  1.3597,  2.4348,  0.7757,  0.8027,  0.5553,  1.1264,  1.3671,\n",
       "          0.2785,  0.5081,  1.3093,  1.2247,  1.1825,  0.4200,  2.0032,  1.5323],\n",
       "        [ 1.7340,  0.4547,  0.2981,  0.9416,  0.3004,  0.5294,  0.7282,  1.1262,\n",
       "          0.5319,  2.3862,  1.7362,  0.7952,  1.8955,  1.8620,  2.2580,  1.9571,\n",
       "          0.8058,  0.9507,  0.7690,  1.8487,  1.4127,  1.4202,  0.9217,  1.7501,\n",
       "          2.0524,  0.4177,  2.2727,  0.6318,  0.8883,  2.0513,  0.0731,  0.5394,\n",
       "          0.8967,  0.5449,  0.2853,  0.6527,  0.5885,  0.8337,  1.6002,  0.9613,\n",
       "          2.2387,  0.6866,  2.1649,  0.2007,  1.1203,  0.4909,  0.5163,  0.4134,\n",
       "          0.4961,  0.6748,  1.3330,  2.2337,  0.8609,  1.0837,  0.9672,  1.1039,\n",
       "          0.6350,  1.0532,  1.1092,  0.5865,  1.2764,  1.0592,  1.6374,  0.5900],\n",
       "        [ 1.7679,  1.7622,  1.3682,  0.0411,  0.7587,  1.7762,  0.5820,  0.6971,\n",
       "          2.2353,  1.1770,  1.3823,  2.6549,  0.5783,  2.5704,  2.0743,  0.9243,\n",
       "          1.1742,  1.1494,  0.9385,  1.6230,  2.1391,  0.9881,  1.6707,  1.5979,\n",
       "          0.1670,  0.2609,  1.9786,  1.6918,  1.2227,  2.1361,  0.0927,  0.5441,\n",
       "          1.6848,  2.5868,  1.5492, -0.0207,  0.8580,  2.3355,  1.0924,  0.0414,\n",
       "          2.0236,  0.5669,  1.2797,  1.1743,  0.8664,  0.1963,  1.4317, -0.2274,\n",
       "          0.8047,  0.1038, -0.2493,  0.6099,  1.3527,  1.1680,  0.4665,  1.2990,\n",
       "          2.1231,  1.3994,  1.4071,  1.1668,  0.5797,  1.4202,  0.4650,  1.7624]]),\n",
       "indices=tensor([[1, 4, 3, 1, 0, 1, 4, 0, 3, 3, 4, 1, 0, 4, 1, 1, 3, 1, 2, 2, 3, 2, 2, 4,\n",
       "         3, 3, 0, 0, 1, 3, 3, 0, 2, 3, 4, 4, 4, 1, 2, 2, 2, 0, 0, 0, 2, 3, 0, 0,\n",
       "         1, 3, 0, 3, 0, 1, 1, 0, 1, 4, 2, 2, 3, 4, 2, 0],\n",
       "        [1, 2, 4, 0, 0, 2, 1, 0, 4, 2, 2, 1, 1, 4, 4, 1, 2, 4, 1, 0, 4, 3, 4, 2,\n",
       "         1, 0, 0, 4, 3, 2, 1, 0, 1, 2, 1, 0, 4, 4, 3, 4, 4, 0, 2, 4, 0, 0, 0, 4,\n",
       "         1, 0, 3, 3, 2, 0, 0, 1, 4, 0, 2, 3, 3, 0, 0, 3],\n",
       "        [2, 4, 4, 1, 1, 3, 0, 3, 1, 2, 0, 2, 3, 1, 1, 3, 0, 2, 1, 1, 0, 0, 4, 3,\n",
       "         4, 0, 3, 3, 4, 1, 0, 2, 1, 3, 3, 0, 2, 0, 1, 0, 3, 2, 0, 1, 4, 1, 3, 4,\n",
       "         4, 4, 1, 0, 3, 4, 4, 1, 3, 3, 4, 0, 2, 1, 3, 4],\n",
       "        [0, 0, 2, 0, 3, 3, 1, 4, 1, 4, 1, 3, 1, 1, 0, 2, 4, 4, 1, 4, 3, 0, 2, 3,\n",
       "         3, 3, 3, 1, 3, 4, 3, 0, 4, 3, 1, 0, 4, 0, 2, 1, 0, 4, 0, 4, 2, 3, 2, 1,\n",
       "         0, 2, 3, 0, 4, 0, 1, 1, 4, 4, 1, 3, 0, 3, 2, 3],\n",
       "        [1, 2, 4, 1, 0, 3, 0, 2, 3, 4, 4, 3, 0, 4, 2, 2, 2, 2, 3, 1, 4, 1, 2, 4,\n",
       "         4, 1, 0, 3, 4, 2, 2, 0, 1, 1, 0, 1, 0, 2, 2, 3, 4, 1, 3, 1, 1, 1, 3, 3,\n",
       "         3, 2, 1, 0, 4, 3, 3, 0, 4, 2, 0, 2, 2, 0, 1, 1],\n",
       "        [3, 0, 4, 3, 1, 1, 1, 0, 0, 0, 2, 0, 2, 3, 3, 4, 0, 0, 1, 0, 1, 1, 4, 4,\n",
       "         0, 1, 4, 4, 3, 1, 1, 4, 0, 3, 1, 2, 4, 1, 0, 0, 1, 4, 1, 2, 4, 0, 0, 4,\n",
       "         3, 2, 4, 1, 3, 4, 0, 3, 4, 4, 3, 0, 0, 4, 2, 0],\n",
       "        [2, 4, 1, 2, 1, 4, 3, 0, 4, 2, 2, 4, 0, 0, 3, 0, 1, 3, 1, 2, 3, 0, 0, 4,\n",
       "         3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 3, 1, 1, 3, 3, 1, 2, 1, 1, 3, 1, 2, 3,\n",
       "         0, 4, 3, 2, 0, 1, 1, 3, 3, 4, 4, 0, 0, 0, 1, 2],\n",
       "        [3, 1, 2, 3, 4, 1, 4, 4, 4, 0, 2, 4, 3, 2, 4, 3, 2, 0, 3, 2, 3, 4, 2, 3,\n",
       "         2, 0, 0, 3, 1, 3, 0, 0, 0, 1, 0, 1, 4, 1, 1, 2, 3, 2, 3, 4, 4, 1, 0, 4,\n",
       "         1, 0, 3, 2, 2, 0, 1, 0, 2, 3, 2, 1, 1, 4, 1, 1],\n",
       "        [4, 4, 1, 0, 0, 1, 0, 3, 0, 0, 0, 2, 4, 0, 1, 0, 0, 0, 0, 3, 2, 1, 0, 2,\n",
       "         3, 4, 1, 4, 1, 1, 0, 0, 4, 4, 0, 1, 4, 2, 1, 0, 2, 2, 3, 1, 2, 3, 1, 1,\n",
       "         4, 1, 2, 0, 0, 4, 1, 1, 1, 2, 4, 1, 2, 4, 2, 1],\n",
       "        [1, 2, 1, 1, 0, 4, 4, 3, 3, 3, 2, 3, 0, 4, 2, 2, 0, 0, 4, 4, 4, 1, 3, 1,\n",
       "         2, 0, 2, 2, 4, 0, 3, 4, 2, 3, 0, 2, 0, 4, 0, 0, 3, 1, 4, 2, 3, 3, 3, 1,\n",
       "         3, 1, 1, 2, 1, 1, 2, 0, 3, 4, 1, 3, 2, 2, 1, 2]]))"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_logits = torch.randn(10, 64, 5)\n",
    "lm_logits.max(axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a8125513",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim, _ = nn.functional.softmax(lm_logits, dim=-1).max(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "cf0c75c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.6371, 0.7113, 0.6539, 0.6658, 0.4832, 0.6810, 0.6999, 0.4940],\n",
       "         [0.6886, 0.6154, 0.6660, 0.5265, 0.5434, 0.6740, 0.7728, 0.8885],\n",
       "         [0.7297, 0.5439, 0.6158, 0.7085, 0.6764, 0.6120, 0.5101, 0.6644],\n",
       "         [0.8776, 0.5991, 0.4408, 0.8313, 0.5794, 0.6011, 0.6572, 0.6787],\n",
       "         [0.5990, 0.5281, 0.6563, 0.8818, 0.5611, 0.6509, 0.8271, 0.7608],\n",
       "         [0.5532, 0.7141, 0.7272, 0.7706, 0.6315, 0.6421, 0.6944, 0.6903],\n",
       "         [0.6303, 0.5447, 0.6154, 0.7218, 0.6062, 0.7099, 0.5324, 0.7870],\n",
       "         [0.7313, 0.6444, 0.6772, 0.6342, 0.8451, 0.7391, 0.6177, 0.6599],\n",
       "         [0.4756, 0.6944, 0.5924, 0.7056, 0.5227, 0.7739, 0.5577, 0.5017],\n",
       "         [0.5419, 0.7659, 0.8067, 0.7036, 0.7211, 0.5651, 0.4744, 0.5982]]),\n",
       " tensor([[ 1, 14, 19, 28, 35, 41, 48, 56],\n",
       "         [ 3, 10, 21, 30, 34, 42, 51, 57],\n",
       "         [ 0, 13, 20, 28, 38, 44, 50, 61],\n",
       "         [ 6, 12, 22, 24, 33, 41, 48, 56],\n",
       "         [ 2, 10, 19, 24, 32, 45, 51, 62],\n",
       "         [ 6, 11, 16, 26, 33, 43, 51, 58],\n",
       "         [ 6, 13, 16, 25, 37, 43, 48, 60],\n",
       "         [ 2, 10, 22, 26, 35, 42, 50, 63],\n",
       "         [ 3, 14, 19, 26, 38, 42, 51, 58],\n",
       "         [ 0, 11, 19, 29, 32, 40, 55, 63]]))"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adaPool = nn.AdaptiveMaxPool1d(8, return_indices=True)\n",
    "peak_values, peak_indices = adaPool(sim)\n",
    "peak_values, peak_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "bf441f2c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# torch.gather(lm_logits, \n",
    "#            1, \n",
    "#            peak_indices.unsqueeze(-1).expand(-1,-1,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "5c59b83f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7113, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim, _ = nn.functional.softmax(lm_logits, dim=-1).max(dim=-1)\n",
    "nn.functional.threshold(sim, 0.7, 0.0, inplace=False)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ea29f725",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1, 14, 19, 28, 32, 41, 48, 56],\n",
       "        [ 3, 10, 21, 30, 34, 42, 51, 57],\n",
       "        [ 0, 13, 20, 28, 38, 44, 50, 61],\n",
       "        [ 6, 12, 16, 24, 33, 41, 48, 56],\n",
       "        [ 2, 10, 19, 24, 32, 45, 51, 62],\n",
       "        [ 6, 11, 16, 26, 33, 43, 51, 58],\n",
       "        [ 6, 13, 16, 25, 37, 43, 48, 60],\n",
       "        [ 2, 10, 22, 26, 35, 42, 50, 63],\n",
       "        [ 0, 14, 19, 26, 38, 42, 51, 58],\n",
       "        [ 0, 11, 19, 29, 32, 40, 48, 63]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim, _ = nn.functional.softmax(lm_logits, dim=-1).max(dim=-1)\n",
    "sim = nn.functional.threshold(sim, 0.5, 0.0, inplace=False)\n",
    "_, peak_indices = adaPool(sim)\n",
    "peak_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "88f7df98",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labels = torch.LongTensor([[ 8,  2,  5,  9,  2,  0,  9, 10],\n",
    "                            [ 5,  6,  3, 12,  7, 15, 12, 11],\n",
    "                            [ 0,  2,  1,  2,  8, 14, 10, 13],\n",
    "                            [ 9,  1, 15, 10,  7, 13,  4,  1],\n",
    "                            [10,  2, 10,  1, 10,  1,  5,  5],\n",
    "                            [11, 16,  6, 15,  5, 15,  5, 12],\n",
    "                            [10, 11,  8,  7,  7,  9, 13,  8],\n",
    "                            [14,  4, 12, 11,  5, 10,  6,  2],\n",
    "                            [15, 14,  2,  3, 15,  2, 10, 16],\n",
    "                            [ 4, 15, 15, 15, 11, 16,  7,  3]])\n",
    "output_attention_mask = torch.ones((10, 8)).long()\n",
    "\n",
    "\n",
    "hidden_states = torch.randn(10, 8, 17) # batch: 3, seq: 8, vocab_size:17\n",
    "\n",
    "cos = nn.CosineSimilarity(dim=2, eps=1e-10)\n",
    "peak = -cos(hidden_states[:,:-1,:], hidden_states[:,1:,:])\n",
    "\n",
    "\n",
    "peak_min, threshold, peak_max = -1.0, -0.25, 1.0\n",
    "_, peak_indices = adaPool(nn.functional.threshold(peak, threshold, -1.0, inplace=False))\n",
    "peak_values = torch.gather(peak, 1, peak_indices)\n",
    "\n",
    "attention_mask = torch.ones_like(peak_indices, dtype=torch.long)\n",
    "word_embeddings = torch.gather(hidden_states, \n",
    "                               1, \n",
    "                               peak_indices.unsqueeze(-1).expand(-1,-1,8))\n",
    "\n",
    "\n",
    "# ctc_loss doesn't support fp16\n",
    "log_probs = nn.functional.log_softmax(lm_logits, dim=-1, dtype=torch.float32).transpose(0, 1)\n",
    "\n",
    "# input_lengths for ctc_loss is defined from RNN peak detection\n",
    "# this can be computed from attention_mask\n",
    "input_lengths = (attention_mask > 0).sum(-1)\n",
    "\n",
    "# assuming that padded tokens are filled with 'Ä '\n",
    "# unlike wav2vec we can get this information from given `output_attention_mask`\n",
    "labels_mask = (output_attention_mask > 0)\n",
    "target_lengths = labels_mask.sum(-1)\n",
    "flattened_targets = labels.masked_select(labels_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ba0d912e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3548,  0.8480,  0.4208, -0.6502,  0.9330, -0.7001,  0.3314],\n",
       "        [-0.1190, -0.0275, -0.7941, -0.4843,  0.2176,  0.3056, -0.9596],\n",
       "        [ 0.6437, -0.3768,  0.9237, -0.1813,  0.0356, -0.8298,  0.6685],\n",
       "        [ 0.6288,  0.4490, -0.8141, -0.2252,  0.6019, -0.7261,  0.8757],\n",
       "        [ 0.3766,  0.8873,  0.1857,  0.3498,  0.8676,  0.6045, -0.4825],\n",
       "        [-0.9401,  0.9193, -0.3107,  0.6471, -0.6423,  0.4934,  0.4392],\n",
       "        [ 0.3144,  0.5935, -0.0865,  0.5704, -0.6300, -0.1896, -0.7666],\n",
       "        [ 0.5708, -0.9884, -0.7868, -0.4532,  0.1233, -0.1323, -0.9159],\n",
       "        [-0.0072,  0.7856,  0.9706,  0.7489,  0.9466, -0.9137, -0.3940],\n",
       "        [ 0.7473, -0.6074,  0.1333, -0.4574, -0.1543,  0.1005,  0.0726]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_arr = peak_max - torch.rand_like(peak) * (peak_max - peak_min)\n",
    "rand_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "2cfd032e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.where(peak > threshold, peak, rand_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "44e59d69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1229, -0.0396,  0.3921, -0.2500,  0.3867,  0.0039, -0.0321],\n",
       "        [-0.0282, -0.2500,  0.3161,  0.4024,  0.0742, -0.2500, -0.1672],\n",
       "        [-0.0058, -0.0945,  0.2487, -0.1499,  0.1145,  0.2011, -0.0524],\n",
       "        [ 0.1907, -0.0431,  0.4695,  0.2039,  0.1798,  0.0318,  0.0404],\n",
       "        [ 0.2051,  0.1577, -0.1642,  0.0759,  0.2468, -0.1419, -0.2500],\n",
       "        [-0.2324,  0.4086,  0.4125, -0.1460,  0.0885,  0.2838,  0.6216],\n",
       "        [-0.1122,  0.0922, -0.1890, -0.0562, -0.0470, -0.0623, -0.0124],\n",
       "        [ 0.1594,  0.0877, -0.2289, -0.0031, -0.0841,  0.1639,  0.0617],\n",
       "        [ 0.0471,  0.0532, -0.0881, -0.0063,  0.0418,  0.2988, -0.2500],\n",
       "        [-0.1040,  0.2068, -0.2350, -0.2285,  0.3139,  0.0658, -0.2418]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.where(peak > threshold, peak, torch.tensor(threshold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "afc0813b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  8,   2,   5,   9,   2,   0,   9,  10, 220],\n",
       "        [  5,   6,   3,  12,   7,  15,  12,  11, 220],\n",
       "        [  0,   2,   1,   2,   8,  14,  10,  13, 220],\n",
       "        [  9,   1,  15,  10,   7,  13,   4,   1, 220],\n",
       "        [ 10,   2,  10,   1,  10,   1,   5,   5, 220],\n",
       "        [ 11,  16,   6,  15,   5,  15,   5,  12, 220],\n",
       "        [ 10,  11,   8,   7,   7,   9,  13,   8, 220],\n",
       "        [ 14,   4,  12,  11,   5,  10,   6,   2, 220],\n",
       "        [ 15,  14,   2,   3,  15,   2,  10,  16, 220],\n",
       "        [  4,  15,  15,  15,  11,  16,   7,   3, 220]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.ConstantPad2d((0,1,0,0), 220)(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5f0e4605",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.0000,  0.0124,  0.1436,  0.0238, -1.0000, -1.0000, -1.0000],\n",
       "        [-1.0000, -1.0000,  0.2761, -1.0000,  0.0731, -1.0000, -1.0000],\n",
       "        [-1.0000,  0.3042,  0.0478, -1.0000,  0.3929, -1.0000,  0.3497],\n",
       "        [-1.0000,  0.3853,  0.1831, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "        [ 0.0465, -1.0000, -1.0000, -1.0000,  0.1183,  0.0150, -1.0000],\n",
       "        [-1.0000, -1.0000,  0.1123,  0.2518,  0.1331,  0.2686,  0.0612],\n",
       "        [-1.0000,  0.4496, -1.0000,  0.2583,  0.0453, -1.0000, -1.0000],\n",
       "        [ 0.1515,  0.3197,  0.3587,  0.0873, -1.0000,  0.1120, -1.0000],\n",
       "        [-1.0000,  0.1219,  0.1486, -1.0000,  0.2875, -1.0000, -1.0000],\n",
       "        [-1.0000, -1.0000,  0.1007, -1.0000,  0.4980, -1.0000, -1.0000]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.functional.threshold(peak, threshold, -1.0, inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "03da7eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ctcloss_reference(log_probs, targets, input_lengths, target_lengths, blank=0, reduction='mean'):\n",
    "    input_lengths = torch.as_tensor(input_lengths, dtype=torch.long)\n",
    "    target_lengths = torch.as_tensor(target_lengths, dtype=torch.long)\n",
    "    dt = log_probs.dtype\n",
    "    log_probs = log_probs.double()  # we need the accuracy as we are not in logspace\n",
    "    targets = targets.long()\n",
    "    cum_target_lengths = target_lengths.cumsum(0)\n",
    "    losses = []\n",
    "    for i in range(log_probs.size(1)):\n",
    "        input_length = input_lengths[i].item()\n",
    "        target_length = target_lengths[i].item()\n",
    "        cum_target_length = cum_target_lengths[i].item()\n",
    "        # ==========================================================================================================\n",
    "        targets_prime = targets.new_full((2 * target_length + 1,), blank)\n",
    "        if targets.dim() == 2:\n",
    "            targets_prime[1::2] = targets[i, :target_length]\n",
    "        else:\n",
    "            targets_prime[1::2] = targets[cum_target_length - target_length:cum_target_length]\n",
    "        # ==========================================================================================================\n",
    "        probs = log_probs[:input_length, i].exp()\n",
    "        # ==========================================================================================================\n",
    "        alpha = log_probs.new_zeros((target_length * 2 + 1,))\n",
    "        alpha[0] = probs[0, blank]\n",
    "        alpha[1] = probs[0, targets_prime[1]]\n",
    "        mask_third = (targets_prime[:-2] != targets_prime[2:])\n",
    "        for t in range(1, input_length):\n",
    "            alpha_next = alpha.clone()\n",
    "            alpha_next[1:] += alpha[:-1]\n",
    "            alpha_next[2:] += torch.where(mask_third, alpha[:-2], alpha.new_zeros(1))\n",
    "            alpha = probs[t, targets_prime] * alpha_next\n",
    "        # ==========================================================================================================\n",
    "        print(alpha)\n",
    "        \n",
    "        losses.append(-alpha[-2:].sum().log()[None])\n",
    "    output = torch.cat(losses, 0)\n",
    "    if reduction == 'mean':\n",
    "        return (output / target_lengths.to(dtype=output.dtype, device=output.device)).mean()\n",
    "    elif reduction == 'sum':\n",
    "        return output.sum()\n",
    "    output = output.to(dt)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "efcd4633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4.6589e-13, 1.6884e-11, 9.3202e-12, 3.2218e-10, 1.3834e-10, 1.5293e-10,\n",
      "        5.2490e-10, 7.1434e-09, 3.2774e-09, 2.3075e-08, 4.9640e-09, 5.1073e-09,\n",
      "        1.4381e-10, 4.1844e-10, 5.6487e-13, 2.3971e-12, 0.0000e+00],\n",
      "       dtype=torch.float64)\n",
      "tensor([4.8645e-13, 4.2530e-11, 6.4957e-11, 3.4620e-10, 1.7610e-10, 3.1341e-10,\n",
      "        2.4851e-10, 2.1682e-10, 3.6141e-10, 5.3372e-09, 6.6471e-10, 5.8048e-09,\n",
      "        4.0460e-10, 2.2505e-10, 2.1111e-12, 2.7577e-12, 0.0000e+00],\n",
      "       dtype=torch.float64)\n",
      "tensor([1.0181e-13, 8.1449e-13, 2.8507e-12, 3.4741e-11, 1.3328e-10, 1.2749e-09,\n",
      "        3.1996e-10, 5.0960e-10, 1.0174e-09, 2.0520e-09, 2.3318e-09, 7.9496e-09,\n",
      "        3.3101e-10, 2.4294e-10, 6.2279e-13, 7.6347e-13, 0.0000e+00],\n",
      "       dtype=torch.float64)\n",
      "tensor([3.1852e-11, 1.9054e-11, 7.7957e-10, 5.4160e-09, 1.7177e-08, 1.4399e-08,\n",
      "        4.9155e-08, 6.6351e-08, 3.9770e-08, 2.2864e-07, 3.0181e-08, 1.2573e-08,\n",
      "        2.2648e-09, 1.7391e-09, 1.0833e-11, 5.0595e-11, 0.0000e+00],\n",
      "       dtype=torch.float64)\n",
      "tensor([3.1528e-11, 2.5385e-11, 1.0620e-09, 8.3943e-10, 1.0308e-08, 8.1120e-09,\n",
      "        3.8481e-09, 1.3478e-09, 2.9450e-09, 2.2283e-09, 4.6068e-10, 1.4372e-10,\n",
      "        6.1174e-11, 4.9439e-11, 2.1158e-12, 0.0000e+00, 0.0000e+00],\n",
      "       dtype=torch.float64)\n",
      "tensor([2.0558e-10, 5.6551e-10, 1.0752e-08, 1.6600e-09, 2.3069e-08, 2.4511e-09,\n",
      "        3.8442e-08, 3.6880e-09, 6.6893e-09, 3.5661e-09, 5.1142e-09, 4.8411e-10,\n",
      "        5.6475e-10, 1.9447e-10, 1.9473e-11, 1.8131e-12, 0.0000e+00],\n",
      "       dtype=torch.float64)\n",
      "tensor([1.8256e-11, 5.7215e-10, 3.5079e-09, 3.3015e-09, 5.2762e-08, 4.1711e-08,\n",
      "        2.2894e-07, 2.1913e-07, 1.1940e-07, 1.3354e-08, 9.3012e-11, 1.2691e-10,\n",
      "        3.2879e-12, 5.2935e-13, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "       dtype=torch.float64)\n",
      "tensor([2.0681e-11, 7.5816e-11, 1.4488e-10, 8.3379e-10, 2.3037e-09, 3.0559e-09,\n",
      "        1.2238e-08, 1.5140e-08, 1.7364e-09, 6.5445e-10, 8.0651e-12, 9.4295e-12,\n",
      "        1.1312e-12, 5.4087e-13, 1.7638e-13, 7.3857e-13, 0.0000e+00],\n",
      "       dtype=torch.float64)\n",
      "tensor([2.6752e-11, 4.1416e-10, 9.4753e-10, 7.6938e-10, 1.2740e-08, 5.9287e-09,\n",
      "        1.4155e-08, 2.3019e-09, 1.2814e-08, 2.1417e-08, 1.8601e-08, 4.9054e-09,\n",
      "        4.9689e-10, 1.7497e-11, 2.8982e-11, 3.5268e-12, 0.0000e+00],\n",
      "       dtype=torch.float64)\n",
      "tensor([2.2034e-12, 5.2046e-12, 4.1134e-11, 1.6774e-09, 3.5054e-10, 1.4931e-09,\n",
      "        2.8088e-10, 3.2341e-10, 3.9314e-11, 2.1617e-11, 5.1659e-12, 5.0176e-12,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "       dtype=torch.float64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(inf, dtype=torch.float64)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctcloss_reference(log_probs, flattened_targets, input_lengths, target_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a168d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f498516",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b802d7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "41fd08bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from transformers import GPT2Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "82b6d927",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_dir = \"/data4/yoomcache\"\n",
    "model_cache_dir = os.path.join(cache_dir, 'huggingface')\n",
    "data_cache_dir = os.path.join(cache_dir, 'datasets')\n",
    "checkpoint_dir = os.path.join(cache_dir, 'checkpoint')\n",
    "\n",
    "wav2vec_pretrained = \"facebook/wav2vec2-base\"\n",
    "gpt_pretrained = \"gpt2\"\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(gpt_pretrained,\n",
    "                                          cache_dir=model_cache_dir,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a024247",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decoder[50256]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cebfdb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = [379,287,319,281,329,355,326,838,284,1315,1105,416,642,807,554,351,257,1160,718,1478,767,1367,1511,1542,1467,604,286,422,340,1440,428,1115,2534,362,290,1936,357,352,2237,1679,1081,632,2319,318,706,513,2608,1596,407,307,860,2026,477,2242,1811,468,530,383,475,644,393,555,1114,3624,262,517,2681,678,787,373,2579,618,2048,651,770,734,818,1248,3439,3598,466,198,423,4570,510,314,3016,389,1675,2808,4747,317,460,1629,1867,3126,5193,4353,503,625,1002,550,464,345,1577,587,465,1987,1550,4153,4974,1234,836,5996,1318,6073,2310,4317,561,4019,887,347,5214,523,5441,1320,657,843,350,857,1802,939,655,5867,546,511,5433,925,481,327,1026,1011,1141,309,777,256,3412,5946,5137,467,7265,883,1406,1729,617,285,339,5846,3933,2263,356,6640,5014,612,1212,921,845,337,3261,4457,6337,275,6135,547,366,1972,1838,1649,1890,311,645,376,360,663,367,406,739,1892,2293,2953,1052,6298,611,7632,7175,279,300,2080,5365,7982,9796,703,371,534,597,775,1642,8190,7618,7600,269,867,4764,402,8646,743,1394,288,569,1595,8093,750,1342,5021,1029,2893,1402,1016,8454,878,6740,532,4101,6454,374,714,1858,399,780,679,8644,635,308,2148,370,881,661,1374,3478,412,3501,691,17,289,8699,1626,749,264,674,484,1877,810,1532,449,1244,11323,9773,479,7863,7337,616,1439,866,3574,474,3294,9225,1262,1588,8257,662,1757,8915,2773,9508,508,6885,2251,509,531,1263,2750,607,277,336,628,32,302,13454,940,2514,10053,1422,1111,1881,299,2753,588,9166,4900,1474,4930,1625,1722,572,1804,7323,7192,7930,19,3899,543,15495,2111,16677,5323,3607,16,832,9698,3268,656,8541,10083,2125,1231,1314,520,7724,609,13151,1719,981,2202,837,1392,8854,1107,911,717,4622,784,21,1718,5688,736,15143,18,20,3236,9193,8275,6702,772,765,2495,2025,1731,1415,471,440,2222,3271,1485,2063,3011,1065,5125,2061,1400,266,2795,890,442,2407,791,5357,2504,4858,3035,1135,3190,3938,10495,922,973,4047,575,1433,968,629,19048,23,13539,3237,9826,1157,9415,584,10190,9849,815,4650,2972,40,1064,1148,991,3633,1270,880,3336,3224,1639,4646,14956,621,2215,2383,1043,3125,2481,5729,781,852,2670,5199,6079,12279,19035,1537,649,3769,5390,22,15629,14436,10048,4874,5180,10460,1816,1828,2805,2211,4619,1218,1194,3152,978,427,2331,1282,790,2321,2327,1870,3260,2329,1495,3198,13037,4441,595,1682,1544,4632,1558,9775,9907,2075,9919,1688,3426,2921,18523,1954,19038,1593,892,17342,1119,13343,7473,5115,2067,2440,851,21409,2312,2011,1168,34,2078,19710,3737,583,1946,25500,6986,1239,10261,1983,33,2396,2627,20299,15349,3226,51,47,1737,8131,1366,1507,2208,3269,2623,7796,4366,3088,1238,764,25181,1355,7683,2932,938,640,1017,12168,606,6104,599,6547,18693,2793,2141,9661,760,1249,16003,4042,1022,1049,783,6635,1913,44,1139,3945,3181,1853,4995,8308,3132,5598,2408,2492,19409,3682,1222,2094,2548,15696,3267,1101,17501,16226,821,26,12713,2813,1903,7003,23871,2727,3578,1290,1957,49,553,2901,2266,20416,22986,21355,2682,1169,1088,2948,8684,751,1471,4955,3050,27829,1321,304,1388,1201,943,19884,7945,2718,900,3901,850,2949,21761,766,3700,19755,2192,1327,24,13374,673,5566,2900,21148,3098,37,20064,1680,526,1959,2091,2124,2102,3220,1178,3510,7650,2227,13,23134,1375,779,1821,18395,5179,3717,3977,987,]\n",
    "\n",
    "for idx in lst:\n",
    "    print(tokenizer.decoder[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1784749d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '!',\n",
       " 1: '\"',\n",
       " 2: '#',\n",
       " 3: '$',\n",
       " 4: '%',\n",
       " 5: '&',\n",
       " 6: \"'\",\n",
       " 7: '(',\n",
       " 8: ')',\n",
       " 9: '*',\n",
       " 10: '+',\n",
       " 11: ',',\n",
       " 12: '-',\n",
       " 13: '.',\n",
       " 14: '/',\n",
       " 15: '0',\n",
       " 16: '1',\n",
       " 17: '2',\n",
       " 18: '3',\n",
       " 19: '4',\n",
       " 20: '5',\n",
       " 21: '6',\n",
       " 22: '7',\n",
       " 23: '8',\n",
       " 24: '9',\n",
       " 25: ':',\n",
       " 26: ';',\n",
       " 27: '<',\n",
       " 28: '=',\n",
       " 29: '>',\n",
       " 30: '?',\n",
       " 31: '@',\n",
       " 32: 'A',\n",
       " 33: 'B',\n",
       " 34: 'C',\n",
       " 35: 'D',\n",
       " 36: 'E',\n",
       " 37: 'F',\n",
       " 38: 'G',\n",
       " 39: 'H',\n",
       " 40: 'I',\n",
       " 41: 'J',\n",
       " 42: 'K',\n",
       " 43: 'L',\n",
       " 44: 'M',\n",
       " 45: 'N',\n",
       " 46: 'O',\n",
       " 47: 'P',\n",
       " 48: 'Q',\n",
       " 49: 'R',\n",
       " 50: 'S',\n",
       " 51: 'T',\n",
       " 52: 'U',\n",
       " 53: 'V',\n",
       " 54: 'W',\n",
       " 55: 'X',\n",
       " 56: 'Y',\n",
       " 57: 'Z',\n",
       " 58: '[',\n",
       " 59: '\\\\',\n",
       " 60: ']',\n",
       " 61: '^',\n",
       " 62: '_',\n",
       " 63: '`',\n",
       " 64: 'a',\n",
       " 65: 'b',\n",
       " 66: 'c',\n",
       " 67: 'd',\n",
       " 68: 'e',\n",
       " 69: 'f',\n",
       " 70: 'g',\n",
       " 71: 'h',\n",
       " 72: 'i',\n",
       " 73: 'j',\n",
       " 74: 'k',\n",
       " 75: 'l',\n",
       " 76: 'm',\n",
       " 77: 'n',\n",
       " 78: 'o',\n",
       " 79: 'p',\n",
       " 80: 'q',\n",
       " 81: 'r',\n",
       " 82: 's',\n",
       " 83: 't',\n",
       " 84: 'u',\n",
       " 85: 'v',\n",
       " 86: 'w',\n",
       " 87: 'x',\n",
       " 88: 'y',\n",
       " 89: 'z',\n",
       " 90: '{',\n",
       " 91: '|',\n",
       " 92: '}',\n",
       " 93: '~',\n",
       " 94: 'Â¡',\n",
       " 95: 'Â¢',\n",
       " 96: 'Â£',\n",
       " 97: 'Â¤',\n",
       " 98: 'Â¥',\n",
       " 99: 'Â¦',\n",
       " 100: 'Â§',\n",
       " 101: 'Â¨',\n",
       " 102: 'Â©',\n",
       " 103: 'Âª',\n",
       " 104: 'Â«',\n",
       " 105: 'Â¬',\n",
       " 106: 'Â®',\n",
       " 107: 'Â¯',\n",
       " 108: 'Â°',\n",
       " 109: 'Â±',\n",
       " 110: 'Â²',\n",
       " 111: 'Â³',\n",
       " 112: 'Â´',\n",
       " 113: 'Âµ',\n",
       " 114: 'Â¶',\n",
       " 115: 'Â·',\n",
       " 116: 'Â¸',\n",
       " 117: 'Â¹',\n",
       " 118: 'Âº',\n",
       " 119: 'Â»',\n",
       " 120: 'Â¼',\n",
       " 121: 'Â½',\n",
       " 122: 'Â¾',\n",
       " 123: 'Â¿',\n",
       " 124: 'Ã',\n",
       " 125: 'Ã',\n",
       " 126: 'Ã',\n",
       " 127: 'Ã',\n",
       " 128: 'Ã',\n",
       " 129: 'Ã',\n",
       " 130: 'Ã',\n",
       " 131: 'Ã',\n",
       " 132: 'Ã',\n",
       " 133: 'Ã',\n",
       " 134: 'Ã',\n",
       " 135: 'Ã',\n",
       " 136: 'Ã',\n",
       " 137: 'Ã',\n",
       " 138: 'Ã',\n",
       " 139: 'Ã',\n",
       " 140: 'Ã',\n",
       " 141: 'Ã',\n",
       " 142: 'Ã',\n",
       " 143: 'Ã',\n",
       " 144: 'Ã',\n",
       " 145: 'Ã',\n",
       " 146: 'Ã',\n",
       " 147: 'Ã',\n",
       " 148: 'Ã',\n",
       " 149: 'Ã',\n",
       " 150: 'Ã',\n",
       " 151: 'Ã',\n",
       " 152: 'Ã',\n",
       " 153: 'Ã',\n",
       " 154: 'Ã',\n",
       " 155: 'Ã',\n",
       " 156: 'Ã ',\n",
       " 157: 'Ã¡',\n",
       " 158: 'Ã¢',\n",
       " 159: 'Ã£',\n",
       " 160: 'Ã¤',\n",
       " 161: 'Ã¥',\n",
       " 162: 'Ã¦',\n",
       " 163: 'Ã§',\n",
       " 164: 'Ã¨',\n",
       " 165: 'Ã©',\n",
       " 166: 'Ãª',\n",
       " 167: 'Ã«',\n",
       " 168: 'Ã¬',\n",
       " 169: 'Ã­',\n",
       " 170: 'Ã®',\n",
       " 171: 'Ã¯',\n",
       " 172: 'Ã°',\n",
       " 173: 'Ã±',\n",
       " 174: 'Ã²',\n",
       " 175: 'Ã³',\n",
       " 176: 'Ã´',\n",
       " 177: 'Ãµ',\n",
       " 178: 'Ã¶',\n",
       " 179: 'Ã·',\n",
       " 180: 'Ã¸',\n",
       " 181: 'Ã¹',\n",
       " 182: 'Ãº',\n",
       " 183: 'Ã»',\n",
       " 184: 'Ã¼',\n",
       " 185: 'Ã½',\n",
       " 186: 'Ã¾',\n",
       " 187: 'Ã¿',\n",
       " 188: 'Ä',\n",
       " 189: 'Ä',\n",
       " 190: 'Ä',\n",
       " 191: 'Ä',\n",
       " 192: 'Ä',\n",
       " 193: 'Ä',\n",
       " 194: 'Ä',\n",
       " 195: 'Ä',\n",
       " 196: 'Ä',\n",
       " 197: 'Ä',\n",
       " 198: 'Ä',\n",
       " 199: 'Ä',\n",
       " 200: 'Ä',\n",
       " 201: 'Ä',\n",
       " 202: 'Ä',\n",
       " 203: 'Ä',\n",
       " 204: 'Ä',\n",
       " 205: 'Ä',\n",
       " 206: 'Ä',\n",
       " 207: 'Ä',\n",
       " 208: 'Ä',\n",
       " 209: 'Ä',\n",
       " 210: 'Ä',\n",
       " 211: 'Ä',\n",
       " 212: 'Ä',\n",
       " 213: 'Ä',\n",
       " 214: 'Ä',\n",
       " 215: 'Ä',\n",
       " 216: 'Ä',\n",
       " 217: 'Ä',\n",
       " 218: 'Ä',\n",
       " 219: 'Ä',\n",
       " 220: 'Ä ',\n",
       " 221: 'Ä¡',\n",
       " 222: 'Ä¢',\n",
       " 223: 'Ä£',\n",
       " 224: 'Ä¤',\n",
       " 225: 'Ä¥',\n",
       " 226: 'Ä¦',\n",
       " 227: 'Ä§',\n",
       " 228: 'Ä¨',\n",
       " 229: 'Ä©',\n",
       " 230: 'Äª',\n",
       " 231: 'Ä«',\n",
       " 232: 'Ä¬',\n",
       " 233: 'Ä­',\n",
       " 234: 'Ä®',\n",
       " 235: 'Ä¯',\n",
       " 236: 'Ä°',\n",
       " 237: 'Ä±',\n",
       " 238: 'Ä²',\n",
       " 239: 'Ä³',\n",
       " 240: 'Ä´',\n",
       " 241: 'Äµ',\n",
       " 242: 'Ä¶',\n",
       " 243: 'Ä·',\n",
       " 244: 'Ä¸',\n",
       " 245: 'Ä¹',\n",
       " 246: 'Äº',\n",
       " 247: 'Ä»',\n",
       " 248: 'Ä¼',\n",
       " 249: 'Ä½',\n",
       " 250: 'Ä¾',\n",
       " 251: 'Ä¿',\n",
       " 252: 'Å',\n",
       " 253: 'Å',\n",
       " 254: 'Å',\n",
       " 255: 'Å',\n",
       " 256: 'Ä t',\n",
       " 257: 'Ä a',\n",
       " 258: 'he',\n",
       " 259: 'in',\n",
       " 260: 're',\n",
       " 261: 'on',\n",
       " 262: 'Ä the',\n",
       " 263: 'er',\n",
       " 264: 'Ä s',\n",
       " 265: 'at',\n",
       " 266: 'Ä w',\n",
       " 267: 'Ä o',\n",
       " 268: 'en',\n",
       " 269: 'Ä c',\n",
       " 270: 'it',\n",
       " 271: 'is',\n",
       " 272: 'an',\n",
       " 273: 'or',\n",
       " 274: 'es',\n",
       " 275: 'Ä b',\n",
       " 276: 'ed',\n",
       " 277: 'Ä f',\n",
       " 278: 'ing',\n",
       " 279: 'Ä p',\n",
       " 280: 'ou',\n",
       " 281: 'Ä an',\n",
       " 282: 'al',\n",
       " 283: 'ar',\n",
       " 284: 'Ä to',\n",
       " 285: 'Ä m',\n",
       " 286: 'Ä of',\n",
       " 287: 'Ä in',\n",
       " 288: 'Ä d',\n",
       " 289: 'Ä h',\n",
       " 290: 'Ä and',\n",
       " 291: 'ic',\n",
       " 292: 'as',\n",
       " 293: 'le',\n",
       " 294: 'Ä th',\n",
       " 295: 'ion',\n",
       " 296: 'om',\n",
       " 297: 'll',\n",
       " 298: 'ent',\n",
       " 299: 'Ä n',\n",
       " 300: 'Ä l',\n",
       " 301: 'st',\n",
       " 302: 'Ä re',\n",
       " 303: 've',\n",
       " 304: 'Ä e',\n",
       " 305: 'ro',\n",
       " 306: 'ly',\n",
       " 307: 'Ä be',\n",
       " 308: 'Ä g',\n",
       " 309: 'Ä T',\n",
       " 310: 'ct',\n",
       " 311: 'Ä S',\n",
       " 312: 'id',\n",
       " 313: 'ot',\n",
       " 314: 'Ä I',\n",
       " 315: 'ut',\n",
       " 316: 'et',\n",
       " 317: 'Ä A',\n",
       " 318: 'Ä is',\n",
       " 319: 'Ä on',\n",
       " 320: 'im',\n",
       " 321: 'am',\n",
       " 322: 'ow',\n",
       " 323: 'ay',\n",
       " 324: 'ad',\n",
       " 325: 'se',\n",
       " 326: 'Ä that',\n",
       " 327: 'Ä C',\n",
       " 328: 'ig',\n",
       " 329: 'Ä for',\n",
       " 330: 'ac',\n",
       " 331: 'Ä y',\n",
       " 332: 'ver',\n",
       " 333: 'ur',\n",
       " 334: 'Ä u',\n",
       " 335: 'ld',\n",
       " 336: 'Ä st',\n",
       " 337: 'Ä M',\n",
       " 338: \"'s\",\n",
       " 339: 'Ä he',\n",
       " 340: 'Ä it',\n",
       " 341: 'ation',\n",
       " 342: 'ith',\n",
       " 343: 'ir',\n",
       " 344: 'ce',\n",
       " 345: 'Ä you',\n",
       " 346: 'il',\n",
       " 347: 'Ä B',\n",
       " 348: 'Ä wh',\n",
       " 349: 'ol',\n",
       " 350: 'Ä P',\n",
       " 351: 'Ä with',\n",
       " 352: 'Ä 1',\n",
       " 353: 'ter',\n",
       " 354: 'ch',\n",
       " 355: 'Ä as',\n",
       " 356: 'Ä we',\n",
       " 357: 'Ä (',\n",
       " 358: 'nd',\n",
       " 359: 'ill',\n",
       " 360: 'Ä D',\n",
       " 361: 'if',\n",
       " 362: 'Ä 2',\n",
       " 363: 'ag',\n",
       " 364: 'ers',\n",
       " 365: 'ke',\n",
       " 366: 'Ä \"',\n",
       " 367: 'Ä H',\n",
       " 368: 'em',\n",
       " 369: 'Ä con',\n",
       " 370: 'Ä W',\n",
       " 371: 'Ä R',\n",
       " 372: 'her',\n",
       " 373: 'Ä was',\n",
       " 374: 'Ä r',\n",
       " 375: 'od',\n",
       " 376: 'Ä F',\n",
       " 377: 'ul',\n",
       " 378: 'ate',\n",
       " 379: 'Ä at',\n",
       " 380: 'ri',\n",
       " 381: 'pp',\n",
       " 382: 'ore',\n",
       " 383: 'Ä The',\n",
       " 384: 'Ä se',\n",
       " 385: 'us',\n",
       " 386: 'Ä pro',\n",
       " 387: 'Ä ha',\n",
       " 388: 'um',\n",
       " 389: 'Ä are',\n",
       " 390: 'Ä de',\n",
       " 391: 'ain',\n",
       " 392: 'and',\n",
       " 393: 'Ä or',\n",
       " 394: 'igh',\n",
       " 395: 'est',\n",
       " 396: 'ist',\n",
       " 397: 'ab',\n",
       " 398: 'rom',\n",
       " 399: 'Ä N',\n",
       " 400: 'th',\n",
       " 401: 'Ä com',\n",
       " 402: 'Ä G',\n",
       " 403: 'un',\n",
       " 404: 'op',\n",
       " 405: '00',\n",
       " 406: 'Ä L',\n",
       " 407: 'Ä not',\n",
       " 408: 'ess',\n",
       " 409: 'Ä ex',\n",
       " 410: 'Ä v',\n",
       " 411: 'res',\n",
       " 412: 'Ä E',\n",
       " 413: 'ew',\n",
       " 414: 'ity',\n",
       " 415: 'ant',\n",
       " 416: 'Ä by',\n",
       " 417: 'el',\n",
       " 418: 'os',\n",
       " 419: 'ort',\n",
       " 420: 'oc',\n",
       " 421: 'qu',\n",
       " 422: 'Ä from',\n",
       " 423: 'Ä have',\n",
       " 424: 'Ä su',\n",
       " 425: 'ive',\n",
       " 426: 'ould',\n",
       " 427: 'Ä sh',\n",
       " 428: 'Ä this',\n",
       " 429: 'nt',\n",
       " 430: 'ra',\n",
       " 431: 'pe',\n",
       " 432: 'ight',\n",
       " 433: 'art',\n",
       " 434: 'ment',\n",
       " 435: 'Ä al',\n",
       " 436: 'ust',\n",
       " 437: 'end',\n",
       " 438: '--',\n",
       " 439: 'all',\n",
       " 440: 'Ä O',\n",
       " 441: 'ack',\n",
       " 442: 'Ä ch',\n",
       " 443: 'Ä le',\n",
       " 444: 'ies',\n",
       " 445: 'red',\n",
       " 446: 'ard',\n",
       " 447: 'Ã¢Ä¢',\n",
       " 448: 'out',\n",
       " 449: 'Ä J',\n",
       " 450: 'Ä ab',\n",
       " 451: 'ear',\n",
       " 452: 'iv',\n",
       " 453: 'ally',\n",
       " 454: 'our',\n",
       " 455: 'ost',\n",
       " 456: 'gh',\n",
       " 457: 'pt',\n",
       " 458: 'Ä pl',\n",
       " 459: 'ast',\n",
       " 460: 'Ä can',\n",
       " 461: 'ak',\n",
       " 462: 'ome',\n",
       " 463: 'ud',\n",
       " 464: 'The',\n",
       " 465: 'Ä his',\n",
       " 466: 'Ä do',\n",
       " 467: 'Ä go',\n",
       " 468: 'Ä has',\n",
       " 469: 'ge',\n",
       " 470: \"'t\",\n",
       " 471: 'Ä U',\n",
       " 472: 'rou',\n",
       " 473: 'Ä sa',\n",
       " 474: 'Ä j',\n",
       " 475: 'Ä but',\n",
       " 476: 'Ä wor',\n",
       " 477: 'Ä all',\n",
       " 478: 'ect',\n",
       " 479: 'Ä k',\n",
       " 480: 'ame',\n",
       " 481: 'Ä will',\n",
       " 482: 'ok',\n",
       " 483: 'Ä whe',\n",
       " 484: 'Ä they',\n",
       " 485: 'ide',\n",
       " 486: '01',\n",
       " 487: 'ff',\n",
       " 488: 'ich',\n",
       " 489: 'pl',\n",
       " 490: 'ther',\n",
       " 491: 'Ä tr',\n",
       " 492: '..',\n",
       " 493: 'Ä int',\n",
       " 494: 'ie',\n",
       " 495: 'ure',\n",
       " 496: 'age',\n",
       " 497: 'Ä ne',\n",
       " 498: 'ial',\n",
       " 499: 'ap',\n",
       " 500: 'ine',\n",
       " 501: 'ice',\n",
       " 502: 'Ä me',\n",
       " 503: 'Ä out',\n",
       " 504: 'ans',\n",
       " 505: 'one',\n",
       " 506: 'ong',\n",
       " 507: 'ions',\n",
       " 508: 'Ä who',\n",
       " 509: 'Ä K',\n",
       " 510: 'Ä up',\n",
       " 511: 'Ä their',\n",
       " 512: 'Ä ad',\n",
       " 513: 'Ä 3',\n",
       " 514: 'Ä us',\n",
       " 515: 'ated',\n",
       " 516: 'ous',\n",
       " 517: 'Ä more',\n",
       " 518: 'ue',\n",
       " 519: 'og',\n",
       " 520: 'Ä St',\n",
       " 521: 'ind',\n",
       " 522: 'ike',\n",
       " 523: 'Ä so',\n",
       " 524: 'ime',\n",
       " 525: 'per',\n",
       " 526: '.\"',\n",
       " 527: 'ber',\n",
       " 528: 'iz',\n",
       " 529: 'act',\n",
       " 530: 'Ä one',\n",
       " 531: 'Ä said',\n",
       " 532: 'Ä -',\n",
       " 533: 'are',\n",
       " 534: 'Ä your',\n",
       " 535: 'cc',\n",
       " 536: 'Ä Th',\n",
       " 537: 'Ä cl',\n",
       " 538: 'ep',\n",
       " 539: 'ake',\n",
       " 540: 'able',\n",
       " 541: 'ip',\n",
       " 542: 'Ä cont',\n",
       " 543: 'Ä which',\n",
       " 544: 'ia',\n",
       " 545: 'Ä im',\n",
       " 546: 'Ä about',\n",
       " 547: 'Ä were',\n",
       " 548: 'very',\n",
       " 549: 'ub',\n",
       " 550: 'Ä had',\n",
       " 551: 'Ä en',\n",
       " 552: 'Ä comp',\n",
       " 553: ',\"',\n",
       " 554: 'Ä In',\n",
       " 555: 'Ä un',\n",
       " 556: 'Ä ag',\n",
       " 557: 'ire',\n",
       " 558: 'ace',\n",
       " 559: 'au',\n",
       " 560: 'ary',\n",
       " 561: 'Ä would',\n",
       " 562: 'ass',\n",
       " 563: 'ry',\n",
       " 564: 'Ä Ã¢Ä¢',\n",
       " 565: 'cl',\n",
       " 566: 'ook',\n",
       " 567: 'ere',\n",
       " 568: 'so',\n",
       " 569: 'Ä V',\n",
       " 570: 'ign',\n",
       " 571: 'ib',\n",
       " 572: 'Ä off',\n",
       " 573: 'Ä te',\n",
       " 574: 'ven',\n",
       " 575: 'Ä Y',\n",
       " 576: 'ile',\n",
       " 577: 'ose',\n",
       " 578: 'ite',\n",
       " 579: 'orm',\n",
       " 580: 'Ä 201',\n",
       " 581: 'Ä res',\n",
       " 582: 'Ä man',\n",
       " 583: 'Ä per',\n",
       " 584: 'Ä other',\n",
       " 585: 'ord',\n",
       " 586: 'ult',\n",
       " 587: 'Ä been',\n",
       " 588: 'Ä like',\n",
       " 589: 'ase',\n",
       " 590: 'ance',\n",
       " 591: 'ks',\n",
       " 592: 'ays',\n",
       " 593: 'own',\n",
       " 594: 'ence',\n",
       " 595: 'Ä dis',\n",
       " 596: 'ction',\n",
       " 597: 'Ä any',\n",
       " 598: 'Ä app',\n",
       " 599: 'Ä sp',\n",
       " 600: 'int',\n",
       " 601: 'ress',\n",
       " 602: 'ations',\n",
       " 603: 'ail',\n",
       " 604: 'Ä 4',\n",
       " 605: 'ical',\n",
       " 606: 'Ä them',\n",
       " 607: 'Ä her',\n",
       " 608: 'ount',\n",
       " 609: 'Ä Ch',\n",
       " 610: 'Ä ar',\n",
       " 611: 'Ä if',\n",
       " 612: 'Ä there',\n",
       " 613: 'Ä pe',\n",
       " 614: 'Ä year',\n",
       " 615: 'av',\n",
       " 616: 'Ä my',\n",
       " 617: 'Ä some',\n",
       " 618: 'Ä when',\n",
       " 619: 'ough',\n",
       " 620: 'ach',\n",
       " 621: 'Ä than',\n",
       " 622: 'ru',\n",
       " 623: 'ond',\n",
       " 624: 'ick',\n",
       " 625: 'Ä over',\n",
       " 626: 'vel',\n",
       " 627: 'Ä qu',\n",
       " 628: 'ÄÄ',\n",
       " 629: 'Ä sc',\n",
       " 630: 'reat',\n",
       " 631: 'ree',\n",
       " 632: 'Ä It',\n",
       " 633: 'ound',\n",
       " 634: 'port',\n",
       " 635: 'Ä also',\n",
       " 636: 'Ä part',\n",
       " 637: 'fter',\n",
       " 638: 'Ä kn',\n",
       " 639: 'Ä bec',\n",
       " 640: 'Ä time',\n",
       " 641: 'ens',\n",
       " 642: 'Ä 5',\n",
       " 643: 'ople',\n",
       " 644: 'Ä what',\n",
       " 645: 'Ä no',\n",
       " 646: 'du',\n",
       " 647: 'mer',\n",
       " 648: 'ang',\n",
       " 649: 'Ä new',\n",
       " 650: '----',\n",
       " 651: 'Ä get',\n",
       " 652: 'ory',\n",
       " 653: 'ition',\n",
       " 654: 'ings',\n",
       " 655: 'Ä just',\n",
       " 656: 'Ä into',\n",
       " 657: 'Ä 0',\n",
       " 658: 'ents',\n",
       " 659: 'ove',\n",
       " 660: 'te',\n",
       " 661: 'Ä people',\n",
       " 662: 'Ä pre',\n",
       " 663: 'Ä its',\n",
       " 664: 'Ä rec',\n",
       " 665: 'Ä tw',\n",
       " 666: 'ian',\n",
       " 667: 'irst',\n",
       " 668: 'ark',\n",
       " 669: 'ors',\n",
       " 670: 'Ä work',\n",
       " 671: 'ade',\n",
       " 672: 'ob',\n",
       " 673: 'Ä she',\n",
       " 674: 'Ä our',\n",
       " 675: 'wn',\n",
       " 676: 'ink',\n",
       " 677: 'lic',\n",
       " 678: 'Ä 19',\n",
       " 679: 'Ä He',\n",
       " 680: 'ish',\n",
       " 681: 'nder',\n",
       " 682: 'ause',\n",
       " 683: 'Ä him',\n",
       " 684: 'ons',\n",
       " 685: 'Ä [',\n",
       " 686: 'Ä ro',\n",
       " 687: 'form',\n",
       " 688: 'ild',\n",
       " 689: 'ates',\n",
       " 690: 'vers',\n",
       " 691: 'Ä only',\n",
       " 692: 'oll',\n",
       " 693: 'Ä spe',\n",
       " 694: 'ck',\n",
       " 695: 'ell',\n",
       " 696: 'amp',\n",
       " 697: 'Ä acc',\n",
       " 698: 'Ä bl',\n",
       " 699: 'ious',\n",
       " 700: 'urn',\n",
       " 701: 'ft',\n",
       " 702: 'ood',\n",
       " 703: 'Ä how',\n",
       " 704: 'hed',\n",
       " 705: \"Ä '\",\n",
       " 706: 'Ä after',\n",
       " 707: 'aw',\n",
       " 708: 'Ä att',\n",
       " 709: 'ov',\n",
       " 710: 'ne',\n",
       " 711: 'Ä play',\n",
       " 712: 'erv',\n",
       " 713: 'ict',\n",
       " 714: 'Ä could',\n",
       " 715: 'itt',\n",
       " 716: 'Ä am',\n",
       " 717: 'Ä first',\n",
       " 718: 'Ä 6',\n",
       " 719: 'Ä act',\n",
       " 720: 'Ä $',\n",
       " 721: 'ec',\n",
       " 722: 'hing',\n",
       " 723: 'ual',\n",
       " 724: 'ull',\n",
       " 725: 'Ä comm',\n",
       " 726: 'oy',\n",
       " 727: 'old',\n",
       " 728: 'ces',\n",
       " 729: 'ater',\n",
       " 730: 'Ä fe',\n",
       " 731: 'Ä bet',\n",
       " 732: 'we',\n",
       " 733: 'iff',\n",
       " 734: 'Ä two',\n",
       " 735: 'ock',\n",
       " 736: 'Ä back',\n",
       " 737: ').',\n",
       " 738: 'ident',\n",
       " 739: 'Ä under',\n",
       " 740: 'rough',\n",
       " 741: 'sel',\n",
       " 742: 'xt',\n",
       " 743: 'Ä may',\n",
       " 744: 'round',\n",
       " 745: 'Ä po',\n",
       " 746: 'ph',\n",
       " 747: 'iss',\n",
       " 748: 'Ä des',\n",
       " 749: 'Ä most',\n",
       " 750: 'Ä did',\n",
       " 751: 'Ä add',\n",
       " 752: 'ject',\n",
       " 753: 'Ä inc',\n",
       " 754: 'fore',\n",
       " 755: 'Ä pol',\n",
       " 756: 'ont',\n",
       " 757: 'Ä again',\n",
       " 758: 'clud',\n",
       " 759: 'tern',\n",
       " 760: 'Ä know',\n",
       " 761: 'Ä need',\n",
       " 762: 'Ä cons',\n",
       " 763: 'Ä co',\n",
       " 764: 'Ä .',\n",
       " 765: 'Ä want',\n",
       " 766: 'Ä see',\n",
       " 767: 'Ä 7',\n",
       " 768: 'ning',\n",
       " 769: 'iew',\n",
       " 770: 'Ä This',\n",
       " 771: 'ced',\n",
       " 772: 'Ä even',\n",
       " 773: 'Ä ind',\n",
       " 774: 'ty',\n",
       " 775: 'Ä We',\n",
       " 776: 'ath',\n",
       " 777: 'Ä these',\n",
       " 778: 'Ä pr',\n",
       " 779: 'Ä use',\n",
       " 780: 'Ä because',\n",
       " 781: 'Ä fl',\n",
       " 782: 'ng',\n",
       " 783: 'Ä now',\n",
       " 784: 'Ä Ã¢Ä¢Äµ',\n",
       " 785: 'com',\n",
       " 786: 'ise',\n",
       " 787: 'Ä make',\n",
       " 788: 'Ä then',\n",
       " 789: 'ower',\n",
       " 790: 'Ä every',\n",
       " 791: 'Ä Un',\n",
       " 792: 'Ä sec',\n",
       " 793: 'oss',\n",
       " 794: 'uch',\n",
       " 795: 'Ä em',\n",
       " 796: 'Ä =',\n",
       " 797: 'Ä Re',\n",
       " 798: 'ied',\n",
       " 799: 'rit',\n",
       " 800: 'Ä inv',\n",
       " 801: 'lect',\n",
       " 802: 'Ä supp',\n",
       " 803: 'ating',\n",
       " 804: 'Ä look',\n",
       " 805: 'man',\n",
       " 806: 'pect',\n",
       " 807: 'Ä 8',\n",
       " 808: 'row',\n",
       " 809: 'Ä bu',\n",
       " 810: 'Ä where',\n",
       " 811: 'ific',\n",
       " 812: 'Ä years',\n",
       " 813: 'ily',\n",
       " 814: 'Ä diff',\n",
       " 815: 'Ä should',\n",
       " 816: 'Ä rem',\n",
       " 817: 'Th',\n",
       " 818: 'In',\n",
       " 819: 'Ä ev',\n",
       " 820: 'day',\n",
       " 821: \"'re\",\n",
       " 822: 'rib',\n",
       " 823: 'Ä rel',\n",
       " 824: 'ss',\n",
       " 825: 'Ä def',\n",
       " 826: 'Ä right',\n",
       " 827: 'Ä sy',\n",
       " 828: '),',\n",
       " 829: 'les',\n",
       " 830: '000',\n",
       " 831: 'hen',\n",
       " 832: 'Ä through',\n",
       " 833: 'Ä Tr',\n",
       " 834: '__',\n",
       " 835: 'Ä way',\n",
       " 836: 'Ä don',\n",
       " 837: 'Ä ,',\n",
       " 838: 'Ä 10',\n",
       " 839: 'ased',\n",
       " 840: 'Ä ass',\n",
       " 841: 'ublic',\n",
       " 842: 'Ä reg',\n",
       " 843: 'Ä And',\n",
       " 844: 'ix',\n",
       " 845: 'Ä very',\n",
       " 846: 'Ä includ',\n",
       " 847: 'other',\n",
       " 848: 'Ä imp',\n",
       " 849: 'oth',\n",
       " 850: 'Ä sub',\n",
       " 851: 'Ä Ã¢Ä¢Ä¶',\n",
       " 852: 'Ä being',\n",
       " 853: 'arg',\n",
       " 854: 'Ä Wh',\n",
       " 855: '==',\n",
       " 856: 'ible',\n",
       " 857: 'Ä does',\n",
       " 858: 'ange',\n",
       " 859: 'ram',\n",
       " 860: 'Ä 9',\n",
       " 861: 'ert',\n",
       " 862: 'ps',\n",
       " 863: 'ited',\n",
       " 864: 'ational',\n",
       " 865: 'Ä br',\n",
       " 866: 'Ä down',\n",
       " 867: 'Ä many',\n",
       " 868: 'aking',\n",
       " 869: 'Ä call',\n",
       " 870: 'uring',\n",
       " 871: 'ities',\n",
       " 872: 'Ä ph',\n",
       " 873: 'ics',\n",
       " 874: 'als',\n",
       " 875: 'Ä dec',\n",
       " 876: 'ative',\n",
       " 877: 'ener',\n",
       " 878: 'Ä before',\n",
       " 879: 'ility',\n",
       " 880: 'Ä well',\n",
       " 881: 'Ä much',\n",
       " 882: 'erson',\n",
       " 883: 'Ä those',\n",
       " 884: 'Ä such',\n",
       " 885: 'Ä ke',\n",
       " 886: 'Ä end',\n",
       " 887: 'Ä But',\n",
       " 888: 'ason',\n",
       " 889: 'ting',\n",
       " 890: 'Ä long',\n",
       " 891: 'ef',\n",
       " 892: 'Ä think',\n",
       " 893: 'ys',\n",
       " 894: 'Ä bel',\n",
       " 895: 'Ä sm',\n",
       " 896: 'its',\n",
       " 897: 'ax',\n",
       " 898: 'Ä own',\n",
       " 899: 'Ä prov',\n",
       " 900: 'Ä set',\n",
       " 901: 'ife',\n",
       " 902: 'ments',\n",
       " 903: 'ble',\n",
       " 904: 'ward',\n",
       " 905: 'Ä show',\n",
       " 906: 'Ä pres',\n",
       " 907: 'ms',\n",
       " 908: 'omet',\n",
       " 909: 'Ä ob',\n",
       " 910: 'Ä say',\n",
       " 911: 'Ä Sh',\n",
       " 912: 'ts',\n",
       " 913: 'ful',\n",
       " 914: 'Ä eff',\n",
       " 915: 'Ä gu',\n",
       " 916: 'Ä inst',\n",
       " 917: 'und',\n",
       " 918: 'ren',\n",
       " 919: 'cess',\n",
       " 920: 'Ä ent',\n",
       " 921: 'Ä You',\n",
       " 922: 'Ä good',\n",
       " 923: 'Ä start',\n",
       " 924: 'ince',\n",
       " 925: 'Ä made',\n",
       " 926: 'tt',\n",
       " 927: 'stem',\n",
       " 928: 'olog',\n",
       " 929: 'up',\n",
       " 930: 'Ä |',\n",
       " 931: 'ump',\n",
       " 932: 'Ä hel',\n",
       " 933: 'vern',\n",
       " 934: 'ular',\n",
       " 935: 'ually',\n",
       " 936: 'Ä ac',\n",
       " 937: 'Ä mon',\n",
       " 938: 'Ä last',\n",
       " 939: 'Ä 200',\n",
       " 940: '10',\n",
       " 941: 'Ä stud',\n",
       " 942: 'ures',\n",
       " 943: 'Ä Ar',\n",
       " 944: 'self',\n",
       " 945: 'ars',\n",
       " 946: 'meric',\n",
       " 947: 'ues',\n",
       " 948: 'cy',\n",
       " 949: 'Ä min',\n",
       " 950: 'ollow',\n",
       " 951: 'Ä col',\n",
       " 952: 'io',\n",
       " 953: 'Ä mod',\n",
       " 954: 'Ä count',\n",
       " 955: 'Ä Com',\n",
       " 956: 'hes',\n",
       " 957: 'Ä fin',\n",
       " 958: 'air',\n",
       " 959: 'ier',\n",
       " 960: 'Ã¢Ä¢Ä¶',\n",
       " 961: 'read',\n",
       " 962: 'ank',\n",
       " 963: 'atch',\n",
       " 964: 'ever',\n",
       " 965: 'Ä str',\n",
       " 966: 'Ä point',\n",
       " 967: 'ork',\n",
       " 968: 'Ä New',\n",
       " 969: 'Ä sur',\n",
       " 970: 'ool',\n",
       " 971: 'alk',\n",
       " 972: 'ement',\n",
       " 973: 'Ä used',\n",
       " 974: 'ract',\n",
       " 975: 'ween',\n",
       " 976: 'Ä same',\n",
       " 977: 'oun',\n",
       " 978: 'Ä Al',\n",
       " 979: 'ci',\n",
       " 980: 'Ä differe',\n",
       " 981: 'Ä while',\n",
       " 982: '--------',\n",
       " 983: 'Ä game',\n",
       " 984: 'cept',\n",
       " 985: 'Ä sim',\n",
       " 986: '...',\n",
       " 987: 'Ä inter',\n",
       " 988: 'ek',\n",
       " 989: 'Ä report',\n",
       " 990: 'Ä produ',\n",
       " 991: 'Ä still',\n",
       " 992: 'led',\n",
       " 993: 'ah',\n",
       " 994: 'Ä here',\n",
       " 995: 'Ä world',\n",
       " 996: 'Ä though',\n",
       " 997: 'Ä num',\n",
       " 998: 'arch',\n",
       " 999: 'imes',\n",
       " ...}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2dc864c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99762bce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f7bce6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "4ea9a914",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_layer = nn.TransformerEncoderLayer(d_model=256, nhead=8)\n",
    "src = torch.rand(10, 32, 256)\n",
    "out = encoder_layer(src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "8738493d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 32, 256])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8ad483",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
