{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aceb3a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fb9209a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = nn.LSTM(10, 20, bidirectional=True)\n",
    "input_ = torch.randn(6, 3, 10) # (seq_len, batch, input_state)\n",
    "output, (hn, cn) = rnn(input_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b32abd7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 3, 40])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc9ee3f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 8, 1])\n"
     ]
    }
   ],
   "source": [
    "m = nn.AdaptiveMaxPool1d(8, return_indices=True)\n",
    "input_ = torch.randn(10, 64, 5)\n",
    "output = m(input_[:,:,-1])\n",
    "print(output[1].unsqueeze(-1).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "962671e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-2.5338e-01,  5.4671e-01, -2.3050e-01, -7.2926e-01],\n",
       "         [ 1.1752e-03,  1.1226e+00,  3.1501e-01,  7.7106e-01],\n",
       "         [ 4.1628e-01, -1.0956e+00,  9.3177e-01,  1.1895e+00],\n",
       "         ...,\n",
       "         [-8.7740e-01, -7.5359e-01, -3.8453e-02, -1.2326e+00],\n",
       "         [ 4.4664e-01,  6.0821e-01,  1.4042e+00, -3.1158e-01],\n",
       "         [-2.1279e-01,  3.8654e-01, -8.8885e-01,  7.6134e-01]],\n",
       "\n",
       "        [[-2.5236e-01,  3.9307e-01,  1.5581e-01,  1.3284e+00],\n",
       "         [ 8.1830e-01,  1.5279e+00,  3.1880e-01, -4.1388e-01],\n",
       "         [-5.0392e-01,  1.2141e+00, -1.8075e+00,  4.7472e-02],\n",
       "         ...,\n",
       "         [-6.0203e-01,  4.5243e-01, -1.7072e-01, -2.5329e-01],\n",
       "         [-7.9795e-01,  4.6026e-01,  2.4228e+00, -4.1313e-02],\n",
       "         [-2.7699e-01, -7.7611e-01, -2.5134e+00, -7.2356e-01]],\n",
       "\n",
       "        [[-1.9027e-02,  1.2823e+00,  1.7713e+00, -1.2226e+00],\n",
       "         [ 5.6685e-01,  2.4027e-01,  1.2333e+00, -3.0240e-01],\n",
       "         [-9.1078e-01,  7.4009e-03,  1.6436e+00, -1.9370e-01],\n",
       "         ...,\n",
       "         [ 1.7855e+00,  3.3070e-01,  1.3802e+00, -2.1394e+00],\n",
       "         [ 5.3497e-02, -2.8220e-01,  4.6132e-01,  7.6302e-01],\n",
       "         [ 6.7177e-01, -2.2307e-01, -4.9449e-01, -4.4649e-01]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 3.0291e-01,  8.5838e-01,  5.2026e-01, -1.3889e+00],\n",
       "         [-5.5890e-01,  1.4520e+00, -1.4744e-01, -1.4669e-02],\n",
       "         [ 5.7643e-01,  9.7507e-01, -1.3274e-01, -7.3007e-01],\n",
       "         ...,\n",
       "         [-5.9831e-01, -2.7321e+00, -8.8701e-01, -1.6127e+00],\n",
       "         [ 9.4412e-01,  6.1059e-01, -2.2400e-01, -1.1964e-01],\n",
       "         [-4.5894e-02, -1.1626e-01, -1.1549e+00, -2.3846e-01]],\n",
       "\n",
       "        [[-3.5137e-01,  5.2023e-01,  8.7632e-01, -2.2872e+00],\n",
       "         [-2.2323e-01,  2.2114e+00, -5.6189e-01, -3.2471e-01],\n",
       "         [-5.3500e-02,  2.9284e-01, -5.9710e-01,  1.5438e-01],\n",
       "         ...,\n",
       "         [-3.0778e+00, -8.9899e-01,  9.7788e-01,  4.5750e-01],\n",
       "         [-1.3219e+00, -1.8621e-01,  2.8171e+00, -8.1414e-01],\n",
       "         [-2.6193e-01, -9.1728e-01, -2.3532e-01,  6.4902e-01]],\n",
       "\n",
       "        [[ 5.7848e-01,  7.3824e-01,  6.3966e-01,  1.7363e+00],\n",
       "         [ 6.0313e-01, -3.9442e-01,  8.2507e-01, -1.5459e-02],\n",
       "         [-1.7248e+00, -7.8360e-01,  4.7775e-01,  9.5563e-01],\n",
       "         ...,\n",
       "         [ 6.4018e-02,  4.3525e-01, -2.3696e+00, -1.2972e+00],\n",
       "         [-9.5408e-01,  1.3406e+00, -7.5551e-01, -1.1637e-02],\n",
       "         [-2.4815e-01, -7.7997e-01,  7.0947e-01, -1.1339e+00]]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_[:,:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32fb9d1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4, 11, 18, 29, 37, 41, 48, 63],\n",
       "        [ 7, 12, 17, 27, 34, 44, 51, 62],\n",
       "        [ 1, 14, 21, 27, 34, 46, 52, 59],\n",
       "        [ 7,  9, 21, 29, 32, 45, 48, 59],\n",
       "        [ 4,  9, 22, 28, 39, 43, 52, 58],\n",
       "        [ 3, 10, 16, 26, 32, 46, 51, 56],\n",
       "        [ 7, 10, 19, 30, 38, 41, 53, 56],\n",
       "        [ 1,  9, 18, 26, 38, 41, 52, 57],\n",
       "        [ 3, 13, 21, 26, 32, 44, 51, 63],\n",
       "        [ 0, 10, 22, 26, 36, 46, 51, 58]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peak_indices = output[1]\n",
    "peak_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b96d2176",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 4,  4,  4,  4],\n",
       "         [11, 11, 11, 11],\n",
       "         [18, 18, 18, 18],\n",
       "         [29, 29, 29, 29],\n",
       "         [37, 37, 37, 37],\n",
       "         [41, 41, 41, 41],\n",
       "         [48, 48, 48, 48],\n",
       "         [63, 63, 63, 63]],\n",
       "\n",
       "        [[ 7,  7,  7,  7],\n",
       "         [12, 12, 12, 12],\n",
       "         [17, 17, 17, 17],\n",
       "         [27, 27, 27, 27],\n",
       "         [34, 34, 34, 34],\n",
       "         [44, 44, 44, 44],\n",
       "         [51, 51, 51, 51],\n",
       "         [62, 62, 62, 62]],\n",
       "\n",
       "        [[ 1,  1,  1,  1],\n",
       "         [14, 14, 14, 14],\n",
       "         [21, 21, 21, 21],\n",
       "         [27, 27, 27, 27],\n",
       "         [34, 34, 34, 34],\n",
       "         [46, 46, 46, 46],\n",
       "         [52, 52, 52, 52],\n",
       "         [59, 59, 59, 59]],\n",
       "\n",
       "        [[ 7,  7,  7,  7],\n",
       "         [ 9,  9,  9,  9],\n",
       "         [21, 21, 21, 21],\n",
       "         [29, 29, 29, 29],\n",
       "         [32, 32, 32, 32],\n",
       "         [45, 45, 45, 45],\n",
       "         [48, 48, 48, 48],\n",
       "         [59, 59, 59, 59]],\n",
       "\n",
       "        [[ 4,  4,  4,  4],\n",
       "         [ 9,  9,  9,  9],\n",
       "         [22, 22, 22, 22],\n",
       "         [28, 28, 28, 28],\n",
       "         [39, 39, 39, 39],\n",
       "         [43, 43, 43, 43],\n",
       "         [52, 52, 52, 52],\n",
       "         [58, 58, 58, 58]],\n",
       "\n",
       "        [[ 3,  3,  3,  3],\n",
       "         [10, 10, 10, 10],\n",
       "         [16, 16, 16, 16],\n",
       "         [26, 26, 26, 26],\n",
       "         [32, 32, 32, 32],\n",
       "         [46, 46, 46, 46],\n",
       "         [51, 51, 51, 51],\n",
       "         [56, 56, 56, 56]],\n",
       "\n",
       "        [[ 7,  7,  7,  7],\n",
       "         [10, 10, 10, 10],\n",
       "         [19, 19, 19, 19],\n",
       "         [30, 30, 30, 30],\n",
       "         [38, 38, 38, 38],\n",
       "         [41, 41, 41, 41],\n",
       "         [53, 53, 53, 53],\n",
       "         [56, 56, 56, 56]],\n",
       "\n",
       "        [[ 1,  1,  1,  1],\n",
       "         [ 9,  9,  9,  9],\n",
       "         [18, 18, 18, 18],\n",
       "         [26, 26, 26, 26],\n",
       "         [38, 38, 38, 38],\n",
       "         [41, 41, 41, 41],\n",
       "         [52, 52, 52, 52],\n",
       "         [57, 57, 57, 57]],\n",
       "\n",
       "        [[ 3,  3,  3,  3],\n",
       "         [13, 13, 13, 13],\n",
       "         [21, 21, 21, 21],\n",
       "         [26, 26, 26, 26],\n",
       "         [32, 32, 32, 32],\n",
       "         [44, 44, 44, 44],\n",
       "         [51, 51, 51, 51],\n",
       "         [63, 63, 63, 63]],\n",
       "\n",
       "        [[ 0,  0,  0,  0],\n",
       "         [10, 10, 10, 10],\n",
       "         [22, 22, 22, 22],\n",
       "         [26, 26, 26, 26],\n",
       "         [36, 36, 36, 36],\n",
       "         [46, 46, 46, 46],\n",
       "         [51, 51, 51, 51],\n",
       "         [58, 58, 58, 58]]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peak_indices.unsqueeze(-1).expand(-1,-1,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21b82888",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 8])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peak_indices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9bd8d6e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 8, 4])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.gather(input_[:,:,-1], 1, peak_indices).unsqueeze(-1).expand(-1,-1,4).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdbb4af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a72d23e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-3.8037e-01, -1.4409e+00,  3.6781e-01, -3.1866e-01,  1.4484e+00,\n",
       "         -6.7730e-01,  6.0127e-01, -1.2655e+00, -1.1730e+00, -2.6237e-01,\n",
       "         -3.1045e-01,  1.7508e+00,  4.6951e-01,  9.5724e-01, -1.4991e-01,\n",
       "          3.3491e-01,  5.3231e-02, -1.7610e+00,  7.3879e-01, -2.6760e+00,\n",
       "         -2.0329e+00,  1.0827e-02, -1.1622e-01, -4.3586e-01, -1.8081e+00,\n",
       "         -7.9936e-01, -3.1625e-01, -8.0669e-01, -1.2031e+00,  1.0413e+00,\n",
       "         -7.4400e-01,  9.4321e-01,  2.9195e-01, -9.7320e-01, -3.1799e-01,\n",
       "         -8.3720e-02,  9.7643e-01,  1.9484e+00, -1.7267e+00,  1.8561e+00,\n",
       "         -6.0976e-02,  7.0732e-01,  3.3005e-01,  6.5367e-01,  1.1927e-01,\n",
       "         -2.3844e-01, -6.9365e-01, -1.7980e-01,  1.1770e+00, -6.1377e-01,\n",
       "         -1.0315e+00, -8.5601e-01, -4.2327e-01,  6.7735e-01,  4.1585e-01,\n",
       "         -1.9643e+00, -1.7473e+00, -6.1493e-01, -4.0734e-02, -3.5726e-01,\n",
       "         -2.7877e-01,  3.1244e-02,  3.9770e-01,  4.1022e-01],\n",
       "        [ 6.9350e-01, -8.3307e-01, -1.0442e+00, -2.3737e+00,  1.4424e-01,\n",
       "          1.3441e-01, -2.9198e+00,  1.7308e+00,  2.3421e-01, -5.2859e-01,\n",
       "         -1.5641e+00,  1.2012e-01,  2.5113e+00, -7.8522e-01, -4.3721e-01,\n",
       "          1.5793e-01,  6.7210e-01,  2.8224e+00, -4.7195e-01, -5.6277e-01,\n",
       "         -1.2061e+00,  5.6175e-01, -6.7884e-01,  1.1571e+00,  1.8056e-01,\n",
       "         -5.3887e-01, -1.3657e-01,  8.7496e-01,  2.8084e-01, -1.7903e+00,\n",
       "         -1.4038e+00, -2.6796e-01, -3.1433e-02, -9.7489e-01,  1.0834e+00,\n",
       "         -2.1072e-01,  4.7868e-01, -4.0564e-01, -2.0001e-01,  5.3630e-01,\n",
       "          8.7406e-01, -1.0116e+00, -7.8918e-02, -2.2423e+00,  2.9475e+00,\n",
       "         -7.7128e-01, -7.6766e-01,  8.3606e-01,  5.0545e-01, -1.9427e-01,\n",
       "         -9.7207e-02,  7.2512e-01, -4.7101e-01,  6.6521e-01, -1.0811e+00,\n",
       "          1.5006e-01, -1.6150e-01, -3.2115e-01, -1.1263e+00, -4.4546e-01,\n",
       "          5.6891e-01, -3.5607e-01,  2.3099e+00,  1.6033e+00],\n",
       "        [-2.0752e+00,  7.7341e-01, -2.6727e-01,  1.8751e-01, -6.0940e-01,\n",
       "          6.0944e-01, -1.4108e+00,  3.1203e-03, -4.8072e-01, -9.9840e-01,\n",
       "          8.1717e-01, -1.0638e-01, -1.7893e+00,  1.7493e-01,  1.1386e+00,\n",
       "          8.5546e-01, -2.0670e+00, -1.2002e+00, -6.4395e-01,  6.1791e-01,\n",
       "         -2.2141e+00,  1.2882e+00,  1.7538e-01, -9.7525e-01,  2.3889e-01,\n",
       "          4.8077e-01, -1.1755e+00,  1.2192e+00, -8.2630e-01,  4.5261e-01,\n",
       "          8.1841e-01, -3.0104e+00, -7.0711e-01,  3.7378e-01,  8.1556e-01,\n",
       "         -1.0174e+00, -2.3902e+00, -1.7000e+00, -2.3366e-01,  4.9063e-01,\n",
       "          5.3555e-01, -6.5442e-01,  2.1220e-01,  7.0825e-01,  1.3776e+00,\n",
       "         -2.8322e-01,  2.2152e+00, -8.3112e-02, -3.5214e-01,  1.8764e-01,\n",
       "         -1.5219e-01,  2.2210e-01,  6.4815e-01, -1.2891e+00,  1.9724e-01,\n",
       "          2.9747e-01,  4.6072e-01,  4.5589e-01,  3.7608e-01,  1.3346e+00,\n",
       "          4.2703e-01,  6.0358e-01,  2.6464e-01, -3.0602e-01],\n",
       "        [ 2.7904e-01,  9.2230e-02, -2.9154e-01, -6.2691e-01,  3.1000e-01,\n",
       "          2.3559e-01,  3.5310e-01,  1.4760e+00,  7.4521e-02,  1.1176e+00,\n",
       "         -1.2835e+00,  5.9577e-02,  9.9909e-01,  1.0195e+00, -2.1699e-01,\n",
       "         -1.0270e+00, -3.0272e-01,  4.2514e-01, -3.9363e-01, -1.6438e-01,\n",
       "          3.4968e-01,  7.3192e-01, -5.4211e-01, -5.0301e-01, -2.0769e-01,\n",
       "         -2.4310e+00, -1.5214e+00, -7.7463e-01, -8.0182e-02,  9.0667e-01,\n",
       "         -4.4414e-01, -3.5639e-01,  1.9366e+00, -2.1863e+00, -4.9349e-01,\n",
       "          5.6768e-01, -1.0332e+00, -1.2219e+00, -9.6603e-01,  1.1999e+00,\n",
       "          3.0172e-01,  8.3584e-01,  6.4119e-01, -2.8931e-01,  3.8169e-01,\n",
       "          1.3644e+00,  7.0751e-01,  6.6880e-01,  1.8265e+00, -1.1602e+00,\n",
       "         -1.5472e+00,  8.1203e-01, -1.8587e+00, -2.2253e+00,  1.6758e-01,\n",
       "          5.5950e-01,  7.4760e-02,  4.7406e-01,  1.8697e-01,  2.7890e+00,\n",
       "          7.5825e-01,  9.1183e-01, -1.0289e+00,  1.3215e+00],\n",
       "        [-7.5355e-01, -1.5293e-01,  1.4347e+00,  1.9545e+00,  2.7548e+00,\n",
       "         -9.7947e-01,  4.7328e-01,  6.4604e-01, -9.7107e-01,  1.0998e+00,\n",
       "          5.4136e-01, -7.5821e-01,  9.0757e-02, -4.9804e-01, -1.5801e-01,\n",
       "         -1.6941e+00,  1.4138e+00,  1.8368e+00, -6.2340e-01, -1.3102e+00,\n",
       "          6.0083e-01, -8.2281e-01,  3.0174e+00, -9.8067e-02, -6.0703e-01,\n",
       "         -2.3855e-01,  1.6712e+00, -1.4110e+00,  2.0579e+00,  1.2968e+00,\n",
       "         -1.6652e+00, -9.7166e-01,  1.0593e+00, -3.8476e-02, -9.7921e-01,\n",
       "          3.9467e-01, -1.0796e-01,  3.8569e-01,  2.7945e-01,  1.3225e+00,\n",
       "         -6.3006e-01, -9.0350e-01, -1.5991e+00,  1.5732e+00, -1.5017e-01,\n",
       "          5.9434e-01, -1.3585e+00, -1.5505e-01,  1.6080e+00,  7.1304e-01,\n",
       "          1.6725e+00, -1.8195e+00,  1.9854e+00, -1.1341e+00, -5.6066e-01,\n",
       "          9.4449e-03,  1.0704e+00,  1.2707e-02,  1.2732e+00,  8.2435e-01,\n",
       "          1.1487e+00,  7.5529e-01, -3.2125e-01,  5.0443e-03],\n",
       "        [-1.3264e+00,  1.1947e+00,  6.5978e-01,  1.6703e+00,  7.5315e-01,\n",
       "          3.6414e-01, -1.1745e+00, -1.6189e+00,  2.8456e-01,  1.0963e+00,\n",
       "          1.1424e+00, -1.3205e+00,  8.4574e-01, -9.3599e-01,  7.2446e-01,\n",
       "         -7.5704e-02,  1.3722e+00,  4.4162e-01,  9.0805e-02, -7.4782e-01,\n",
       "         -1.4284e+00, -1.1078e+00, -8.0655e-01,  1.0092e+00,  3.6252e-01,\n",
       "         -1.1027e+00,  1.9119e+00,  6.8152e-01,  1.4427e+00,  1.7744e+00,\n",
       "         -4.5984e-01, -1.1057e+00,  1.4637e+00, -3.9912e-01, -9.4308e-01,\n",
       "         -1.2667e+00, -1.7007e+00, -1.1263e+00,  3.8887e-02,  1.9813e-01,\n",
       "         -1.4519e+00, -2.1642e+00,  5.0126e-01,  3.1457e-01,  5.1345e-01,\n",
       "         -4.4681e-01,  8.1104e-01,  3.5933e-01, -1.6006e+00, -5.7186e-01,\n",
       "          3.3009e-01,  6.6312e-01, -8.1573e-01, -1.1405e+00, -1.0507e+00,\n",
       "         -4.5330e-01,  1.1455e+00, -7.4422e-01,  1.3355e-01,  7.1095e-03,\n",
       "         -1.5515e+00, -1.0806e+00,  3.8853e-01, -9.2937e-01],\n",
       "        [ 1.2040e+00, -3.2222e-02, -1.3116e+00, -1.5572e-01,  1.3660e+00,\n",
       "          5.6145e-01, -6.1659e-01,  1.7799e+00, -2.6122e+00,  4.4084e-01,\n",
       "          9.7115e-01,  5.6042e-02, -9.5519e-02, -1.3721e+00,  9.4907e-01,\n",
       "          4.9343e-01,  4.7340e-01,  1.6950e+00, -8.1468e-01,  2.8136e+00,\n",
       "         -8.8539e-01, -2.3686e-01, -2.3805e-01, -1.7201e+00, -1.4674e+00,\n",
       "          1.5735e-01, -1.0745e-01, -9.5118e-01, -1.6419e-01,  3.2982e-04,\n",
       "          8.7997e-01, -2.5502e-01, -1.4077e+00,  2.0876e-01,  2.4166e-01,\n",
       "          4.1729e-01, -3.4642e-01, -1.6595e-01,  5.9799e-01,  2.2830e-01,\n",
       "         -3.5374e-01,  1.4235e+00,  1.0324e+00, -1.0871e+00, -1.5109e-01,\n",
       "         -1.2041e-01,  7.4096e-02,  9.1012e-01,  4.3335e-01, -9.5479e-01,\n",
       "         -4.6236e-01, -3.5672e-01, -1.7824e-01,  6.8134e-01,  6.2060e-01,\n",
       "         -9.6107e-01,  1.4431e+00, -2.4210e+00, -1.8278e+00,  6.4020e-01,\n",
       "         -6.0730e-01,  2.1101e-02,  2.3387e-01, -1.4527e+00],\n",
       "        [-4.4776e-01,  1.3096e+00,  4.9257e-01, -3.9352e-02, -3.0842e-01,\n",
       "         -1.8605e+00, -6.7283e-01, -1.0006e+00,  5.6294e-01,  1.8228e+00,\n",
       "          1.2772e+00, -1.2124e+00,  1.0442e+00, -2.3272e-01, -1.1280e+00,\n",
       "         -4.4428e-01, -1.8092e+00,  1.2502e+00,  1.9627e+00,  3.6322e-01,\n",
       "          1.1189e+00,  1.7635e+00, -2.0273e-01,  5.5314e-01, -2.0833e+00,\n",
       "         -4.1755e-01,  8.2507e-01, -1.0828e+00, -1.3901e+00, -1.4019e+00,\n",
       "          1.3676e-01,  7.0329e-01, -1.3100e+00,  8.3501e-02,  1.3063e-01,\n",
       "          8.2404e-01,  5.9428e-01, -2.8910e-01,  1.0540e+00,  1.8912e-01,\n",
       "         -1.2545e+00,  1.7519e+00,  8.5245e-01,  7.9043e-01,  1.5885e-01,\n",
       "          1.1043e+00, -3.2737e+00,  1.4843e+00,  4.5880e-01, -1.7693e+00,\n",
       "          1.8089e-02,  3.8504e-03,  5.5033e-01, -2.0327e+00,  2.3782e-01,\n",
       "         -1.2808e+00,  1.2790e-01,  1.1913e+00,  4.4011e-01, -1.8729e-01,\n",
       "          3.4194e-01, -2.4870e-01, -8.8465e-01,  1.1342e+00],\n",
       "        [ 1.3033e+00, -1.9508e+00, -1.1771e-01,  2.3778e+00, -3.8580e-01,\n",
       "          3.2982e-01, -8.1050e-01,  1.4103e-01, -5.8711e-01, -7.0988e-01,\n",
       "          1.8854e-02, -1.6583e-01, -3.2999e-01,  4.4951e-01,  3.1708e-01,\n",
       "         -1.0339e+00, -4.8011e-01,  9.7151e-01,  9.8454e-01, -8.2007e-01,\n",
       "          6.7736e-01,  1.0441e+00, -4.1664e-02,  5.7484e-01,  6.8117e-01,\n",
       "         -7.3524e-01,  2.8257e+00,  1.3008e+00, -9.3298e-01, -9.3727e-01,\n",
       "         -1.1327e+00, -1.2403e+00,  2.1855e+00, -1.2132e+00, -7.4255e-01,\n",
       "          1.8237e+00, -1.7638e-01, -8.8709e-01, -8.2016e-01,  2.9712e-01,\n",
       "          5.6331e-01,  1.0387e+00,  4.4874e-01, -1.8233e-01,  1.1616e+00,\n",
       "          1.0545e+00,  6.3623e-01, -6.4571e-01,  1.2684e+00,  3.5489e-01,\n",
       "          4.6420e-01,  1.3271e+00, -1.0444e+00,  1.7629e-01,  2.2230e-01,\n",
       "          2.0595e-01, -5.0953e-01,  4.3696e-01, -2.2698e+00, -1.8069e+00,\n",
       "         -7.4126e-01,  1.0656e+00, -2.7012e-01,  1.4611e+00],\n",
       "        [ 9.2279e-01, -5.7755e-01, -5.3452e-02,  5.9949e-01, -9.8067e-01,\n",
       "         -2.0203e+00,  6.6278e-01,  1.2121e-01, -4.1525e-01, -5.3954e-01,\n",
       "          5.9044e-01, -1.8432e+00, -5.7478e-01, -4.3639e-01, -1.1265e+00,\n",
       "          1.9227e-01,  5.3162e-01, -1.9138e+00, -2.0113e+00,  3.8036e-01,\n",
       "          9.3774e-01,  3.2466e-01,  1.0487e+00, -1.4372e+00,  4.7130e-01,\n",
       "         -3.5348e-01,  1.2117e+00, -2.1979e-01, -7.4757e-02,  7.2153e-01,\n",
       "         -7.4541e-01, -1.8524e+00, -4.9607e-01,  6.6141e-01, -1.0286e+00,\n",
       "         -3.5282e-01,  1.8637e+00, -4.7652e-01, -1.3979e+00,  1.4751e-01,\n",
       "          5.0675e-01, -1.4563e+00,  4.8878e-01, -7.7388e-01,  3.1080e-01,\n",
       "         -6.5362e-01,  9.7081e-01,  5.8460e-01,  4.9585e-01, -6.2589e-01,\n",
       "          9.3448e-01,  1.6564e+00, -1.9286e-01, -1.1500e+00,  1.6069e+00,\n",
       "          8.2895e-01,  6.3022e-01,  6.4752e-02,  1.9697e+00, -1.4406e+00,\n",
       "         -2.0790e+00, -8.7987e-01, -4.8014e-01,  7.1401e-01]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_[:,:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28765682",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4, 11, 18, 29, 37, 39, 54, 58],\n",
       "        [ 5, 12, 17, 28, 34, 44, 53, 60],\n",
       "        [ 5, 15, 15, 30, 34, 46, 52, 59],\n",
       "        [ 7,  9, 21, 24, 32, 42, 48, 59],\n",
       "        [ 4,  7, 22, 26, 39, 45, 50, 61],\n",
       "        [ 5, 10, 16, 29, 32, 47, 47, 56],\n",
       "        [ 7,  7, 19, 31, 31, 42, 54, 56],\n",
       "        [ 4, 10, 23, 23, 31, 45, 52, 57],\n",
       "        [ 0, 14, 18, 27, 32, 46, 51, 57],\n",
       "        [ 3, 10, 22, 29, 36, 40, 51, 58]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m(input_[:,:-1,-1] - input_[:,1:,-1])[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cf96d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1788ed36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee55eda1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0, 12, 16, 27, 35, 41, 51, 56],\n",
       "        [ 6, 15, 23, 27, 32, 42, 55, 57],\n",
       "        [ 5,  8, 20, 24, 37, 43, 48, 57],\n",
       "        [ 3, 11, 16, 31, 35, 47, 53, 63],\n",
       "        [ 3, 13, 19, 31, 37, 47, 51, 58],\n",
       "        [ 0, 11, 21, 25, 36, 41, 48, 58],\n",
       "        [ 1,  9, 20, 29, 32, 41, 50, 61],\n",
       "        [ 1, 15, 17, 28, 37, 42, 50, 61],\n",
       "        [ 6, 15, 16, 31, 36, 47, 52, 61],\n",
       "        [ 2, 12, 22, 26, 35, 46, 48, 59]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = nn.AdaptiveMaxPool1d(8, return_indices=True)\n",
    "input_ = torch.randn(10, 64, 5)\n",
    "output = m(input_[:,:,-1])\n",
    "peak_values, peak_indices = output\n",
    "peak_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2049abe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5, 16,  5, 10, 15, 15, 16, 15],\n",
       "        [16,  8,  2,  2, 14,  5, 15,  9],\n",
       "        [ 2,  6, 13,  1, 15, 15,  8,  1],\n",
       "        [ 9,  1, 14, 13,  5,  2,  0,  1],\n",
       "        [16,  3,  4, 11, 12, 12, 12,  3],\n",
       "        [11,  4, 11,  8,  2,  8,  8,  0],\n",
       "        [ 6,  4,  0, 11,  5, 13,  2, 12],\n",
       "        [ 3, 13, 10,  0,  9,  6,  7,  9],\n",
       "        [10, 14,  4,  0, 10, 14,  1,  0],\n",
       "        [15,  6,  5,  8,  5,  9, 13, 15]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = torch.LongTensor([[ 8,  2,  5,  9,  2,  0,  9, 10],\n",
    "                            [ 5,  6,  3, 12,  7, 15, 12, 11],\n",
    "                            [ 0,  2,  1,  2,  8, 14, 10, 13],\n",
    "                            [ 9,  1, 15, 10,  7, 13,  4,  1],\n",
    "                            [10,  2, 10,  1, 10,  1,  5,  5],\n",
    "                            [11, 16,  6, 15,  5, 15,  5, 12],\n",
    "                            [10, 11,  8,  7,  7,  9, 13,  8],\n",
    "                            [14,  4, 12, 11,  5, 10,  6,  2],\n",
    "                            [15, 14,  2,  3, 15,  2, 10, 16],\n",
    "                            [ 4, 15, 15, 15, 11, 16,  7,  3]])\n",
    "\n",
    "\n",
    "lm_logits = torch.randn(10, 8, 17) # batch: 3, seq: 6, vocab_size:17\n",
    "pred_label = torch.argmax(lm_logits[..., :, :], dim=2, keepdim=False)\n",
    "pred_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "652b62e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_label = torch.argmax(lm_logits[..., :, :], dim=2, keepdim=False)\n",
    "loss_peak = torch.binary_cross_entropy_with_logits(peak_values, (pred_label == labels).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a306dd24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.4045, 1.8716, 0.1048, 1.4660, 0.7471, 1.5152, 1.6122, 1.3578],\n",
       "        [1.9298, 1.1566, 2.2494, 1.2845, 2.4682, 1.8715, 1.3995, 1.1963],\n",
       "        [1.7687, 2.7565, 1.1142, 1.2289, 1.3425, 1.2423, 1.7587, 1.4073],\n",
       "        [0.3071, 0.1185, 1.0681, 1.0482, 1.7305, 1.5252, 1.6395, 0.1502],\n",
       "        [1.1190, 2.2591, 1.1395, 1.6398, 2.3223, 1.7429, 1.4313, 1.4042],\n",
       "        [0.3216, 0.8361, 1.5679, 1.5592, 1.3657, 0.9944, 1.5584, 1.5849],\n",
       "        [2.1694, 0.8153, 1.1467, 1.6893, 1.6555, 1.9997, 1.1406, 1.8442],\n",
       "        [1.2873, 0.8420, 1.9848, 1.4536, 1.4695, 1.2708, 2.7784, 1.8248],\n",
       "        [1.4961, 0.1621, 2.0278, 0.7493, 1.8975, 0.9167, 1.7640, 0.7497],\n",
       "        [1.1968, 0.9521, 1.6895, 2.0793, 1.5666, 1.3747, 1.8195, 0.9044]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_peak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38b115c",
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ea35df",
   "metadata": {},
   "outputs": [],
   "source": [
    "(pred_label == labels).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7baab439",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([[ 0.9745,  0.6706,  0.7684,  0.7408,  2.8551,  2.4442,  0.5550,  1.3212,\n",
       "          0.3334,  1.7347,  1.7006,  0.9743,  0.6944,  1.1692,  0.8869,  0.6143,\n",
       "          1.4069,  0.8043,  1.9979,  1.2987,  0.4230,  1.3377,  0.6699,  1.2400,\n",
       "          1.1509,  1.2615,  0.5953,  2.8560,  1.1580,  1.5226,  0.5852,  0.3671,\n",
       "          0.5638,  0.5527,  0.4937,  1.7851,  1.6368,  1.2934,  1.8651, -0.0704,\n",
       "          0.8625,  1.2517,  2.5961,  0.9198,  2.8899,  2.9901,  0.8609,  0.9424,\n",
       "          0.3189,  0.3511,  0.3501,  1.9866,  1.1950,  0.2078,  0.9780,  0.9392,\n",
       "          0.9844,  1.1953,  0.4109,  0.7613,  0.2776,  0.7725,  0.3451,  0.3508],\n",
       "        [-0.0730,  0.7988,  0.9958,  1.4305,  0.7930,  0.6164, -0.5642,  2.7229,\n",
       "          1.3831,  0.5765,  1.2455,  1.0611,  0.1133,  1.0686,  1.3430,  1.4013,\n",
       "          0.6503,  1.1284,  0.8328,  1.2357,  1.6746,  1.3760,  1.6906,  1.1578,\n",
       "          1.5226,  2.2274,  0.7553,  1.6615,  1.1365,  1.2940,  1.2718,  0.7861,\n",
       "          0.7185,  1.4270,  0.8478,  0.9946,  0.7052,  0.8643, -0.6626,  0.1781,\n",
       "          1.2779,  0.1896,  0.2024,  0.4578,  1.6523,  0.4042,  1.5784,  1.1496,\n",
       "          1.2777,  1.8305,  1.9405,  0.9761,  2.9271,  2.1173,  0.1354,  1.5398,\n",
       "          2.1392,  2.4948,  1.7975,  1.8406,  1.1367,  1.6961,  0.0041,  1.0292],\n",
       "        [ 1.8206,  2.3853,  1.3436,  1.4197,  1.7299,  0.5376,  0.4658,  1.5638,\n",
       "          1.1075,  0.9808,  0.2690,  2.0347,  0.0988,  1.2410,  1.6808,  0.8815,\n",
       "          0.8021,  0.5316,  0.4126,  0.9008,  1.5457,  1.4183,  1.2027,  1.1968,\n",
       "          2.0649, -0.0071,  1.1972,  1.7858,  0.7352,  1.7988,  0.7341,  1.4635,\n",
       "          1.2629,  1.1411,  0.3936,  0.7108,  2.1085,  1.9547,  0.9437,  0.6955,\n",
       "          1.0193,  0.8396,  1.3121,  2.4135,  2.1172,  1.7648,  1.3825,  0.9800,\n",
       "          0.8562, -0.0318,  1.2107,  1.8061,  1.8654,  0.7924,  1.3482,  1.2040,\n",
       "          0.8766,  1.0304,  1.1164,  0.3487,  1.4187,  1.0132,  0.7073,  0.8106],\n",
       "        [ 1.6349,  0.8861,  0.9823,  1.2010,  0.3786,  0.4054,  0.8661,  1.4999,\n",
       "          2.5936,  1.5581,  1.0690,  1.3913,  2.1217,  2.5926,  1.2943,  2.3779,\n",
       "          0.5746,  1.1623,  1.0717,  1.5197,  1.4099,  1.3221,  1.1434,  0.7973,\n",
       "          1.4927,  0.8686,  2.1569,  1.8187,  0.8985,  0.9536,  2.2033,  1.0871,\n",
       "          1.2734,  1.8843,  1.8714,  2.0947,  1.4567,  1.4103,  0.4554,  0.5611,\n",
       "          1.3759,  0.8183,  2.3051,  1.8714,  0.6975,  1.2841,  1.9898,  1.5550,\n",
       "          1.6266,  0.6887,  0.5514,  1.5586,  0.7784,  1.0867,  0.7364,  1.1298,\n",
       "          1.1603,  0.7124,  0.3612,  2.2314,  0.9498,  1.7082,  1.4678,  2.6897],\n",
       "        [ 2.4929,  0.2046,  1.2143,  1.5984,  1.3602,  1.5005,  0.6319,  1.0092,\n",
       "          2.1212,  0.4036,  0.7671,  1.8904, -0.2986,  0.4734,  1.7223,  0.5629,\n",
       "          1.0576,  0.3222,  1.4900,  1.1858,  0.8551,  1.3853, -0.2785,  2.2457,\n",
       "          2.2886,  1.4049,  0.9118,  0.9804,  1.9960, -0.2816,  1.6338,  1.4519,\n",
       "         -0.1481,  1.1628,  0.8618,  2.4359,  0.4288,  1.6803,  1.2522,  0.1259,\n",
       "          1.0651,  0.0432,  1.3268,  2.3605,  2.3726,  0.9013,  1.4887,  1.9304,\n",
       "          0.9349,  3.1568,  0.5231,  1.1783,  1.2585,  1.6584,  2.1457,  1.0679,\n",
       "          0.7974,  0.4999,  0.6061,  2.3438,  2.1180,  0.2886,  0.6190,  0.5750],\n",
       "        [ 0.6786,  1.6960,  0.7494,  0.8033,  0.8446,  1.0365,  1.3938,  1.5574,\n",
       "          1.7903,  2.4117,  1.8818,  0.7698,  0.5200,  0.8754,  1.9497,  1.4675,\n",
       "          1.3262,  0.9210,  0.9777,  1.3692,  1.0291,  1.7329,  2.3135,  0.6726,\n",
       "          2.5264,  0.9491,  0.4024,  1.1749, -0.1204,  1.4989,  1.2089,  1.0847,\n",
       "          1.4498,  0.7906,  1.9220,  0.7132,  1.9692,  0.2060,  0.5254,  0.7956,\n",
       "          1.6870,  0.6472,  1.0902,  1.4644,  1.6198,  0.6007,  0.1072,  1.4107,\n",
       "          0.8345,  0.8040,  0.2062,  0.3730,  0.3792,  0.4072,  1.6127,  3.0214,\n",
       "          0.7568,  1.1333,  0.9971,  0.8398,  1.3974,  1.6930,  2.1037,  1.5506],\n",
       "        [ 1.0801,  1.6747,  1.0696,  2.3642,  0.7414,  1.3964,  0.0890,  0.7724,\n",
       "          2.4328,  1.1913,  1.1848,  1.8714,  1.5819,  1.1017,  1.7346,  2.8176,\n",
       "          0.6002,  1.8556,  0.9785,  1.4267,  3.0844,  0.6312,  0.5726,  0.4616,\n",
       "          0.4406,  0.7928,  1.2540,  1.7120,  0.9027,  0.7738,  1.0833,  1.8901,\n",
       "          0.9894,  0.5254,  1.8017,  0.4754,  0.4262,  1.9575,  1.2750,  1.1372,\n",
       "          1.7744,  2.8006,  0.4698,  1.5746,  1.8697,  1.5089,  0.9905,  1.1423,\n",
       "          1.0430,  1.2129,  0.4202,  0.3776,  1.0150,  1.5470, -0.0502,  1.2401,\n",
       "          0.9239,  1.6855,  1.0712,  1.8089,  0.5102,  1.1411,  1.2718, -0.2167],\n",
       "        [ 2.6811,  1.0404,  2.0387,  0.5296,  0.8920,  0.1342,  0.7912,  1.9242,\n",
       "          0.5270,  0.4579,  1.9263, -0.1761,  1.2858,  1.2129,  1.4033,  1.8735,\n",
       "          0.9796,  1.6359,  1.2669,  0.0673,  2.1515, -0.1522,  0.5726,  0.9148,\n",
       "          1.2016,  0.6516,  2.4282,  1.0516,  0.7784,  1.9775,  1.3017,  0.4801,\n",
       "          1.2223,  0.7903,  0.2828,  1.7611,  0.9060,  2.0798, -0.1547, -0.2888,\n",
       "          0.7551,  2.3519,  1.6256,  1.2780,  1.7629,  1.1117,  0.4380,  0.5171,\n",
       "          2.0991,  1.2858,  1.2093,  1.2026, -0.0490,  0.2411,  0.8041,  2.1903,\n",
       "          1.5147,  0.7313, -0.2316,  0.8727,  0.6309,  0.6868,  0.8405,  0.3955],\n",
       "        [ 1.0861,  1.6641,  1.3675,  1.0969,  0.4206,  0.8043,  1.4122,  2.4656,\n",
       "          0.2647,  0.4156,  1.5142,  1.2279,  1.5036,  1.1025,  0.9331,  1.3277,\n",
       "          0.8459,  1.1035,  0.6261,  1.7524,  1.6135,  0.6249,  0.2322,  1.6115,\n",
       "          1.4623,  1.0628,  1.9470,  1.5216,  0.5208,  1.4836,  0.8438,  0.8636,\n",
       "          2.0468,  0.6152,  0.8450,  1.1293,  1.9401,  0.7990,  1.2720,  1.5837,\n",
       "          3.3274,  1.2285,  0.8354,  1.0087,  1.1713,  1.1331,  2.0551,  1.2090,\n",
       "          0.1832,  0.5471,  0.4588,  1.7132,  1.9634,  0.8052,  1.0069,  1.5858,\n",
       "          0.6466,  1.2267,  0.9644,  1.0967,  1.5320,  1.4150,  0.8973,  1.3849],\n",
       "        [ 1.4440,  2.0312,  0.8108,  0.2154,  0.7268,  1.3815,  2.3245,  0.6933,\n",
       "          1.1142,  1.8343,  1.5586,  0.4273,  1.1828,  1.6846,  2.6431,  0.8478,\n",
       "          1.8797,  2.2952,  0.9415,  0.7781,  0.0651,  1.3943, -0.4656,  1.3804,\n",
       "          1.3695,  0.8774,  0.6670,  0.2596,  0.7246,  0.6448,  0.1188,  1.3270,\n",
       "          0.5623,  1.0681,  0.9197,  1.4607,  0.8945,  2.2440,  1.2376,  0.9267,\n",
       "          2.4354,  0.7781, -0.0522,  1.0661,  0.6800,  0.3780,  1.9760,  1.6953,\n",
       "          2.3130,  1.5831,  1.0097,  0.8017,  1.6876,  1.1263,  0.2698,  0.5758,\n",
       "          1.6809, -0.1375,  0.4375,  2.3168,  0.7928,  1.5215,  1.0281,  2.1278]]),\n",
       "indices=tensor([[1, 2, 2, 1, 2, 2, 2, 3, 3, 3, 1, 1, 0, 2, 1, 1, 1, 2, 2, 2, 0, 0, 1, 2,\n",
       "         2, 0, 3, 2, 4, 1, 4, 4, 0, 2, 3, 4, 4, 2, 1, 1, 0, 0, 0, 4, 3, 2, 4, 0,\n",
       "         1, 3, 4, 2, 4, 0, 4, 1, 3, 0, 4, 2, 4, 0, 4, 2],\n",
       "        [3, 2, 4, 0, 4, 3, 2, 2, 4, 0, 4, 4, 1, 4, 2, 0, 1, 1, 4, 3, 3, 4, 2, 4,\n",
       "         0, 1, 2, 1, 0, 4, 1, 3, 3, 2, 3, 2, 4, 1, 1, 1, 2, 1, 1, 2, 2, 0, 4, 4,\n",
       "         4, 0, 4, 2, 2, 0, 3, 2, 1, 1, 0, 1, 1, 1, 0, 2],\n",
       "        [1, 3, 1, 2, 2, 2, 1, 4, 2, 3, 3, 2, 2, 1, 4, 2, 2, 0, 3, 3, 3, 1, 3, 2,\n",
       "         4, 2, 0, 2, 4, 0, 2, 4, 1, 3, 2, 1, 4, 0, 1, 4, 1, 4, 1, 2, 3, 3, 3, 4,\n",
       "         0, 4, 1, 0, 0, 2, 4, 1, 1, 0, 4, 1, 2, 1, 1, 4],\n",
       "        [1, 1, 0, 2, 3, 0, 0, 0, 4, 1, 4, 4, 4, 2, 0, 2, 2, 1, 4, 0, 3, 0, 4, 0,\n",
       "         0, 0, 3, 4, 2, 1, 0, 0, 0, 3, 4, 3, 0, 2, 2, 3, 2, 3, 2, 3, 3, 1, 0, 3,\n",
       "         4, 1, 4, 4, 1, 0, 4, 1, 1, 1, 3, 3, 4, 0, 4, 2],\n",
       "        [4, 3, 4, 2, 1, 4, 0, 3, 0, 3, 2, 3, 0, 1, 3, 4, 1, 2, 1, 2, 0, 4, 0, 2,\n",
       "         4, 4, 4, 3, 0, 4, 2, 1, 1, 0, 2, 0, 1, 1, 4, 1, 2, 2, 3, 2, 3, 3, 4, 4,\n",
       "         4, 1, 1, 2, 1, 4, 4, 4, 1, 2, 0, 2, 2, 3, 3, 1],\n",
       "        [3, 1, 4, 1, 2, 0, 0, 2, 1, 4, 3, 3, 4, 0, 0, 1, 4, 1, 1, 1, 0, 1, 2, 3,\n",
       "         2, 1, 1, 4, 4, 3, 0, 2, 1, 1, 1, 2, 2, 0, 4, 0, 1, 0, 3, 0, 3, 2, 4, 0,\n",
       "         4, 1, 0, 1, 4, 3, 2, 4, 0, 1, 1, 3, 3, 0, 0, 3],\n",
       "        [3, 3, 1, 4, 1, 4, 1, 1, 1, 0, 0, 2, 2, 3, 0, 0, 2, 1, 1, 1, 0, 3, 1, 2,\n",
       "         1, 1, 3, 1, 2, 1, 2, 1, 1, 4, 1, 2, 0, 1, 1, 4, 1, 4, 4, 1, 0, 2, 1, 1,\n",
       "         0, 3, 2, 2, 3, 0, 1, 4, 3, 2, 4, 0, 3, 0, 2, 0],\n",
       "        [0, 1, 1, 1, 2, 0, 1, 4, 1, 0, 2, 4, 0, 2, 1, 3, 4, 1, 2, 2, 0, 2, 2, 1,\n",
       "         0, 2, 1, 2, 0, 3, 4, 2, 0, 0, 0, 4, 0, 4, 4, 3, 1, 4, 1, 1, 2, 3, 0, 4,\n",
       "         1, 2, 3, 4, 3, 0, 3, 2, 1, 0, 3, 3, 0, 0, 4, 1],\n",
       "        [2, 2, 0, 1, 0, 1, 1, 3, 4, 0, 2, 0, 4, 0, 0, 0, 3, 0, 0, 2, 0, 3, 3, 0,\n",
       "         3, 0, 3, 1, 2, 0, 3, 4, 0, 1, 2, 0, 4, 3, 2, 2, 2, 4, 1, 2, 3, 4, 0, 2,\n",
       "         2, 1, 0, 3, 0, 3, 4, 0, 2, 4, 2, 4, 1, 0, 1, 3],\n",
       "        [3, 3, 2, 3, 1, 2, 2, 4, 1, 1, 1, 4, 1, 0, 0, 2, 3, 1, 4, 1, 2, 3, 4, 2,\n",
       "         2, 3, 3, 1, 3, 4, 4, 2, 2, 0, 0, 4, 2, 0, 4, 0, 1, 2, 0, 3, 0, 2, 0, 3,\n",
       "         0, 2, 4, 1, 3, 4, 1, 4, 1, 0, 1, 2, 4, 0, 0, 4]]))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_logits = torch.randn(10, 64, 5)\n",
    "lm_logits.max(axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a8125513",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim, _ = nn.functional.softmax(lm_logits, dim=-1).max(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cf0c75c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.2298, 0.2237, 0.1806, 0.2741, 0.1664, 0.1391, 0.1543, 0.1691],\n",
       "         [0.1354, 0.1579, 0.3011, 0.2627, 0.2351, 0.1617, 0.2248, 0.1234],\n",
       "         [0.1998, 0.1513, 0.4888, 0.2503, 0.3447, 0.1898, 0.1751, 0.1926],\n",
       "         [0.2829, 0.3271, 0.2426, 0.2297, 0.1943, 0.1208, 0.2027, 0.1935],\n",
       "         [0.2947, 0.2885, 0.1398, 0.1813, 0.2162, 0.2102, 0.1742, 0.3733],\n",
       "         [0.1365, 0.4949, 0.1827, 0.2374, 0.2388, 0.3275, 0.2886, 0.3632],\n",
       "         [0.3551, 0.1695, 0.2136, 0.3067, 0.3219, 0.1887, 0.1495, 0.1463],\n",
       "         [0.3327, 0.2434, 0.1993, 0.2348, 0.3439, 0.2452, 0.3621, 0.1526],\n",
       "         [0.1734, 0.3103, 0.1786, 0.3588, 0.2217, 0.1905, 0.3474, 0.2389],\n",
       "         [0.5486, 0.3124, 0.1964, 0.2016, 0.3889, 0.1131, 0.3223, 0.2308]]),\n",
       " tensor([[0, 1, 2, 3, 4, 5, 6, 7],\n",
       "         [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "         [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "         [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "         [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "         [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "         [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "         [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "         [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "         [0, 1, 2, 3, 4, 5, 6, 7]]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adaPool = nn.AdaptiveMaxPool1d(8, return_indices=True)\n",
    "peak_values, peak_indices = adaPool(sim)\n",
    "peak_values, peak_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bf441f2c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# torch.gather(lm_logits, \n",
    "#            1, \n",
    "#            peak_indices.unsqueeze(-1).expand(-1,-1,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5c59b83f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim, _ = nn.functional.softmax(lm_logits, dim=-1).max(dim=-1)\n",
    "nn.functional.threshold(sim, 0.7, 0.0, inplace=False)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ea29f725",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2, 3, 4, 5, 6, 7],\n",
       "        [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "        [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "        [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "        [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "        [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "        [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "        [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "        [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "        [0, 1, 2, 3, 4, 5, 6, 7]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim, _ = nn.functional.softmax(lm_logits, dim=-1).max(dim=-1)\n",
    "sim = nn.functional.threshold(sim, 0.5, 0.0, inplace=False)\n",
    "_, peak_indices = adaPool(sim)\n",
    "peak_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "88f7df98",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labels = torch.LongTensor([[ 8,  2,  5,  9,  2,  0,  9, 10],\n",
    "                            [ 5,  6,  3, 12,  7, 15, 12, 11],\n",
    "                            [ 0,  2,  1,  2,  8, 14, 10, 13],\n",
    "                            [ 9,  1, 15, 10,  7, 13,  4,  1],\n",
    "                            [10,  2, 10,  1, 10,  1,  5,  5],\n",
    "                            [11, 16,  6, 15,  5, 15,  5, 12],\n",
    "                            [10, 11,  8,  7,  7,  9, 13,  8],\n",
    "                            [14,  4, 12, 11,  5, 10,  6,  2],\n",
    "                            [15, 14,  2,  3, 15,  2, 10, 16],\n",
    "                            [ 4, 15, 15, 15, 11, 16,  7,  3]])\n",
    "output_attention_mask = torch.ones((10, 8)).long()\n",
    "\n",
    "\n",
    "hidden_states = torch.randn(10, 8, 17) # batch: 3, seq: 8, vocab_size:17\n",
    "\n",
    "cos = nn.CosineSimilarity(dim=2, eps=1e-10)\n",
    "peak = -cos(hidden_states[:,:-1,:], hidden_states[:,1:,:])\n",
    "\n",
    "\n",
    "threshold = 0.0\n",
    "_, peak_indices = adaPool(nn.functional.threshold(peak, threshold, -1.0, inplace=False))\n",
    "peak_values = torch.gather(peak, 1, peak_indices)\n",
    "\n",
    "attention_mask = torch.ones_like(peak_indices, dtype=torch.long)\n",
    "word_embeddings = torch.gather(hidden_states, \n",
    "                               1, \n",
    "                               peak_indices.unsqueeze(-1).expand(-1,-1,8))\n",
    "\n",
    "\n",
    "# ctc_loss doesn't support fp16\n",
    "log_probs = nn.functional.log_softmax(lm_logits, dim=-1, dtype=torch.float32).transpose(0, 1)\n",
    "\n",
    "# input_lengths for ctc_loss is defined from RNN peak detection\n",
    "# this can be computed from attention_mask\n",
    "input_lengths = (attention_mask > 0).sum(-1)\n",
    "\n",
    "# assuming that padded tokens are filled with 'Ä '\n",
    "# unlike wav2vec we can get this information from given `output_attention_mask`\n",
    "labels_mask = (output_attention_mask > 0)\n",
    "target_lengths = labels_mask.sum(-1)\n",
    "flattened_targets = labels.masked_select(labels_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ba0d912e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.9432, -0.8977,  0.5507, -0.6983,  0.5680,  0.9546, -0.9493],\n",
       "        [ 0.5982, -0.2407,  0.9099, -0.5839,  0.3570,  0.6443,  0.2364],\n",
       "        [ 0.6419, -0.2350, -0.6919,  0.3350, -0.3584,  0.3171, -0.8422],\n",
       "        [-0.1181,  0.9154, -0.0295,  0.1802,  0.2820,  0.5055,  0.7339],\n",
       "        [-0.5956, -0.7757, -0.7029, -0.8798,  0.4919,  0.3820,  0.1950],\n",
       "        [ 0.7279, -0.3337, -0.0059,  0.1963, -0.0298, -0.8412,  0.0186],\n",
       "        [-0.8601,  0.8751, -0.3137, -0.2510,  0.5285,  0.2301, -0.2327],\n",
       "        [-0.3387, -0.7656, -0.5913,  0.5626, -0.9919,  0.3445,  0.9923],\n",
       "        [ 0.0132, -0.6010, -0.9743, -0.0888, -0.7851,  0.3863,  0.2800],\n",
       "        [-0.8826, -0.4796,  0.3370,  0.4261, -0.3293,  0.9938, -0.4268]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_arr = peak_max - torch.rand_like(peak) * (peak_max - peak_min)\n",
    "rand_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2cfd032e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.9432,  0.0124,  0.1436,  0.0238,  0.5680,  0.9546, -0.9493],\n",
       "        [ 0.5982, -0.2407,  0.2761, -0.5839,  0.0731,  0.6443,  0.2364],\n",
       "        [ 0.6419,  0.3042,  0.0478,  0.3350,  0.3929,  0.3171,  0.3497],\n",
       "        [-0.1181,  0.3853,  0.1831,  0.1802,  0.2820,  0.5055,  0.7339],\n",
       "        [ 0.0465, -0.7757, -0.7029, -0.8798,  0.1183,  0.0150,  0.1950],\n",
       "        [ 0.7279, -0.3337,  0.1123,  0.2518,  0.1331,  0.2686,  0.0612],\n",
       "        [-0.8601,  0.4496, -0.3137,  0.2583,  0.0453,  0.2301, -0.2327],\n",
       "        [ 0.1515,  0.3197,  0.3587,  0.0873, -0.9919,  0.1120,  0.9923],\n",
       "        [ 0.0132,  0.1219,  0.1486, -0.0888,  0.2875,  0.3863,  0.2800],\n",
       "        [-0.8826, -0.4796,  0.1007,  0.4261,  0.4980,  0.9938, -0.4268]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.where(peak > threshold, peak, rand_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "afc0813b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  8,   2,   5,   9,   2,   0,   9,  10, 220],\n",
       "        [  5,   6,   3,  12,   7,  15,  12,  11, 220],\n",
       "        [  0,   2,   1,   2,   8,  14,  10,  13, 220],\n",
       "        [  9,   1,  15,  10,   7,  13,   4,   1, 220],\n",
       "        [ 10,   2,  10,   1,  10,   1,   5,   5, 220],\n",
       "        [ 11,  16,   6,  15,   5,  15,   5,  12, 220],\n",
       "        [ 10,  11,   8,   7,   7,   9,  13,   8, 220],\n",
       "        [ 14,   4,  12,  11,   5,  10,   6,   2, 220],\n",
       "        [ 15,  14,   2,   3,  15,   2,  10,  16, 220],\n",
       "        [  4,  15,  15,  15,  11,  16,   7,   3, 220]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.ConstantPad2d((0,1,0,0), 220)(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5f0e4605",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.0000,  0.0124,  0.1436,  0.0238, -1.0000, -1.0000, -1.0000],\n",
       "        [-1.0000, -1.0000,  0.2761, -1.0000,  0.0731, -1.0000, -1.0000],\n",
       "        [-1.0000,  0.3042,  0.0478, -1.0000,  0.3929, -1.0000,  0.3497],\n",
       "        [-1.0000,  0.3853,  0.1831, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "        [ 0.0465, -1.0000, -1.0000, -1.0000,  0.1183,  0.0150, -1.0000],\n",
       "        [-1.0000, -1.0000,  0.1123,  0.2518,  0.1331,  0.2686,  0.0612],\n",
       "        [-1.0000,  0.4496, -1.0000,  0.2583,  0.0453, -1.0000, -1.0000],\n",
       "        [ 0.1515,  0.3197,  0.3587,  0.0873, -1.0000,  0.1120, -1.0000],\n",
       "        [-1.0000,  0.1219,  0.1486, -1.0000,  0.2875, -1.0000, -1.0000],\n",
       "        [-1.0000, -1.0000,  0.1007, -1.0000,  0.4980, -1.0000, -1.0000]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.functional.threshold(peak, threshold, -1.0, inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "03da7eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ctcloss_reference(log_probs, targets, input_lengths, target_lengths, blank=0, reduction='mean'):\n",
    "    input_lengths = torch.as_tensor(input_lengths, dtype=torch.long)\n",
    "    target_lengths = torch.as_tensor(target_lengths, dtype=torch.long)\n",
    "    dt = log_probs.dtype\n",
    "    log_probs = log_probs.double()  # we need the accuracy as we are not in logspace\n",
    "    targets = targets.long()\n",
    "    cum_target_lengths = target_lengths.cumsum(0)\n",
    "    losses = []\n",
    "    for i in range(log_probs.size(1)):\n",
    "        input_length = input_lengths[i].item()\n",
    "        target_length = target_lengths[i].item()\n",
    "        cum_target_length = cum_target_lengths[i].item()\n",
    "        # ==========================================================================================================\n",
    "        targets_prime = targets.new_full((2 * target_length + 1,), blank)\n",
    "        if targets.dim() == 2:\n",
    "            targets_prime[1::2] = targets[i, :target_length]\n",
    "        else:\n",
    "            targets_prime[1::2] = targets[cum_target_length - target_length:cum_target_length]\n",
    "        # ==========================================================================================================\n",
    "        probs = log_probs[:input_length, i].exp()\n",
    "        # ==========================================================================================================\n",
    "        alpha = log_probs.new_zeros((target_length * 2 + 1,))\n",
    "        alpha[0] = probs[0, blank]\n",
    "        alpha[1] = probs[0, targets_prime[1]]\n",
    "        mask_third = (targets_prime[:-2] != targets_prime[2:])\n",
    "        for t in range(1, input_length):\n",
    "            alpha_next = alpha.clone()\n",
    "            alpha_next[1:] += alpha[:-1]\n",
    "            alpha_next[2:] += torch.where(mask_third, alpha[:-2], alpha.new_zeros(1))\n",
    "            alpha = probs[t, targets_prime] * alpha_next\n",
    "        # ==========================================================================================================\n",
    "        print(alpha)\n",
    "        \n",
    "        losses.append(-alpha[-2:].sum().log()[None])\n",
    "    output = torch.cat(losses, 0)\n",
    "    if reduction == 'mean':\n",
    "        return (output / target_lengths.to(dtype=output.dtype, device=output.device)).mean()\n",
    "    elif reduction == 'sum':\n",
    "        return output.sum()\n",
    "    output = output.to(dt)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "efcd4633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4.6589e-13, 1.6884e-11, 9.3202e-12, 3.2218e-10, 1.3834e-10, 1.5293e-10,\n",
      "        5.2490e-10, 7.1434e-09, 3.2774e-09, 2.3075e-08, 4.9640e-09, 5.1073e-09,\n",
      "        1.4381e-10, 4.1844e-10, 5.6487e-13, 2.3971e-12, 0.0000e+00],\n",
      "       dtype=torch.float64)\n",
      "tensor([4.8645e-13, 4.2530e-11, 6.4957e-11, 3.4620e-10, 1.7610e-10, 3.1341e-10,\n",
      "        2.4851e-10, 2.1682e-10, 3.6141e-10, 5.3372e-09, 6.6471e-10, 5.8048e-09,\n",
      "        4.0460e-10, 2.2505e-10, 2.1111e-12, 2.7577e-12, 0.0000e+00],\n",
      "       dtype=torch.float64)\n",
      "tensor([1.0181e-13, 8.1449e-13, 2.8507e-12, 3.4741e-11, 1.3328e-10, 1.2749e-09,\n",
      "        3.1996e-10, 5.0960e-10, 1.0174e-09, 2.0520e-09, 2.3318e-09, 7.9496e-09,\n",
      "        3.3101e-10, 2.4294e-10, 6.2279e-13, 7.6347e-13, 0.0000e+00],\n",
      "       dtype=torch.float64)\n",
      "tensor([3.1852e-11, 1.9054e-11, 7.7957e-10, 5.4160e-09, 1.7177e-08, 1.4399e-08,\n",
      "        4.9155e-08, 6.6351e-08, 3.9770e-08, 2.2864e-07, 3.0181e-08, 1.2573e-08,\n",
      "        2.2648e-09, 1.7391e-09, 1.0833e-11, 5.0595e-11, 0.0000e+00],\n",
      "       dtype=torch.float64)\n",
      "tensor([3.1528e-11, 2.5385e-11, 1.0620e-09, 8.3943e-10, 1.0308e-08, 8.1120e-09,\n",
      "        3.8481e-09, 1.3478e-09, 2.9450e-09, 2.2283e-09, 4.6068e-10, 1.4372e-10,\n",
      "        6.1174e-11, 4.9439e-11, 2.1158e-12, 0.0000e+00, 0.0000e+00],\n",
      "       dtype=torch.float64)\n",
      "tensor([2.0558e-10, 5.6551e-10, 1.0752e-08, 1.6600e-09, 2.3069e-08, 2.4511e-09,\n",
      "        3.8442e-08, 3.6880e-09, 6.6893e-09, 3.5661e-09, 5.1142e-09, 4.8411e-10,\n",
      "        5.6475e-10, 1.9447e-10, 1.9473e-11, 1.8131e-12, 0.0000e+00],\n",
      "       dtype=torch.float64)\n",
      "tensor([1.8256e-11, 5.7215e-10, 3.5079e-09, 3.3015e-09, 5.2762e-08, 4.1711e-08,\n",
      "        2.2894e-07, 2.1913e-07, 1.1940e-07, 1.3354e-08, 9.3012e-11, 1.2691e-10,\n",
      "        3.2879e-12, 5.2935e-13, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "       dtype=torch.float64)\n",
      "tensor([2.0681e-11, 7.5816e-11, 1.4488e-10, 8.3379e-10, 2.3037e-09, 3.0559e-09,\n",
      "        1.2238e-08, 1.5140e-08, 1.7364e-09, 6.5445e-10, 8.0651e-12, 9.4295e-12,\n",
      "        1.1312e-12, 5.4087e-13, 1.7638e-13, 7.3857e-13, 0.0000e+00],\n",
      "       dtype=torch.float64)\n",
      "tensor([2.6752e-11, 4.1416e-10, 9.4753e-10, 7.6938e-10, 1.2740e-08, 5.9287e-09,\n",
      "        1.4155e-08, 2.3019e-09, 1.2814e-08, 2.1417e-08, 1.8601e-08, 4.9054e-09,\n",
      "        4.9689e-10, 1.7497e-11, 2.8982e-11, 3.5268e-12, 0.0000e+00],\n",
      "       dtype=torch.float64)\n",
      "tensor([2.2034e-12, 5.2046e-12, 4.1134e-11, 1.6774e-09, 3.5054e-10, 1.4931e-09,\n",
      "        2.8088e-10, 3.2341e-10, 3.9314e-11, 2.1617e-11, 5.1659e-12, 5.0176e-12,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "       dtype=torch.float64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(inf, dtype=torch.float64)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctcloss_reference(log_probs, flattened_targets, input_lengths, target_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a168d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f498516",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b802d7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "41fd08bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from transformers import GPT2Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "82b6d927",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_dir = \"/data4/yoomcache\"\n",
    "model_cache_dir = os.path.join(cache_dir, 'huggingface')\n",
    "data_cache_dir = os.path.join(cache_dir, 'datasets')\n",
    "checkpoint_dir = os.path.join(cache_dir, 'checkpoint')\n",
    "\n",
    "wav2vec_pretrained = \"facebook/wav2vec2-base\"\n",
    "gpt_pretrained = \"gpt2\"\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(gpt_pretrained,\n",
    "                                          cache_dir=model_cache_dir,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a024247",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decoder[50256]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cebfdb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = [379,287,319,281,329,355,326,838,284,1315,1105,416,642,807,554,351,257,1160,718,1478,767,1367,1511,1542,1467,604,286,422,340,1440,428,1115,2534,362,290,1936,357,352,2237,1679,1081,632,2319,318,706,513,2608,1596,407,307,860,2026,477,2242,1811,468,530,383,475,644,393,555,1114,3624,262,517,2681,678,787,373,2579,618,2048,651,770,734,818,1248,3439,3598,466,198,423,4570,510,314,3016,389,1675,2808,4747,317,460,1629,1867,3126,5193,4353,503,625,1002,550,464,345,1577,587,465,1987,1550,4153,4974,1234,836,5996,1318,6073,2310,4317,561,4019,887,347,5214,523,5441,1320,657,843,350,857,1802,939,655,5867,546,511,5433,925,481,327,1026,1011,1141,309,777,256,3412,5946,5137,467,7265,883,1406,1729,617,285,339,5846,3933,2263,356,6640,5014,612,1212,921,845,337,3261,4457,6337,275,6135,547,366,1972,1838,1649,1890,311,645,376,360,663,367,406,739,1892,2293,2953,1052,6298,611,7632,7175,279,300,2080,5365,7982,9796,703,371,534,597,775,1642,8190,7618,7600,269,867,4764,402,8646,743,1394,288,569,1595,8093,750,1342,5021,1029,2893,1402,1016,8454,878,6740,532,4101,6454,374,714,1858,399,780,679,8644,635,308,2148,370,881,661,1374,3478,412,3501,691,17,289,8699,1626,749,264,674,484,1877,810,1532,449,1244,11323,9773,479,7863,7337,616,1439,866,3574,474,3294,9225,1262,1588,8257,662,1757,8915,2773,9508,508,6885,2251,509,531,1263,2750,607,277,336,628,32,302,13454,940,2514,10053,1422,1111,1881,299,2753,588,9166,4900,1474,4930,1625,1722,572,1804,7323,7192,7930,19,3899,543,15495,2111,16677,5323,3607,16,832,9698,3268,656,8541,10083,2125,1231,1314,520,7724,609,13151,1719,981,2202,837,1392,8854,1107,911,717,4622,784,21,1718,5688,736,15143,18,20,3236,9193,8275,6702,772,765,2495,2025,1731,1415,471,440,2222,3271,1485,2063,3011,1065,5125,2061,1400,266,2795,890,442,2407,791,5357,2504,4858,3035,1135,3190,3938,10495,922,973,4047,575,1433,968,629,19048,23,13539,3237,9826,1157,9415,584,10190,9849,815,4650,2972,40,1064,1148,991,3633,1270,880,3336,3224,1639,4646,14956,621,2215,2383,1043,3125,2481,5729,781,852,2670,5199,6079,12279,19035,1537,649,3769,5390,22,15629,14436,10048,4874,5180,10460,1816,1828,2805,2211,4619,1218,1194,3152,978,427,2331,1282,790,2321,2327,1870,3260,2329,1495,3198,13037,4441,595,1682,1544,4632,1558,9775,9907,2075,9919,1688,3426,2921,18523,1954,19038,1593,892,17342,1119,13343,7473,5115,2067,2440,851,21409,2312,2011,1168,34,2078,19710,3737,583,1946,25500,6986,1239,10261,1983,33,2396,2627,20299,15349,3226,51,47,1737,8131,1366,1507,2208,3269,2623,7796,4366,3088,1238,764,25181,1355,7683,2932,938,640,1017,12168,606,6104,599,6547,18693,2793,2141,9661,760,1249,16003,4042,1022,1049,783,6635,1913,44,1139,3945,3181,1853,4995,8308,3132,5598,2408,2492,19409,3682,1222,2094,2548,15696,3267,1101,17501,16226,821,26,12713,2813,1903,7003,23871,2727,3578,1290,1957,49,553,2901,2266,20416,22986,21355,2682,1169,1088,2948,8684,751,1471,4955,3050,27829,1321,304,1388,1201,943,19884,7945,2718,900,3901,850,2949,21761,766,3700,19755,2192,1327,24,13374,673,5566,2900,21148,3098,37,20064,1680,526,1959,2091,2124,2102,3220,1178,3510,7650,2227,13,23134,1375,779,1821,18395,5179,3717,3977,987,]\n",
    "\n",
    "for idx in lst:\n",
    "    print(tokenizer.decoder[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1784749d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '!',\n",
       " 1: '\"',\n",
       " 2: '#',\n",
       " 3: '$',\n",
       " 4: '%',\n",
       " 5: '&',\n",
       " 6: \"'\",\n",
       " 7: '(',\n",
       " 8: ')',\n",
       " 9: '*',\n",
       " 10: '+',\n",
       " 11: ',',\n",
       " 12: '-',\n",
       " 13: '.',\n",
       " 14: '/',\n",
       " 15: '0',\n",
       " 16: '1',\n",
       " 17: '2',\n",
       " 18: '3',\n",
       " 19: '4',\n",
       " 20: '5',\n",
       " 21: '6',\n",
       " 22: '7',\n",
       " 23: '8',\n",
       " 24: '9',\n",
       " 25: ':',\n",
       " 26: ';',\n",
       " 27: '<',\n",
       " 28: '=',\n",
       " 29: '>',\n",
       " 30: '?',\n",
       " 31: '@',\n",
       " 32: 'A',\n",
       " 33: 'B',\n",
       " 34: 'C',\n",
       " 35: 'D',\n",
       " 36: 'E',\n",
       " 37: 'F',\n",
       " 38: 'G',\n",
       " 39: 'H',\n",
       " 40: 'I',\n",
       " 41: 'J',\n",
       " 42: 'K',\n",
       " 43: 'L',\n",
       " 44: 'M',\n",
       " 45: 'N',\n",
       " 46: 'O',\n",
       " 47: 'P',\n",
       " 48: 'Q',\n",
       " 49: 'R',\n",
       " 50: 'S',\n",
       " 51: 'T',\n",
       " 52: 'U',\n",
       " 53: 'V',\n",
       " 54: 'W',\n",
       " 55: 'X',\n",
       " 56: 'Y',\n",
       " 57: 'Z',\n",
       " 58: '[',\n",
       " 59: '\\\\',\n",
       " 60: ']',\n",
       " 61: '^',\n",
       " 62: '_',\n",
       " 63: '`',\n",
       " 64: 'a',\n",
       " 65: 'b',\n",
       " 66: 'c',\n",
       " 67: 'd',\n",
       " 68: 'e',\n",
       " 69: 'f',\n",
       " 70: 'g',\n",
       " 71: 'h',\n",
       " 72: 'i',\n",
       " 73: 'j',\n",
       " 74: 'k',\n",
       " 75: 'l',\n",
       " 76: 'm',\n",
       " 77: 'n',\n",
       " 78: 'o',\n",
       " 79: 'p',\n",
       " 80: 'q',\n",
       " 81: 'r',\n",
       " 82: 's',\n",
       " 83: 't',\n",
       " 84: 'u',\n",
       " 85: 'v',\n",
       " 86: 'w',\n",
       " 87: 'x',\n",
       " 88: 'y',\n",
       " 89: 'z',\n",
       " 90: '{',\n",
       " 91: '|',\n",
       " 92: '}',\n",
       " 93: '~',\n",
       " 94: 'Â¡',\n",
       " 95: 'Â¢',\n",
       " 96: 'Â£',\n",
       " 97: 'Â¤',\n",
       " 98: 'Â¥',\n",
       " 99: 'Â¦',\n",
       " 100: 'Â§',\n",
       " 101: 'Â¨',\n",
       " 102: 'Â©',\n",
       " 103: 'Âª',\n",
       " 104: 'Â«',\n",
       " 105: 'Â¬',\n",
       " 106: 'Â®',\n",
       " 107: 'Â¯',\n",
       " 108: 'Â°',\n",
       " 109: 'Â±',\n",
       " 110: 'Â²',\n",
       " 111: 'Â³',\n",
       " 112: 'Â´',\n",
       " 113: 'Âµ',\n",
       " 114: 'Â¶',\n",
       " 115: 'Â·',\n",
       " 116: 'Â¸',\n",
       " 117: 'Â¹',\n",
       " 118: 'Âº',\n",
       " 119: 'Â»',\n",
       " 120: 'Â¼',\n",
       " 121: 'Â½',\n",
       " 122: 'Â¾',\n",
       " 123: 'Â¿',\n",
       " 124: 'Ã',\n",
       " 125: 'Ã',\n",
       " 126: 'Ã',\n",
       " 127: 'Ã',\n",
       " 128: 'Ã',\n",
       " 129: 'Ã',\n",
       " 130: 'Ã',\n",
       " 131: 'Ã',\n",
       " 132: 'Ã',\n",
       " 133: 'Ã',\n",
       " 134: 'Ã',\n",
       " 135: 'Ã',\n",
       " 136: 'Ã',\n",
       " 137: 'Ã',\n",
       " 138: 'Ã',\n",
       " 139: 'Ã',\n",
       " 140: 'Ã',\n",
       " 141: 'Ã',\n",
       " 142: 'Ã',\n",
       " 143: 'Ã',\n",
       " 144: 'Ã',\n",
       " 145: 'Ã',\n",
       " 146: 'Ã',\n",
       " 147: 'Ã',\n",
       " 148: 'Ã',\n",
       " 149: 'Ã',\n",
       " 150: 'Ã',\n",
       " 151: 'Ã',\n",
       " 152: 'Ã',\n",
       " 153: 'Ã',\n",
       " 154: 'Ã',\n",
       " 155: 'Ã',\n",
       " 156: 'Ã ',\n",
       " 157: 'Ã¡',\n",
       " 158: 'Ã¢',\n",
       " 159: 'Ã£',\n",
       " 160: 'Ã¤',\n",
       " 161: 'Ã¥',\n",
       " 162: 'Ã¦',\n",
       " 163: 'Ã§',\n",
       " 164: 'Ã¨',\n",
       " 165: 'Ã©',\n",
       " 166: 'Ãª',\n",
       " 167: 'Ã«',\n",
       " 168: 'Ã¬',\n",
       " 169: 'Ã­',\n",
       " 170: 'Ã®',\n",
       " 171: 'Ã¯',\n",
       " 172: 'Ã°',\n",
       " 173: 'Ã±',\n",
       " 174: 'Ã²',\n",
       " 175: 'Ã³',\n",
       " 176: 'Ã´',\n",
       " 177: 'Ãµ',\n",
       " 178: 'Ã¶',\n",
       " 179: 'Ã·',\n",
       " 180: 'Ã¸',\n",
       " 181: 'Ã¹',\n",
       " 182: 'Ãº',\n",
       " 183: 'Ã»',\n",
       " 184: 'Ã¼',\n",
       " 185: 'Ã½',\n",
       " 186: 'Ã¾',\n",
       " 187: 'Ã¿',\n",
       " 188: 'Ä',\n",
       " 189: 'Ä',\n",
       " 190: 'Ä',\n",
       " 191: 'Ä',\n",
       " 192: 'Ä',\n",
       " 193: 'Ä',\n",
       " 194: 'Ä',\n",
       " 195: 'Ä',\n",
       " 196: 'Ä',\n",
       " 197: 'Ä',\n",
       " 198: 'Ä',\n",
       " 199: 'Ä',\n",
       " 200: 'Ä',\n",
       " 201: 'Ä',\n",
       " 202: 'Ä',\n",
       " 203: 'Ä',\n",
       " 204: 'Ä',\n",
       " 205: 'Ä',\n",
       " 206: 'Ä',\n",
       " 207: 'Ä',\n",
       " 208: 'Ä',\n",
       " 209: 'Ä',\n",
       " 210: 'Ä',\n",
       " 211: 'Ä',\n",
       " 212: 'Ä',\n",
       " 213: 'Ä',\n",
       " 214: 'Ä',\n",
       " 215: 'Ä',\n",
       " 216: 'Ä',\n",
       " 217: 'Ä',\n",
       " 218: 'Ä',\n",
       " 219: 'Ä',\n",
       " 220: 'Ä ',\n",
       " 221: 'Ä¡',\n",
       " 222: 'Ä¢',\n",
       " 223: 'Ä£',\n",
       " 224: 'Ä¤',\n",
       " 225: 'Ä¥',\n",
       " 226: 'Ä¦',\n",
       " 227: 'Ä§',\n",
       " 228: 'Ä¨',\n",
       " 229: 'Ä©',\n",
       " 230: 'Äª',\n",
       " 231: 'Ä«',\n",
       " 232: 'Ä¬',\n",
       " 233: 'Ä­',\n",
       " 234: 'Ä®',\n",
       " 235: 'Ä¯',\n",
       " 236: 'Ä°',\n",
       " 237: 'Ä±',\n",
       " 238: 'Ä²',\n",
       " 239: 'Ä³',\n",
       " 240: 'Ä´',\n",
       " 241: 'Äµ',\n",
       " 242: 'Ä¶',\n",
       " 243: 'Ä·',\n",
       " 244: 'Ä¸',\n",
       " 245: 'Ä¹',\n",
       " 246: 'Äº',\n",
       " 247: 'Ä»',\n",
       " 248: 'Ä¼',\n",
       " 249: 'Ä½',\n",
       " 250: 'Ä¾',\n",
       " 251: 'Ä¿',\n",
       " 252: 'Å',\n",
       " 253: 'Å',\n",
       " 254: 'Å',\n",
       " 255: 'Å',\n",
       " 256: 'Ä t',\n",
       " 257: 'Ä a',\n",
       " 258: 'he',\n",
       " 259: 'in',\n",
       " 260: 're',\n",
       " 261: 'on',\n",
       " 262: 'Ä the',\n",
       " 263: 'er',\n",
       " 264: 'Ä s',\n",
       " 265: 'at',\n",
       " 266: 'Ä w',\n",
       " 267: 'Ä o',\n",
       " 268: 'en',\n",
       " 269: 'Ä c',\n",
       " 270: 'it',\n",
       " 271: 'is',\n",
       " 272: 'an',\n",
       " 273: 'or',\n",
       " 274: 'es',\n",
       " 275: 'Ä b',\n",
       " 276: 'ed',\n",
       " 277: 'Ä f',\n",
       " 278: 'ing',\n",
       " 279: 'Ä p',\n",
       " 280: 'ou',\n",
       " 281: 'Ä an',\n",
       " 282: 'al',\n",
       " 283: 'ar',\n",
       " 284: 'Ä to',\n",
       " 285: 'Ä m',\n",
       " 286: 'Ä of',\n",
       " 287: 'Ä in',\n",
       " 288: 'Ä d',\n",
       " 289: 'Ä h',\n",
       " 290: 'Ä and',\n",
       " 291: 'ic',\n",
       " 292: 'as',\n",
       " 293: 'le',\n",
       " 294: 'Ä th',\n",
       " 295: 'ion',\n",
       " 296: 'om',\n",
       " 297: 'll',\n",
       " 298: 'ent',\n",
       " 299: 'Ä n',\n",
       " 300: 'Ä l',\n",
       " 301: 'st',\n",
       " 302: 'Ä re',\n",
       " 303: 've',\n",
       " 304: 'Ä e',\n",
       " 305: 'ro',\n",
       " 306: 'ly',\n",
       " 307: 'Ä be',\n",
       " 308: 'Ä g',\n",
       " 309: 'Ä T',\n",
       " 310: 'ct',\n",
       " 311: 'Ä S',\n",
       " 312: 'id',\n",
       " 313: 'ot',\n",
       " 314: 'Ä I',\n",
       " 315: 'ut',\n",
       " 316: 'et',\n",
       " 317: 'Ä A',\n",
       " 318: 'Ä is',\n",
       " 319: 'Ä on',\n",
       " 320: 'im',\n",
       " 321: 'am',\n",
       " 322: 'ow',\n",
       " 323: 'ay',\n",
       " 324: 'ad',\n",
       " 325: 'se',\n",
       " 326: 'Ä that',\n",
       " 327: 'Ä C',\n",
       " 328: 'ig',\n",
       " 329: 'Ä for',\n",
       " 330: 'ac',\n",
       " 331: 'Ä y',\n",
       " 332: 'ver',\n",
       " 333: 'ur',\n",
       " 334: 'Ä u',\n",
       " 335: 'ld',\n",
       " 336: 'Ä st',\n",
       " 337: 'Ä M',\n",
       " 338: \"'s\",\n",
       " 339: 'Ä he',\n",
       " 340: 'Ä it',\n",
       " 341: 'ation',\n",
       " 342: 'ith',\n",
       " 343: 'ir',\n",
       " 344: 'ce',\n",
       " 345: 'Ä you',\n",
       " 346: 'il',\n",
       " 347: 'Ä B',\n",
       " 348: 'Ä wh',\n",
       " 349: 'ol',\n",
       " 350: 'Ä P',\n",
       " 351: 'Ä with',\n",
       " 352: 'Ä 1',\n",
       " 353: 'ter',\n",
       " 354: 'ch',\n",
       " 355: 'Ä as',\n",
       " 356: 'Ä we',\n",
       " 357: 'Ä (',\n",
       " 358: 'nd',\n",
       " 359: 'ill',\n",
       " 360: 'Ä D',\n",
       " 361: 'if',\n",
       " 362: 'Ä 2',\n",
       " 363: 'ag',\n",
       " 364: 'ers',\n",
       " 365: 'ke',\n",
       " 366: 'Ä \"',\n",
       " 367: 'Ä H',\n",
       " 368: 'em',\n",
       " 369: 'Ä con',\n",
       " 370: 'Ä W',\n",
       " 371: 'Ä R',\n",
       " 372: 'her',\n",
       " 373: 'Ä was',\n",
       " 374: 'Ä r',\n",
       " 375: 'od',\n",
       " 376: 'Ä F',\n",
       " 377: 'ul',\n",
       " 378: 'ate',\n",
       " 379: 'Ä at',\n",
       " 380: 'ri',\n",
       " 381: 'pp',\n",
       " 382: 'ore',\n",
       " 383: 'Ä The',\n",
       " 384: 'Ä se',\n",
       " 385: 'us',\n",
       " 386: 'Ä pro',\n",
       " 387: 'Ä ha',\n",
       " 388: 'um',\n",
       " 389: 'Ä are',\n",
       " 390: 'Ä de',\n",
       " 391: 'ain',\n",
       " 392: 'and',\n",
       " 393: 'Ä or',\n",
       " 394: 'igh',\n",
       " 395: 'est',\n",
       " 396: 'ist',\n",
       " 397: 'ab',\n",
       " 398: 'rom',\n",
       " 399: 'Ä N',\n",
       " 400: 'th',\n",
       " 401: 'Ä com',\n",
       " 402: 'Ä G',\n",
       " 403: 'un',\n",
       " 404: 'op',\n",
       " 405: '00',\n",
       " 406: 'Ä L',\n",
       " 407: 'Ä not',\n",
       " 408: 'ess',\n",
       " 409: 'Ä ex',\n",
       " 410: 'Ä v',\n",
       " 411: 'res',\n",
       " 412: 'Ä E',\n",
       " 413: 'ew',\n",
       " 414: 'ity',\n",
       " 415: 'ant',\n",
       " 416: 'Ä by',\n",
       " 417: 'el',\n",
       " 418: 'os',\n",
       " 419: 'ort',\n",
       " 420: 'oc',\n",
       " 421: 'qu',\n",
       " 422: 'Ä from',\n",
       " 423: 'Ä have',\n",
       " 424: 'Ä su',\n",
       " 425: 'ive',\n",
       " 426: 'ould',\n",
       " 427: 'Ä sh',\n",
       " 428: 'Ä this',\n",
       " 429: 'nt',\n",
       " 430: 'ra',\n",
       " 431: 'pe',\n",
       " 432: 'ight',\n",
       " 433: 'art',\n",
       " 434: 'ment',\n",
       " 435: 'Ä al',\n",
       " 436: 'ust',\n",
       " 437: 'end',\n",
       " 438: '--',\n",
       " 439: 'all',\n",
       " 440: 'Ä O',\n",
       " 441: 'ack',\n",
       " 442: 'Ä ch',\n",
       " 443: 'Ä le',\n",
       " 444: 'ies',\n",
       " 445: 'red',\n",
       " 446: 'ard',\n",
       " 447: 'Ã¢Ä¢',\n",
       " 448: 'out',\n",
       " 449: 'Ä J',\n",
       " 450: 'Ä ab',\n",
       " 451: 'ear',\n",
       " 452: 'iv',\n",
       " 453: 'ally',\n",
       " 454: 'our',\n",
       " 455: 'ost',\n",
       " 456: 'gh',\n",
       " 457: 'pt',\n",
       " 458: 'Ä pl',\n",
       " 459: 'ast',\n",
       " 460: 'Ä can',\n",
       " 461: 'ak',\n",
       " 462: 'ome',\n",
       " 463: 'ud',\n",
       " 464: 'The',\n",
       " 465: 'Ä his',\n",
       " 466: 'Ä do',\n",
       " 467: 'Ä go',\n",
       " 468: 'Ä has',\n",
       " 469: 'ge',\n",
       " 470: \"'t\",\n",
       " 471: 'Ä U',\n",
       " 472: 'rou',\n",
       " 473: 'Ä sa',\n",
       " 474: 'Ä j',\n",
       " 475: 'Ä but',\n",
       " 476: 'Ä wor',\n",
       " 477: 'Ä all',\n",
       " 478: 'ect',\n",
       " 479: 'Ä k',\n",
       " 480: 'ame',\n",
       " 481: 'Ä will',\n",
       " 482: 'ok',\n",
       " 483: 'Ä whe',\n",
       " 484: 'Ä they',\n",
       " 485: 'ide',\n",
       " 486: '01',\n",
       " 487: 'ff',\n",
       " 488: 'ich',\n",
       " 489: 'pl',\n",
       " 490: 'ther',\n",
       " 491: 'Ä tr',\n",
       " 492: '..',\n",
       " 493: 'Ä int',\n",
       " 494: 'ie',\n",
       " 495: 'ure',\n",
       " 496: 'age',\n",
       " 497: 'Ä ne',\n",
       " 498: 'ial',\n",
       " 499: 'ap',\n",
       " 500: 'ine',\n",
       " 501: 'ice',\n",
       " 502: 'Ä me',\n",
       " 503: 'Ä out',\n",
       " 504: 'ans',\n",
       " 505: 'one',\n",
       " 506: 'ong',\n",
       " 507: 'ions',\n",
       " 508: 'Ä who',\n",
       " 509: 'Ä K',\n",
       " 510: 'Ä up',\n",
       " 511: 'Ä their',\n",
       " 512: 'Ä ad',\n",
       " 513: 'Ä 3',\n",
       " 514: 'Ä us',\n",
       " 515: 'ated',\n",
       " 516: 'ous',\n",
       " 517: 'Ä more',\n",
       " 518: 'ue',\n",
       " 519: 'og',\n",
       " 520: 'Ä St',\n",
       " 521: 'ind',\n",
       " 522: 'ike',\n",
       " 523: 'Ä so',\n",
       " 524: 'ime',\n",
       " 525: 'per',\n",
       " 526: '.\"',\n",
       " 527: 'ber',\n",
       " 528: 'iz',\n",
       " 529: 'act',\n",
       " 530: 'Ä one',\n",
       " 531: 'Ä said',\n",
       " 532: 'Ä -',\n",
       " 533: 'are',\n",
       " 534: 'Ä your',\n",
       " 535: 'cc',\n",
       " 536: 'Ä Th',\n",
       " 537: 'Ä cl',\n",
       " 538: 'ep',\n",
       " 539: 'ake',\n",
       " 540: 'able',\n",
       " 541: 'ip',\n",
       " 542: 'Ä cont',\n",
       " 543: 'Ä which',\n",
       " 544: 'ia',\n",
       " 545: 'Ä im',\n",
       " 546: 'Ä about',\n",
       " 547: 'Ä were',\n",
       " 548: 'very',\n",
       " 549: 'ub',\n",
       " 550: 'Ä had',\n",
       " 551: 'Ä en',\n",
       " 552: 'Ä comp',\n",
       " 553: ',\"',\n",
       " 554: 'Ä In',\n",
       " 555: 'Ä un',\n",
       " 556: 'Ä ag',\n",
       " 557: 'ire',\n",
       " 558: 'ace',\n",
       " 559: 'au',\n",
       " 560: 'ary',\n",
       " 561: 'Ä would',\n",
       " 562: 'ass',\n",
       " 563: 'ry',\n",
       " 564: 'Ä Ã¢Ä¢',\n",
       " 565: 'cl',\n",
       " 566: 'ook',\n",
       " 567: 'ere',\n",
       " 568: 'so',\n",
       " 569: 'Ä V',\n",
       " 570: 'ign',\n",
       " 571: 'ib',\n",
       " 572: 'Ä off',\n",
       " 573: 'Ä te',\n",
       " 574: 'ven',\n",
       " 575: 'Ä Y',\n",
       " 576: 'ile',\n",
       " 577: 'ose',\n",
       " 578: 'ite',\n",
       " 579: 'orm',\n",
       " 580: 'Ä 201',\n",
       " 581: 'Ä res',\n",
       " 582: 'Ä man',\n",
       " 583: 'Ä per',\n",
       " 584: 'Ä other',\n",
       " 585: 'ord',\n",
       " 586: 'ult',\n",
       " 587: 'Ä been',\n",
       " 588: 'Ä like',\n",
       " 589: 'ase',\n",
       " 590: 'ance',\n",
       " 591: 'ks',\n",
       " 592: 'ays',\n",
       " 593: 'own',\n",
       " 594: 'ence',\n",
       " 595: 'Ä dis',\n",
       " 596: 'ction',\n",
       " 597: 'Ä any',\n",
       " 598: 'Ä app',\n",
       " 599: 'Ä sp',\n",
       " 600: 'int',\n",
       " 601: 'ress',\n",
       " 602: 'ations',\n",
       " 603: 'ail',\n",
       " 604: 'Ä 4',\n",
       " 605: 'ical',\n",
       " 606: 'Ä them',\n",
       " 607: 'Ä her',\n",
       " 608: 'ount',\n",
       " 609: 'Ä Ch',\n",
       " 610: 'Ä ar',\n",
       " 611: 'Ä if',\n",
       " 612: 'Ä there',\n",
       " 613: 'Ä pe',\n",
       " 614: 'Ä year',\n",
       " 615: 'av',\n",
       " 616: 'Ä my',\n",
       " 617: 'Ä some',\n",
       " 618: 'Ä when',\n",
       " 619: 'ough',\n",
       " 620: 'ach',\n",
       " 621: 'Ä than',\n",
       " 622: 'ru',\n",
       " 623: 'ond',\n",
       " 624: 'ick',\n",
       " 625: 'Ä over',\n",
       " 626: 'vel',\n",
       " 627: 'Ä qu',\n",
       " 628: 'ÄÄ',\n",
       " 629: 'Ä sc',\n",
       " 630: 'reat',\n",
       " 631: 'ree',\n",
       " 632: 'Ä It',\n",
       " 633: 'ound',\n",
       " 634: 'port',\n",
       " 635: 'Ä also',\n",
       " 636: 'Ä part',\n",
       " 637: 'fter',\n",
       " 638: 'Ä kn',\n",
       " 639: 'Ä bec',\n",
       " 640: 'Ä time',\n",
       " 641: 'ens',\n",
       " 642: 'Ä 5',\n",
       " 643: 'ople',\n",
       " 644: 'Ä what',\n",
       " 645: 'Ä no',\n",
       " 646: 'du',\n",
       " 647: 'mer',\n",
       " 648: 'ang',\n",
       " 649: 'Ä new',\n",
       " 650: '----',\n",
       " 651: 'Ä get',\n",
       " 652: 'ory',\n",
       " 653: 'ition',\n",
       " 654: 'ings',\n",
       " 655: 'Ä just',\n",
       " 656: 'Ä into',\n",
       " 657: 'Ä 0',\n",
       " 658: 'ents',\n",
       " 659: 'ove',\n",
       " 660: 'te',\n",
       " 661: 'Ä people',\n",
       " 662: 'Ä pre',\n",
       " 663: 'Ä its',\n",
       " 664: 'Ä rec',\n",
       " 665: 'Ä tw',\n",
       " 666: 'ian',\n",
       " 667: 'irst',\n",
       " 668: 'ark',\n",
       " 669: 'ors',\n",
       " 670: 'Ä work',\n",
       " 671: 'ade',\n",
       " 672: 'ob',\n",
       " 673: 'Ä she',\n",
       " 674: 'Ä our',\n",
       " 675: 'wn',\n",
       " 676: 'ink',\n",
       " 677: 'lic',\n",
       " 678: 'Ä 19',\n",
       " 679: 'Ä He',\n",
       " 680: 'ish',\n",
       " 681: 'nder',\n",
       " 682: 'ause',\n",
       " 683: 'Ä him',\n",
       " 684: 'ons',\n",
       " 685: 'Ä [',\n",
       " 686: 'Ä ro',\n",
       " 687: 'form',\n",
       " 688: 'ild',\n",
       " 689: 'ates',\n",
       " 690: 'vers',\n",
       " 691: 'Ä only',\n",
       " 692: 'oll',\n",
       " 693: 'Ä spe',\n",
       " 694: 'ck',\n",
       " 695: 'ell',\n",
       " 696: 'amp',\n",
       " 697: 'Ä acc',\n",
       " 698: 'Ä bl',\n",
       " 699: 'ious',\n",
       " 700: 'urn',\n",
       " 701: 'ft',\n",
       " 702: 'ood',\n",
       " 703: 'Ä how',\n",
       " 704: 'hed',\n",
       " 705: \"Ä '\",\n",
       " 706: 'Ä after',\n",
       " 707: 'aw',\n",
       " 708: 'Ä att',\n",
       " 709: 'ov',\n",
       " 710: 'ne',\n",
       " 711: 'Ä play',\n",
       " 712: 'erv',\n",
       " 713: 'ict',\n",
       " 714: 'Ä could',\n",
       " 715: 'itt',\n",
       " 716: 'Ä am',\n",
       " 717: 'Ä first',\n",
       " 718: 'Ä 6',\n",
       " 719: 'Ä act',\n",
       " 720: 'Ä $',\n",
       " 721: 'ec',\n",
       " 722: 'hing',\n",
       " 723: 'ual',\n",
       " 724: 'ull',\n",
       " 725: 'Ä comm',\n",
       " 726: 'oy',\n",
       " 727: 'old',\n",
       " 728: 'ces',\n",
       " 729: 'ater',\n",
       " 730: 'Ä fe',\n",
       " 731: 'Ä bet',\n",
       " 732: 'we',\n",
       " 733: 'iff',\n",
       " 734: 'Ä two',\n",
       " 735: 'ock',\n",
       " 736: 'Ä back',\n",
       " 737: ').',\n",
       " 738: 'ident',\n",
       " 739: 'Ä under',\n",
       " 740: 'rough',\n",
       " 741: 'sel',\n",
       " 742: 'xt',\n",
       " 743: 'Ä may',\n",
       " 744: 'round',\n",
       " 745: 'Ä po',\n",
       " 746: 'ph',\n",
       " 747: 'iss',\n",
       " 748: 'Ä des',\n",
       " 749: 'Ä most',\n",
       " 750: 'Ä did',\n",
       " 751: 'Ä add',\n",
       " 752: 'ject',\n",
       " 753: 'Ä inc',\n",
       " 754: 'fore',\n",
       " 755: 'Ä pol',\n",
       " 756: 'ont',\n",
       " 757: 'Ä again',\n",
       " 758: 'clud',\n",
       " 759: 'tern',\n",
       " 760: 'Ä know',\n",
       " 761: 'Ä need',\n",
       " 762: 'Ä cons',\n",
       " 763: 'Ä co',\n",
       " 764: 'Ä .',\n",
       " 765: 'Ä want',\n",
       " 766: 'Ä see',\n",
       " 767: 'Ä 7',\n",
       " 768: 'ning',\n",
       " 769: 'iew',\n",
       " 770: 'Ä This',\n",
       " 771: 'ced',\n",
       " 772: 'Ä even',\n",
       " 773: 'Ä ind',\n",
       " 774: 'ty',\n",
       " 775: 'Ä We',\n",
       " 776: 'ath',\n",
       " 777: 'Ä these',\n",
       " 778: 'Ä pr',\n",
       " 779: 'Ä use',\n",
       " 780: 'Ä because',\n",
       " 781: 'Ä fl',\n",
       " 782: 'ng',\n",
       " 783: 'Ä now',\n",
       " 784: 'Ä Ã¢Ä¢Äµ',\n",
       " 785: 'com',\n",
       " 786: 'ise',\n",
       " 787: 'Ä make',\n",
       " 788: 'Ä then',\n",
       " 789: 'ower',\n",
       " 790: 'Ä every',\n",
       " 791: 'Ä Un',\n",
       " 792: 'Ä sec',\n",
       " 793: 'oss',\n",
       " 794: 'uch',\n",
       " 795: 'Ä em',\n",
       " 796: 'Ä =',\n",
       " 797: 'Ä Re',\n",
       " 798: 'ied',\n",
       " 799: 'rit',\n",
       " 800: 'Ä inv',\n",
       " 801: 'lect',\n",
       " 802: 'Ä supp',\n",
       " 803: 'ating',\n",
       " 804: 'Ä look',\n",
       " 805: 'man',\n",
       " 806: 'pect',\n",
       " 807: 'Ä 8',\n",
       " 808: 'row',\n",
       " 809: 'Ä bu',\n",
       " 810: 'Ä where',\n",
       " 811: 'ific',\n",
       " 812: 'Ä years',\n",
       " 813: 'ily',\n",
       " 814: 'Ä diff',\n",
       " 815: 'Ä should',\n",
       " 816: 'Ä rem',\n",
       " 817: 'Th',\n",
       " 818: 'In',\n",
       " 819: 'Ä ev',\n",
       " 820: 'day',\n",
       " 821: \"'re\",\n",
       " 822: 'rib',\n",
       " 823: 'Ä rel',\n",
       " 824: 'ss',\n",
       " 825: 'Ä def',\n",
       " 826: 'Ä right',\n",
       " 827: 'Ä sy',\n",
       " 828: '),',\n",
       " 829: 'les',\n",
       " 830: '000',\n",
       " 831: 'hen',\n",
       " 832: 'Ä through',\n",
       " 833: 'Ä Tr',\n",
       " 834: '__',\n",
       " 835: 'Ä way',\n",
       " 836: 'Ä don',\n",
       " 837: 'Ä ,',\n",
       " 838: 'Ä 10',\n",
       " 839: 'ased',\n",
       " 840: 'Ä ass',\n",
       " 841: 'ublic',\n",
       " 842: 'Ä reg',\n",
       " 843: 'Ä And',\n",
       " 844: 'ix',\n",
       " 845: 'Ä very',\n",
       " 846: 'Ä includ',\n",
       " 847: 'other',\n",
       " 848: 'Ä imp',\n",
       " 849: 'oth',\n",
       " 850: 'Ä sub',\n",
       " 851: 'Ä Ã¢Ä¢Ä¶',\n",
       " 852: 'Ä being',\n",
       " 853: 'arg',\n",
       " 854: 'Ä Wh',\n",
       " 855: '==',\n",
       " 856: 'ible',\n",
       " 857: 'Ä does',\n",
       " 858: 'ange',\n",
       " 859: 'ram',\n",
       " 860: 'Ä 9',\n",
       " 861: 'ert',\n",
       " 862: 'ps',\n",
       " 863: 'ited',\n",
       " 864: 'ational',\n",
       " 865: 'Ä br',\n",
       " 866: 'Ä down',\n",
       " 867: 'Ä many',\n",
       " 868: 'aking',\n",
       " 869: 'Ä call',\n",
       " 870: 'uring',\n",
       " 871: 'ities',\n",
       " 872: 'Ä ph',\n",
       " 873: 'ics',\n",
       " 874: 'als',\n",
       " 875: 'Ä dec',\n",
       " 876: 'ative',\n",
       " 877: 'ener',\n",
       " 878: 'Ä before',\n",
       " 879: 'ility',\n",
       " 880: 'Ä well',\n",
       " 881: 'Ä much',\n",
       " 882: 'erson',\n",
       " 883: 'Ä those',\n",
       " 884: 'Ä such',\n",
       " 885: 'Ä ke',\n",
       " 886: 'Ä end',\n",
       " 887: 'Ä But',\n",
       " 888: 'ason',\n",
       " 889: 'ting',\n",
       " 890: 'Ä long',\n",
       " 891: 'ef',\n",
       " 892: 'Ä think',\n",
       " 893: 'ys',\n",
       " 894: 'Ä bel',\n",
       " 895: 'Ä sm',\n",
       " 896: 'its',\n",
       " 897: 'ax',\n",
       " 898: 'Ä own',\n",
       " 899: 'Ä prov',\n",
       " 900: 'Ä set',\n",
       " 901: 'ife',\n",
       " 902: 'ments',\n",
       " 903: 'ble',\n",
       " 904: 'ward',\n",
       " 905: 'Ä show',\n",
       " 906: 'Ä pres',\n",
       " 907: 'ms',\n",
       " 908: 'omet',\n",
       " 909: 'Ä ob',\n",
       " 910: 'Ä say',\n",
       " 911: 'Ä Sh',\n",
       " 912: 'ts',\n",
       " 913: 'ful',\n",
       " 914: 'Ä eff',\n",
       " 915: 'Ä gu',\n",
       " 916: 'Ä inst',\n",
       " 917: 'und',\n",
       " 918: 'ren',\n",
       " 919: 'cess',\n",
       " 920: 'Ä ent',\n",
       " 921: 'Ä You',\n",
       " 922: 'Ä good',\n",
       " 923: 'Ä start',\n",
       " 924: 'ince',\n",
       " 925: 'Ä made',\n",
       " 926: 'tt',\n",
       " 927: 'stem',\n",
       " 928: 'olog',\n",
       " 929: 'up',\n",
       " 930: 'Ä |',\n",
       " 931: 'ump',\n",
       " 932: 'Ä hel',\n",
       " 933: 'vern',\n",
       " 934: 'ular',\n",
       " 935: 'ually',\n",
       " 936: 'Ä ac',\n",
       " 937: 'Ä mon',\n",
       " 938: 'Ä last',\n",
       " 939: 'Ä 200',\n",
       " 940: '10',\n",
       " 941: 'Ä stud',\n",
       " 942: 'ures',\n",
       " 943: 'Ä Ar',\n",
       " 944: 'self',\n",
       " 945: 'ars',\n",
       " 946: 'meric',\n",
       " 947: 'ues',\n",
       " 948: 'cy',\n",
       " 949: 'Ä min',\n",
       " 950: 'ollow',\n",
       " 951: 'Ä col',\n",
       " 952: 'io',\n",
       " 953: 'Ä mod',\n",
       " 954: 'Ä count',\n",
       " 955: 'Ä Com',\n",
       " 956: 'hes',\n",
       " 957: 'Ä fin',\n",
       " 958: 'air',\n",
       " 959: 'ier',\n",
       " 960: 'Ã¢Ä¢Ä¶',\n",
       " 961: 'read',\n",
       " 962: 'ank',\n",
       " 963: 'atch',\n",
       " 964: 'ever',\n",
       " 965: 'Ä str',\n",
       " 966: 'Ä point',\n",
       " 967: 'ork',\n",
       " 968: 'Ä New',\n",
       " 969: 'Ä sur',\n",
       " 970: 'ool',\n",
       " 971: 'alk',\n",
       " 972: 'ement',\n",
       " 973: 'Ä used',\n",
       " 974: 'ract',\n",
       " 975: 'ween',\n",
       " 976: 'Ä same',\n",
       " 977: 'oun',\n",
       " 978: 'Ä Al',\n",
       " 979: 'ci',\n",
       " 980: 'Ä differe',\n",
       " 981: 'Ä while',\n",
       " 982: '--------',\n",
       " 983: 'Ä game',\n",
       " 984: 'cept',\n",
       " 985: 'Ä sim',\n",
       " 986: '...',\n",
       " 987: 'Ä inter',\n",
       " 988: 'ek',\n",
       " 989: 'Ä report',\n",
       " 990: 'Ä produ',\n",
       " 991: 'Ä still',\n",
       " 992: 'led',\n",
       " 993: 'ah',\n",
       " 994: 'Ä here',\n",
       " 995: 'Ä world',\n",
       " 996: 'Ä though',\n",
       " 997: 'Ä num',\n",
       " 998: 'arch',\n",
       " 999: 'imes',\n",
       " ...}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea9a914",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
