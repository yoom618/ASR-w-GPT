{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39678a37",
   "metadata": {},
   "source": [
    "### 0. Initial Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf0bf6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture\n",
    "# !pip install datasets==1.0.2\n",
    "# !pip install transformers==4.2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d44238cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33myoom-private\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/yoomin/wandb/run-20220404_181030-2zbxcchv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/yoom-private/testing-gptONLY/runs/2zbxcchv\" target=\"_blank\">glowing-meadow-3</a></strong> to <a href=\"https://wandb.ai/yoom-private/testing-gptONLY\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/yoom-private/testing-gptONLY/runs/2zbxcchv?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f844b486f70>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "cache_dir = \"/data4/yoomcache\"\n",
    "model_cache_dir = os.path.join(cache_dir, 'huggingface')\n",
    "data_cache_dir = os.path.join(cache_dir, 'datasets')\n",
    "checkpoint_dir = os.path.join(cache_dir, 'checkpoint')\n",
    "\n",
    "import logging\n",
    "logging.getLogger().setLevel(logging.CRITICAL)\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "\n",
    "import torch\n",
    "from datasets import load_dataset, load_metric, load_from_disk\n",
    "from transformers import BertTokenizer, RobertaTokenizer, GPT2Tokenizer\n",
    "from transformers import AutoConfig, EncoderDecoderConfig, EncoderDecoderModel\n",
    "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
    "\n",
    "import wandb\n",
    "wandb.init(project=\"testing-gptONLY\", entity=\"yoom-private\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc6e87b",
   "metadata": {},
   "source": [
    "### 1. Initialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "435b40c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "config_encoder = AutoConfig.from_pretrained(\"gpt2\", cache_dir=model_cache_dir)\n",
    "config_decoder = AutoConfig.from_pretrained(\"gpt2\", cache_dir=model_cache_dir)\n",
    "config = EncoderDecoderConfig.from_encoder_decoder_configs(config_encoder, config_decoder, cache_dir=model_cache_dir)\n",
    "model = EncoderDecoderModel(config=config)\n",
    "# model.save_pretrained(\"roberta2gpt\", cache_dir=model_cache_dir)\n",
    "# model = EncoderDecoderModel.from_pretrained(\"roberta2gpt\", cache_dir=model_cache_dir)\n",
    "\n",
    "model.encoder.h = model.encoder.h[:4]\n",
    "model.decoder.transformer.h = model.decoder.transformer.h[-4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e29f57e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (crossattention): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (q_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_cross_attn): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (crossattention): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (q_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_cross_attn): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (crossattention): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (q_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_cross_attn): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (crossattention): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (q_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_cross_attn): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6fe24aec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# make sure GPT2 appends EOS in begin and end\n",
    "def build_inputs_with_special_tokens(self, token_ids_0, token_ids_1=None):\n",
    "    outputs = [self.bos_token_id] + token_ids_0 + [self.eos_token_id]\n",
    "    return outputs\n",
    "\n",
    "GPT2Tokenizer.build_inputs_with_special_tokens = build_inputs_with_special_tokens\n",
    "\n",
    "\n",
    "encoder_tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\", cache_dir=model_cache_dir)\n",
    "encoder_tokenizer.pad_token = encoder_tokenizer.unk_token\n",
    "# encoder_tokenizer.bos_token = encoder_tokenizer.cls_token  # CLS token will work as BOS token\n",
    "# encoder_tokenizer.eos_token = encoder_tokenizer.sep_token  # SEP token will work as EOS token\n",
    "\n",
    "decoder_tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\", cache_dir=model_cache_dir)\n",
    "# set pad_token_id to unk_token_id -> be careful here as unk_token_id == eos_token_id == bos_token_id\n",
    "decoder_tokenizer.pad_token = decoder_tokenizer.unk_token\n",
    "\n",
    "\n",
    "model.config.decoder_start_token_id = encoder_tokenizer.cls_token_id\n",
    "model.config.eos_token_id = encoder_tokenizer.sep_token_id\n",
    "model.config.pad_token_id = encoder_tokenizer.pad_token_id\n",
    "model.config.vocab_size = model.config.encoder.vocab_size\n",
    "\n",
    "\n",
    "# set decoding params\n",
    "model.config.decoder_start_token_id = decoder_tokenizer.bos_token_id\n",
    "model.config.eos_token_id = decoder_tokenizer.eos_token_id\n",
    "model.config.max_length = 142\n",
    "model.config.min_length = 56\n",
    "model.config.no_repeat_ngram_size = 3\n",
    "model.early_stopping = True\n",
    "model.length_penalty = 2.0\n",
    "model.num_beams = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "466b4194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze decoder parameters\n",
    "for param in model.decoder.parameters():\n",
    "    param.requires_grad = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bce84c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "467b21e7",
   "metadata": {},
   "source": [
    "### 2. Preparing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "feaded22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# map data correctly\n",
    "def map_to_encoder_decoder_inputs(batch):    # Tokenizer will automatically set [BOS] <text> [EOS] \n",
    "    encoder_length, decoder_length = 512, 128\n",
    "    inputs = encoder_tokenizer(batch[\"article\"], \n",
    "                               padding=\"max_length\", \n",
    "                               truncation=True, \n",
    "                               max_length=encoder_length)\n",
    "    outputs = decoder_tokenizer(batch[\"highlights\"], \n",
    "                                padding=\"max_length\", \n",
    "                                truncation=True, \n",
    "                                max_length=decoder_length)\n",
    "    \n",
    "    batch[\"input_ids\"] = inputs.input_ids\n",
    "    batch[\"attention_mask\"] = inputs.attention_mask\n",
    "    batch[\"decoder_input_ids\"] = outputs.input_ids\n",
    "    batch[\"labels\"] = outputs.input_ids.copy()\n",
    "    batch[\"decoder_attention_mask\"] = outputs.attention_mask\n",
    "\n",
    "    # complicated list comprehension here because pad_token_id alone is not good enough to know whether label should be excluded or not\n",
    "    batch[\"labels\"] = -100 if batch[\"decoder_attention_mask\"] == 0 else batch[\"labels\"]\n",
    "\n",
    "    assert len(inputs.input_ids) == encoder_length\n",
    "    assert len(outputs.input_ids) == decoder_length\n",
    "\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d77189b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(cache_dir, 'preprocessed/train')):\n",
    "    train_dataset = load_from_disk(os.path.join(cache_dir, 'preprocessed/train'))\n",
    "else:\n",
    "    train_dataset = load_dataset(\"ccdv/cnn_dailymail\", \"3.0.0\", split=\"train\", cache_dir=data_cache_dir)\n",
    "    train_dataset = train_dataset.map(\n",
    "        map_to_encoder_decoder_inputs, \n",
    "        # batched=True, \n",
    "        # batch_size=batch_size, \n",
    "        remove_columns=['id', 'article', 'highlights'],\n",
    "    )\n",
    "    train_dataset.set_format(\n",
    "        type=\"torch\", \n",
    "        columns=[\"input_ids\", \"attention_mask\", \"decoder_input_ids\", \"decoder_attention_mask\", \"labels\"],\n",
    "    )\n",
    "    \n",
    "    train_dataset.save_to_disk(os.path.join(cache_dir, 'preprocessed/train'))\n",
    "\n",
    "\n",
    "if os.path.exists(os.path.join(cache_dir, 'preprocessed/val')):\n",
    "    val_dataset = load_from_disk(os.path.join(cache_dir, 'preprocessed/val'))\n",
    "else:\n",
    "    val_dataset = load_dataset(\"ccdv/cnn_dailymail\", \"3.0.0\", split=\"validation\", cache_dir=data_cache_dir)\n",
    "    val_dataset = val_dataset.map(\n",
    "        map_to_encoder_decoder_inputs, \n",
    "        # batched=True, \n",
    "        # batch_size=batch_size, \n",
    "        remove_columns=['id', 'article', 'highlights'],\n",
    "    )\n",
    "    val_dataset.set_format(\n",
    "        type=\"torch\", \n",
    "        columns=[\"input_ids\", \"attention_mask\", \"decoder_input_ids\", \"decoder_attention_mask\", \"labels\"],\n",
    "    )\n",
    "    val_dataset.save_to_disk(os.path.join(cache_dir, 'preprocessed/val'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80414621",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "63779bf8",
   "metadata": {},
   "source": [
    "### Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9cde9706",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load rouge for validation\n",
    "rouge = load_metric(\"rouge\")\n",
    "# rouge = load_metric(\"rouge\", experiment_id=1)\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels_ids = pred.label_ids\n",
    "    pred_ids = pred.predictions\n",
    "\n",
    "    # all unnecessary tokens are removed\n",
    "    pred_str = decoder_tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "    labels_ids[labels_ids == -100] = decoder_tokenizer.eos_token_id\n",
    "    label_str = decoder_tokenizer.batch_decode(labels_ids, skip_special_tokens=True)\n",
    "\n",
    "    rouge_output = rouge.compute(predictions=pred_str, references=label_str, rouge_types=[\"rouge2\"])[\"rouge2\"].mid\n",
    "\n",
    "    return {\n",
    "        \"rouge2_precision\": round(rouge_output.precision, 4),\n",
    "        \"rouge2_recall\": round(rouge_output.recall, 4),\n",
    "        \"rouge2_fmeasure\": round(rouge_output.fmeasure, 4),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1453320d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 28711\n",
      "  Num Epochs = 100\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 179500\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='170001' max='179500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [170001/179500 38:09:04 < 2:07:54, 1.24 it/s, Epoch 94.71/100]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge2 Precision</th>\n",
       "      <th>Rouge2 Recall</th>\n",
       "      <th>Rouge2 Fmeasure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>5.023300</td>\n",
       "      <td>3.589779</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>4.471300</td>\n",
       "      <td>3.203995</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>4.194800</td>\n",
       "      <td>3.085265</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>4.072400</td>\n",
       "      <td>3.006499</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>3.970900</td>\n",
       "      <td>2.895184</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>3.810200</td>\n",
       "      <td>2.781841</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>3.667800</td>\n",
       "      <td>2.682241</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>3.577300</td>\n",
       "      <td>2.575866</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>0.001000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>3.420300</td>\n",
       "      <td>2.447604</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>0.002100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>3.301900</td>\n",
       "      <td>2.363680</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.003900</td>\n",
       "      <td>0.002100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>3.210900</td>\n",
       "      <td>2.268435</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>3.077400</td>\n",
       "      <td>2.176966</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>2.968700</td>\n",
       "      <td>2.063487</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>2.831700</td>\n",
       "      <td>1.977451</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>2.713800</td>\n",
       "      <td>1.901897</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>2.640100</td>\n",
       "      <td>1.854109</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>2.571400</td>\n",
       "      <td>1.808803</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>2.522000</td>\n",
       "      <td>1.761184</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>2.457200</td>\n",
       "      <td>1.720794</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>2.420900</td>\n",
       "      <td>1.686010</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21000</td>\n",
       "      <td>2.368100</td>\n",
       "      <td>1.650332</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>2.333500</td>\n",
       "      <td>1.625865</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23000</td>\n",
       "      <td>2.287100</td>\n",
       "      <td>1.598562</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24000</td>\n",
       "      <td>2.259200</td>\n",
       "      <td>1.572089</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25000</td>\n",
       "      <td>2.231000</td>\n",
       "      <td>1.546331</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26000</td>\n",
       "      <td>2.198800</td>\n",
       "      <td>1.527397</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27000</td>\n",
       "      <td>2.175100</td>\n",
       "      <td>1.509326</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28000</td>\n",
       "      <td>2.143000</td>\n",
       "      <td>1.490550</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29000</td>\n",
       "      <td>2.122400</td>\n",
       "      <td>1.470730</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>2.093800</td>\n",
       "      <td>1.453950</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31000</td>\n",
       "      <td>2.077700</td>\n",
       "      <td>1.445163</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32000</td>\n",
       "      <td>2.048800</td>\n",
       "      <td>1.424704</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33000</td>\n",
       "      <td>2.024000</td>\n",
       "      <td>1.414317</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34000</td>\n",
       "      <td>2.016700</td>\n",
       "      <td>1.397117</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35000</td>\n",
       "      <td>1.991300</td>\n",
       "      <td>1.391947</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36000</td>\n",
       "      <td>1.982800</td>\n",
       "      <td>1.384483</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37000</td>\n",
       "      <td>1.956600</td>\n",
       "      <td>1.372409</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38000</td>\n",
       "      <td>1.948600</td>\n",
       "      <td>1.366692</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39000</td>\n",
       "      <td>1.932800</td>\n",
       "      <td>1.357882</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40000</td>\n",
       "      <td>1.917000</td>\n",
       "      <td>1.352336</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41000</td>\n",
       "      <td>1.910500</td>\n",
       "      <td>1.343619</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42000</td>\n",
       "      <td>1.895700</td>\n",
       "      <td>1.336895</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43000</td>\n",
       "      <td>1.881400</td>\n",
       "      <td>1.331700</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44000</td>\n",
       "      <td>1.866400</td>\n",
       "      <td>1.328056</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45000</td>\n",
       "      <td>1.863300</td>\n",
       "      <td>1.320481</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46000</td>\n",
       "      <td>1.851400</td>\n",
       "      <td>1.318297</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47000</td>\n",
       "      <td>1.838900</td>\n",
       "      <td>1.314763</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48000</td>\n",
       "      <td>1.831900</td>\n",
       "      <td>1.310102</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49000</td>\n",
       "      <td>1.822100</td>\n",
       "      <td>1.306544</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50000</td>\n",
       "      <td>1.812800</td>\n",
       "      <td>1.302947</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51000</td>\n",
       "      <td>1.805900</td>\n",
       "      <td>1.297641</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52000</td>\n",
       "      <td>1.793600</td>\n",
       "      <td>1.297907</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53000</td>\n",
       "      <td>1.788400</td>\n",
       "      <td>1.293182</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54000</td>\n",
       "      <td>1.778500</td>\n",
       "      <td>1.289469</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55000</td>\n",
       "      <td>1.770000</td>\n",
       "      <td>1.287272</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56000</td>\n",
       "      <td>1.770800</td>\n",
       "      <td>1.287074</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57000</td>\n",
       "      <td>1.759100</td>\n",
       "      <td>1.286711</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58000</td>\n",
       "      <td>1.751000</td>\n",
       "      <td>1.287793</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59000</td>\n",
       "      <td>1.746400</td>\n",
       "      <td>1.281691</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60000</td>\n",
       "      <td>1.738600</td>\n",
       "      <td>1.280380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61000</td>\n",
       "      <td>1.737900</td>\n",
       "      <td>1.275322</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62000</td>\n",
       "      <td>1.726200</td>\n",
       "      <td>1.275964</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63000</td>\n",
       "      <td>1.724700</td>\n",
       "      <td>1.275604</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64000</td>\n",
       "      <td>1.716200</td>\n",
       "      <td>1.271479</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65000</td>\n",
       "      <td>1.712300</td>\n",
       "      <td>1.273856</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66000</td>\n",
       "      <td>1.705400</td>\n",
       "      <td>1.271380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67000</td>\n",
       "      <td>1.704000</td>\n",
       "      <td>1.273367</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68000</td>\n",
       "      <td>1.696100</td>\n",
       "      <td>1.270292</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69000</td>\n",
       "      <td>1.691200</td>\n",
       "      <td>1.268958</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70000</td>\n",
       "      <td>1.691300</td>\n",
       "      <td>1.269051</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71000</td>\n",
       "      <td>1.678100</td>\n",
       "      <td>1.271457</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72000</td>\n",
       "      <td>1.681700</td>\n",
       "      <td>1.270470</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73000</td>\n",
       "      <td>1.676800</td>\n",
       "      <td>1.269439</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74000</td>\n",
       "      <td>1.667500</td>\n",
       "      <td>1.269791</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75000</td>\n",
       "      <td>1.671300</td>\n",
       "      <td>1.268568</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76000</td>\n",
       "      <td>1.655800</td>\n",
       "      <td>1.269024</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77000</td>\n",
       "      <td>1.663100</td>\n",
       "      <td>1.265483</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78000</td>\n",
       "      <td>1.651400</td>\n",
       "      <td>1.268916</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79000</td>\n",
       "      <td>1.651000</td>\n",
       "      <td>1.265060</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80000</td>\n",
       "      <td>1.646300</td>\n",
       "      <td>1.269748</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81000</td>\n",
       "      <td>1.643500</td>\n",
       "      <td>1.268982</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82000</td>\n",
       "      <td>1.635500</td>\n",
       "      <td>1.267630</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83000</td>\n",
       "      <td>1.642100</td>\n",
       "      <td>1.269072</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84000</td>\n",
       "      <td>1.630500</td>\n",
       "      <td>1.270619</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85000</td>\n",
       "      <td>1.631200</td>\n",
       "      <td>1.269234</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86000</td>\n",
       "      <td>1.627200</td>\n",
       "      <td>1.267673</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87000</td>\n",
       "      <td>1.624500</td>\n",
       "      <td>1.266419</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88000</td>\n",
       "      <td>1.622000</td>\n",
       "      <td>1.267912</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>89000</td>\n",
       "      <td>1.615600</td>\n",
       "      <td>1.269645</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90000</td>\n",
       "      <td>1.616800</td>\n",
       "      <td>1.271303</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>91000</td>\n",
       "      <td>1.609300</td>\n",
       "      <td>1.266789</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92000</td>\n",
       "      <td>1.608600</td>\n",
       "      <td>1.271220</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93000</td>\n",
       "      <td>1.608000</td>\n",
       "      <td>1.272980</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94000</td>\n",
       "      <td>1.603700</td>\n",
       "      <td>1.269688</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95000</td>\n",
       "      <td>1.603800</td>\n",
       "      <td>1.272151</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96000</td>\n",
       "      <td>1.596600</td>\n",
       "      <td>1.273725</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97000</td>\n",
       "      <td>1.599700</td>\n",
       "      <td>1.273922</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98000</td>\n",
       "      <td>1.592200</td>\n",
       "      <td>1.273728</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99000</td>\n",
       "      <td>1.591600</td>\n",
       "      <td>1.270502</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100000</td>\n",
       "      <td>1.586700</td>\n",
       "      <td>1.273350</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>101000</td>\n",
       "      <td>1.587600</td>\n",
       "      <td>1.272543</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>102000</td>\n",
       "      <td>1.586000</td>\n",
       "      <td>1.272600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>103000</td>\n",
       "      <td>1.581700</td>\n",
       "      <td>1.273080</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>104000</td>\n",
       "      <td>1.581600</td>\n",
       "      <td>1.275753</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105000</td>\n",
       "      <td>1.577700</td>\n",
       "      <td>1.275924</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>106000</td>\n",
       "      <td>1.578900</td>\n",
       "      <td>1.274437</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>107000</td>\n",
       "      <td>1.571600</td>\n",
       "      <td>1.273713</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>108000</td>\n",
       "      <td>1.574300</td>\n",
       "      <td>1.276667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>109000</td>\n",
       "      <td>1.568800</td>\n",
       "      <td>1.273252</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110000</td>\n",
       "      <td>1.570600</td>\n",
       "      <td>1.277080</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>111000</td>\n",
       "      <td>1.568400</td>\n",
       "      <td>1.276068</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>112000</td>\n",
       "      <td>1.563600</td>\n",
       "      <td>1.276620</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>113000</td>\n",
       "      <td>1.563400</td>\n",
       "      <td>1.275325</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>114000</td>\n",
       "      <td>1.560100</td>\n",
       "      <td>1.277657</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>115000</td>\n",
       "      <td>1.563000</td>\n",
       "      <td>1.278520</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>116000</td>\n",
       "      <td>1.557100</td>\n",
       "      <td>1.278951</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>117000</td>\n",
       "      <td>1.556900</td>\n",
       "      <td>1.280519</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>118000</td>\n",
       "      <td>1.558400</td>\n",
       "      <td>1.277872</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>119000</td>\n",
       "      <td>1.548200</td>\n",
       "      <td>1.280062</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120000</td>\n",
       "      <td>1.556000</td>\n",
       "      <td>1.279106</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>121000</td>\n",
       "      <td>1.550300</td>\n",
       "      <td>1.280074</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>122000</td>\n",
       "      <td>1.550700</td>\n",
       "      <td>1.279790</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>123000</td>\n",
       "      <td>1.546100</td>\n",
       "      <td>1.280365</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>124000</td>\n",
       "      <td>1.547900</td>\n",
       "      <td>1.280926</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125000</td>\n",
       "      <td>1.546900</td>\n",
       "      <td>1.280902</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>126000</td>\n",
       "      <td>1.540100</td>\n",
       "      <td>1.282570</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>127000</td>\n",
       "      <td>1.540800</td>\n",
       "      <td>1.282852</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>128000</td>\n",
       "      <td>1.545600</td>\n",
       "      <td>1.282176</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>129000</td>\n",
       "      <td>1.540300</td>\n",
       "      <td>1.282507</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130000</td>\n",
       "      <td>1.538400</td>\n",
       "      <td>1.283417</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>131000</td>\n",
       "      <td>1.540900</td>\n",
       "      <td>1.283229</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>132000</td>\n",
       "      <td>1.541500</td>\n",
       "      <td>1.284232</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>133000</td>\n",
       "      <td>1.532100</td>\n",
       "      <td>1.282666</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>134000</td>\n",
       "      <td>1.533100</td>\n",
       "      <td>1.286791</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>135000</td>\n",
       "      <td>1.538000</td>\n",
       "      <td>1.283751</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>136000</td>\n",
       "      <td>1.532900</td>\n",
       "      <td>1.284260</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>137000</td>\n",
       "      <td>1.530400</td>\n",
       "      <td>1.285941</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>138000</td>\n",
       "      <td>1.531200</td>\n",
       "      <td>1.283337</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>139000</td>\n",
       "      <td>1.533700</td>\n",
       "      <td>1.284452</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140000</td>\n",
       "      <td>1.528900</td>\n",
       "      <td>1.285535</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>141000</td>\n",
       "      <td>1.527400</td>\n",
       "      <td>1.285378</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>142000</td>\n",
       "      <td>1.531000</td>\n",
       "      <td>1.285294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>143000</td>\n",
       "      <td>1.529000</td>\n",
       "      <td>1.286905</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>144000</td>\n",
       "      <td>1.527200</td>\n",
       "      <td>1.286638</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>145000</td>\n",
       "      <td>1.525200</td>\n",
       "      <td>1.285862</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>146000</td>\n",
       "      <td>1.523300</td>\n",
       "      <td>1.287759</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>147000</td>\n",
       "      <td>1.527900</td>\n",
       "      <td>1.287034</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>148000</td>\n",
       "      <td>1.524600</td>\n",
       "      <td>1.286148</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>149000</td>\n",
       "      <td>1.523700</td>\n",
       "      <td>1.286239</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150000</td>\n",
       "      <td>1.522500</td>\n",
       "      <td>1.286823</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>151000</td>\n",
       "      <td>1.522300</td>\n",
       "      <td>1.287331</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>152000</td>\n",
       "      <td>1.524500</td>\n",
       "      <td>1.288403</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>153000</td>\n",
       "      <td>1.520000</td>\n",
       "      <td>1.287412</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>154000</td>\n",
       "      <td>1.522400</td>\n",
       "      <td>1.287553</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155000</td>\n",
       "      <td>1.522300</td>\n",
       "      <td>1.287272</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>156000</td>\n",
       "      <td>1.519800</td>\n",
       "      <td>1.287839</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>157000</td>\n",
       "      <td>1.517500</td>\n",
       "      <td>1.288082</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>158000</td>\n",
       "      <td>1.521300</td>\n",
       "      <td>1.287419</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159000</td>\n",
       "      <td>1.518600</td>\n",
       "      <td>1.287895</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160000</td>\n",
       "      <td>1.522300</td>\n",
       "      <td>1.287793</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>161000</td>\n",
       "      <td>1.518200</td>\n",
       "      <td>1.288443</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>162000</td>\n",
       "      <td>1.518500</td>\n",
       "      <td>1.287933</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>163000</td>\n",
       "      <td>1.518900</td>\n",
       "      <td>1.287377</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>164000</td>\n",
       "      <td>1.514900</td>\n",
       "      <td>1.287843</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>165000</td>\n",
       "      <td>1.521900</td>\n",
       "      <td>1.287677</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>166000</td>\n",
       "      <td>1.516000</td>\n",
       "      <td>1.287685</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>167000</td>\n",
       "      <td>1.520900</td>\n",
       "      <td>1.288269</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>168000</td>\n",
       "      <td>1.519400</td>\n",
       "      <td>1.288022</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>169000</td>\n",
       "      <td>1.515800</td>\n",
       "      <td>1.288087</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='43' max='84' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [43/84 02:03 < 02:00, 0.34 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-1000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-1000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-1000/pytorch_model.bin\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-2000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-2000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-2000/pytorch_model.bin\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-3000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-3000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-3000/pytorch_model.bin\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-4000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-4000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-4000/pytorch_model.bin\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-5000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-5000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-5000/pytorch_model.bin\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-6000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-6000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-6000/pytorch_model.bin\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-7000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-7000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-7000/pytorch_model.bin\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-8000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-8000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-8000/pytorch_model.bin\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-9000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-9000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-9000/pytorch_model.bin\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-10000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-10000/pytorch_model.bin\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-11000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-11000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-11000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-1000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-12000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-12000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-12000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-2000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-13000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-13000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-13000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-3000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-14000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-14000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-14000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-4000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-15000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-15000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-15000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-5000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-16000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-16000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-16000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-6000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-17000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-17000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-17000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-7000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-18000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-18000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-18000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-8000] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-19000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-19000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-19000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-9000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-20000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-20000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-20000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-10000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-21000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-21000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-21000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-11000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-22000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-22000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-22000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-12000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-23000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-23000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-23000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-13000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-24000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-24000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-24000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-14000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-25000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-25000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-25000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-15000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-26000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-26000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-26000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-16000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-27000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-27000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-27000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-17000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-28000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-28000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-28000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-18000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-29000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-29000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-29000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-19000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-30000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-30000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-30000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-20000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-31000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-31000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-31000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-21000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-32000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-32000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-32000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-22000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-33000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-33000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-33000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-23000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-34000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-34000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-34000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-24000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-35000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-35000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-35000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-25000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-36000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-36000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-36000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-26000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-37000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-37000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-37000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-27000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-38000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-38000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-38000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-28000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-39000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-39000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-39000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-29000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-40000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-40000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-40000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-30000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-41000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-41000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-41000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-31000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-42000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-42000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-42000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-32000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-43000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-43000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-43000/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-33000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-44000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-44000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-44000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-34000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-45000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-45000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-45000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-35000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-46000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-46000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-46000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-36000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-47000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-47000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-47000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-37000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-48000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-48000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-48000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-38000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-49000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-49000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-49000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-39000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-50000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-50000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-50000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-40000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-51000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-51000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-51000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-41000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-52000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-52000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-52000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-42000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-53000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-53000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-53000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-43000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-54000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-54000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-54000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-44000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-55000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-55000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-55000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-45000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-56000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-56000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-56000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-46000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-57000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-57000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-57000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-47000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-58000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-58000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-58000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-48000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-59000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-59000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-59000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-49000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-60000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-60000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-60000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-50000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-61000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-61000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-61000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-51000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-62000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-62000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-62000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-52000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-63000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-63000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-63000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-53000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-64000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-64000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-64000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-54000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-65000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-65000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-65000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-55000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-66000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-66000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-66000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-56000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-67000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-67000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-67000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-57000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-68000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-68000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-68000/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-58000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-69000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-69000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-69000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-59000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-70000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-70000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-70000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-60000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-71000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-71000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-71000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-61000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-72000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-72000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-72000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-62000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-73000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-73000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-73000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-63000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-74000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-74000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-74000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-64000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-75000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-75000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-75000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-65000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-76000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-76000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-76000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-66000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-77000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-77000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-77000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-67000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-78000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-78000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-78000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-68000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-79000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-79000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-79000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-69000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-80000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-80000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-80000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-70000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-81000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-81000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-81000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-71000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-82000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-82000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-82000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-72000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-83000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-83000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-83000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-73000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-84000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-84000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-84000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-74000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-85000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-85000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-85000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-75000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-86000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-86000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-86000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-76000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-87000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-87000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-87000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-77000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-88000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-88000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-88000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-78000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-89000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-89000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-89000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-79000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-90000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-90000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-90000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-80000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-91000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-91000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-91000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-81000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-92000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-92000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-92000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-82000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-93000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-93000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-93000/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-83000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-94000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-94000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-94000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-84000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-95000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-95000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-95000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-85000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-96000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-96000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-96000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-86000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-97000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-97000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-97000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-87000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-98000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-98000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-98000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-88000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-99000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-99000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-99000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-89000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "wandb: Network error (ReadTimeout), entering retry loop.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-100000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-100000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-100000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-90000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-101000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-101000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-101000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-91000] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-102000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-102000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-102000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-92000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-103000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-103000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-103000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-93000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-104000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-104000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-104000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-94000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-105000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-105000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-105000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-95000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-106000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-106000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-106000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-96000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-107000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-107000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-107000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-97000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-108000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-108000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-108000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-98000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-109000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-109000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-109000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-99000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-110000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-110000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-110000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-100000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-111000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-111000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-111000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-101000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-112000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-112000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-112000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-102000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-113000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-113000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-113000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-103000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-114000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-114000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-114000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-104000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-115000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-115000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-115000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-105000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-116000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-116000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-116000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-106000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-117000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-117000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-117000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-107000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-118000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-118000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-118000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-108000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-119000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-119000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-119000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-109000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-120000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-120000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-120000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-110000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-121000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-121000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-121000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-111000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-122000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-122000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-122000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-112000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-123000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-123000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-123000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-113000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-124000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-124000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-124000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-114000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-125000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-125000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-125000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-115000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-126000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-126000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-126000/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-116000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-127000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-127000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-127000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-117000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-128000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-128000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-128000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-118000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-129000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-129000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-129000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-119000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-130000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-130000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-130000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-120000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-131000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-131000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-131000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-121000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-132000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-132000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-132000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-122000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-133000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-133000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-133000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-123000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-134000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-134000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-134000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-124000] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-135000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-135000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-135000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-125000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-136000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-136000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-136000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-126000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-137000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-137000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-137000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-127000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-138000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-138000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-138000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-128000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-139000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-139000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-139000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-129000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-140000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-140000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-140000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-130000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-141000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-141000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-141000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-131000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-142000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-142000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-142000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-132000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-143000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-143000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-143000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-133000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-144000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-144000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-144000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-134000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-145000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-145000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-145000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-135000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-146000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-146000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-146000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-136000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-147000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-147000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-147000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-137000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-148000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-148000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-148000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-138000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-149000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-149000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-149000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-139000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-150000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-150000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-150000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-140000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-151000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-151000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-151000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-141000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-152000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-152000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-152000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-142000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-153000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-153000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-153000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-143000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-154000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-154000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-154000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-144000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-155000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-155000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-155000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-145000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-156000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-156000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-156000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-146000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-157000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-157000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-157000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-147000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-158000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-158000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-158000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-148000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-159000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-159000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-159000/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-149000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-160000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-160000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-160000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-150000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-161000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-161000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-161000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-151000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-162000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-162000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-162000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-152000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-163000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-163000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-163000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-153000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-164000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-164000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-164000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-154000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-165000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-165000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-165000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-155000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-166000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-166000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-166000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-156000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-167000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-167000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-167000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-157000] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-168000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-168000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-168000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-158000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /data4/yoomcache/checkpoint/gptONLY/checkpoint-169000\n",
      "Configuration saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-169000/config.json\n",
      "Model weights saved in /data4/yoomcache/checkpoint/gptONLY/checkpoint-169000/pytorch_model.bin\n",
      "Deleting older checkpoint [/data4/yoomcache/checkpoint/gptONLY/checkpoint-159000] due to args.save_total_limit\n",
      "/home/yoomin/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1337\n",
      "  Batch size = 16\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "\n",
    "# set training arguments - these params are not really tuned, feel free to change\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    predict_with_generate=True,\n",
    "    output_dir=os.path.join(checkpoint_dir, \"gptONLY\"),\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    # do_predict=True,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    learning_rate=1e-4, \n",
    "#     weight_decay=0.0, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0,\n",
    "    num_train_epochs=100,\n",
    "    max_steps=-1,\n",
    "    lr_scheduler_type='cosine',\n",
    "    \n",
    "    logging_strategy='steps',\n",
    "    save_strategy='steps',\n",
    "    evaluation_strategy='steps',\n",
    "    logging_steps=1000,\n",
    "    save_steps=1000,\n",
    "    eval_steps=1000,\n",
    "    warmup_steps=10000,\n",
    "    save_total_limit=10,\n",
    "    overwrite_output_dir=True,\n",
    ")\n",
    "\n",
    "# instantiate trainer\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    ")\n",
    "\n",
    "# start training\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2be7e0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6b0595",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd93c69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401ac735",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fff11ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7245a07f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a488e8b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad86b46e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
